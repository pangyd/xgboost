nohup: ignoring input
北京市
1005A
1008A
1009A
1010A
1012A
3417A
3418A
3671A
3672A
3673A
3674A
3675A
3695A
3696A
3697A
[flaml.automl: 09-23 04:16:11] {2390} INFO - task = regression
[flaml.automl: 09-23 04:16:11] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 04:16:11] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 04:16:11] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 04:16:11] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 04:16:11] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 04:16:12] {3025} INFO - Estimated sufficient time budget=250819s. Estimated necessary time budget=251s.
[flaml.automl: 09-23 04:16:12] {3072} INFO -  at 2.2s,	estimator xgboost's best error=51.0113,	best estimator xgboost's best error=51.0113
[flaml.automl: 09-23 04:16:12] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 04:16:14] {3072} INFO -  at 3.7s,	estimator xgboost's best error=23.8398,	best estimator xgboost's best error=23.8398
[flaml.automl: 09-23 04:16:14] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 04:16:15] {3072} INFO -  at 4.8s,	estimator xgboost's best error=23.8398,	best estimator xgboost's best error=23.8398
[flaml.automl: 09-23 04:16:15] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 04:16:16] {3072} INFO -  at 5.9s,	estimator xgboost's best error=23.8398,	best estimator xgboost's best error=23.8398
[flaml.automl: 09-23 04:16:16] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 04:16:17] {3072} INFO -  at 7.0s,	estimator xgboost's best error=13.6769,	best estimator xgboost's best error=13.6769
[flaml.automl: 09-23 04:16:17] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 04:16:18] {3072} INFO -  at 8.2s,	estimator xgboost's best error=13.6769,	best estimator xgboost's best error=13.6769
[flaml.automl: 09-23 04:16:18] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 04:16:19] {3072} INFO -  at 9.5s,	estimator xgboost's best error=11.2112,	best estimator xgboost's best error=11.2112
[flaml.automl: 09-23 04:16:19] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 04:16:21] {3072} INFO -  at 10.9s,	estimator xgboost's best error=11.2112,	best estimator xgboost's best error=11.2112
[flaml.automl: 09-23 04:16:21] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 04:16:22] {3072} INFO -  at 12.2s,	estimator xgboost's best error=11.2112,	best estimator xgboost's best error=11.2112
[flaml.automl: 09-23 04:16:22] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 04:16:23] {3072} INFO -  at 13.5s,	estimator xgboost's best error=11.2112,	best estimator xgboost's best error=11.2112
[flaml.automl: 09-23 04:16:23] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 04:16:25] {3072} INFO -  at 14.6s,	estimator xgboost's best error=11.2112,	best estimator xgboost's best error=11.2112
[flaml.automl: 09-23 04:16:25] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 04:16:26] {3072} INFO -  at 16.2s,	estimator xgboost's best error=10.1968,	best estimator xgboost's best error=10.1968
[flaml.automl: 09-23 04:16:26] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 04:16:27] {3072} INFO -  at 17.3s,	estimator xgboost's best error=10.1968,	best estimator xgboost's best error=10.1968
[flaml.automl: 09-23 04:16:27] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 04:16:32] {3072} INFO -  at 21.9s,	estimator xgboost's best error=9.0474,	best estimator xgboost's best error=9.0474
[flaml.automl: 09-23 04:16:32] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 04:16:36] {3072} INFO -  at 26.2s,	estimator xgboost's best error=8.8444,	best estimator xgboost's best error=8.8444
[flaml.automl: 09-23 04:16:36] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 04:16:40] {3072} INFO -  at 29.8s,	estimator xgboost's best error=8.8444,	best estimator xgboost's best error=8.8444
[flaml.automl: 09-23 04:16:40] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 04:16:43] {3072} INFO -  at 33.2s,	estimator xgboost's best error=8.8444,	best estimator xgboost's best error=8.8444
[flaml.automl: 09-23 04:16:43] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 04:16:46] {3072} INFO -  at 36.3s,	estimator xgboost's best error=8.8444,	best estimator xgboost's best error=8.8444
[flaml.automl: 09-23 04:16:46] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 04:16:49] {3072} INFO -  at 39.0s,	estimator xgboost's best error=8.8444,	best estimator xgboost's best error=8.8444
[flaml.automl: 09-23 04:16:49] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 04:17:01] {3072} INFO -  at 51.2s,	estimator xgboost's best error=8.6306,	best estimator xgboost's best error=8.6306
[flaml.automl: 09-23 04:17:13] {3335} INFO - retrain xgboost for 12.1s
[flaml.automl: 09-23 04:17:13] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 04:17:13] {2636} INFO - fit succeeded
[flaml.automl: 09-23 04:17:13] {2637} INFO - Time taken to find the best model: 51.24915432929993
[flaml.automl: 09-23 04:17:13] {2648} WARNING - Time taken to find the best model is 85% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
PM10(0)最佳参数：{'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 165942}
PM10(0)最佳损失：-7.630590216108436
PM10(0)最好结果：{'pred_time': 2.273297037049846e-06, 'wall_clock_time': 51.24915432929993, 'metric_for_logging': {'pred_time': 2.273297037049846e-06}, 'val_loss': 8.630590216108436, 'training_iteration': 1, 'config': {'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 165942}, 'config/n_estimators': 31, 'config/max_leaves': 7, 'config/min_child_weight': 0.6186300892591503, 'config/learning_rate': 0.48254477352294606, 'config/subsample': 0.8921566499079494, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9831203893408513, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.011522990442748649, 'config/FLAML_sample_size': 165942, 'experiment_tag': 'exp', 'time_total_s': 12.206373691558838}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.9012670466907208
PM10(0)的mse=203.41244743550814
PM10(0)的mae=8.521099985457562
PM10(0)的mar=0.2763298093230225
总共花费的时间为：65.63
天津市
1015A
1019A
2859A
2860A
2922A
3325A
3326A
3327A
3460A
3461A
3462A
[flaml.automl: 09-23 04:43:20] {2390} INFO - task = regression
[flaml.automl: 09-23 04:43:20] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 04:43:20] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 04:43:20] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 04:43:20] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 04:43:20] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 04:43:20] {3025} INFO - Estimated sufficient time budget=7955s. Estimated necessary time budget=8s.
[flaml.automl: 09-23 04:43:20] {3072} INFO -  at 0.5s,	estimator xgboost's best error=44.4107,	best estimator xgboost's best error=44.4107
[flaml.automl: 09-23 04:43:20] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 04:43:20] {3072} INFO -  at 0.6s,	estimator xgboost's best error=21.6201,	best estimator xgboost's best error=21.6201
[flaml.automl: 09-23 04:43:20] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 04:43:20] {3072} INFO -  at 0.7s,	estimator xgboost's best error=21.6201,	best estimator xgboost's best error=21.6201
[flaml.automl: 09-23 04:43:20] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 04:43:20] {3072} INFO -  at 0.7s,	estimator xgboost's best error=21.6201,	best estimator xgboost's best error=21.6201
[flaml.automl: 09-23 04:43:20] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 04:43:20] {3072} INFO -  at 0.8s,	estimator xgboost's best error=17.1704,	best estimator xgboost's best error=17.1704
[flaml.automl: 09-23 04:43:20] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 04:43:20] {3072} INFO -  at 0.8s,	estimator xgboost's best error=13.8887,	best estimator xgboost's best error=13.8887
[flaml.automl: 09-23 04:43:20] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 04:43:20] {3072} INFO -  at 0.8s,	estimator xgboost's best error=12.7770,	best estimator xgboost's best error=12.7770
[flaml.automl: 09-23 04:43:20] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 04:43:20] {3072} INFO -  at 0.9s,	estimator xgboost's best error=12.7770,	best estimator xgboost's best error=12.7770
[flaml.automl: 09-23 04:43:20] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 04:43:20] {3072} INFO -  at 0.9s,	estimator xgboost's best error=12.7770,	best estimator xgboost's best error=12.7770
[flaml.automl: 09-23 04:43:20] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 04:43:21] {3072} INFO -  at 1.1s,	estimator xgboost's best error=11.4487,	best estimator xgboost's best error=11.4487
[flaml.automl: 09-23 04:43:21] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 04:43:21] {3072} INFO -  at 1.1s,	estimator xgboost's best error=11.4487,	best estimator xgboost's best error=11.4487
[flaml.automl: 09-23 04:43:21] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 04:43:21] {3072} INFO -  at 1.1s,	estimator xgboost's best error=11.4487,	best estimator xgboost's best error=11.4487
[flaml.automl: 09-23 04:43:21] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 04:43:21] {3072} INFO -  at 1.2s,	estimator xgboost's best error=9.8382,	best estimator xgboost's best error=9.8382
[flaml.automl: 09-23 04:43:21] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 04:43:21] {3072} INFO -  at 1.3s,	estimator xgboost's best error=9.1653,	best estimator xgboost's best error=9.1653
[flaml.automl: 09-23 04:43:21] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 04:43:21] {3072} INFO -  at 1.3s,	estimator xgboost's best error=9.1653,	best estimator xgboost's best error=9.1653
[flaml.automl: 09-23 04:43:21] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 04:43:21] {3072} INFO -  at 1.6s,	estimator xgboost's best error=9.1653,	best estimator xgboost's best error=9.1653
[flaml.automl: 09-23 04:43:21] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 04:43:21] {3072} INFO -  at 1.7s,	estimator xgboost's best error=9.1653,	best estimator xgboost's best error=9.1653
[flaml.automl: 09-23 04:43:21] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 04:43:21] {3072} INFO -  at 1.8s,	estimator xgboost's best error=9.0812,	best estimator xgboost's best error=9.0812
[flaml.automl: 09-23 04:43:21] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 04:43:22] {3072} INFO -  at 2.0s,	estimator xgboost's best error=9.0812,	best estimator xgboost's best error=9.0812
[flaml.automl: 09-23 04:43:22] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 04:43:22] {3072} INFO -  at 2.1s,	estimator xgboost's best error=9.0812,	best estimator xgboost's best error=9.0812
[flaml.automl: 09-23 04:43:22] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 04:43:22] {3072} INFO -  at 2.2s,	estimator xgboost's best error=9.0812,	best estimator xgboost's best error=9.0812
[flaml.automl: 09-23 04:43:22] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 04:43:23] {3072} INFO -  at 3.1s,	estimator xgboost's best error=8.7906,	best estimator xgboost's best error=8.7906
[flaml.automl: 09-23 04:43:23] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 04:43:23] {3072} INFO -  at 3.1s,	estimator xgboost's best error=8.7906,	best estimator xgboost's best error=8.7906
[flaml.automl: 09-23 04:43:23] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 04:43:23] {3072} INFO -  at 3.9s,	estimator xgboost's best error=8.7906,	best estimator xgboost's best error=8.7906
[flaml.automl: 09-23 04:43:23] {2897} INFO - iteration 24, current learner xgboost
[flaml.automl: 09-23 04:43:24] {3072} INFO -  at 4.1s,	estimator xgboost's best error=8.7906,	best estimator xgboost's best error=8.7906
[flaml.automl: 09-23 04:43:24] {2897} INFO - iteration 25, current learner xgboost
[flaml.automl: 09-23 04:43:24] {3072} INFO -  at 4.2s,	estimator xgboost's best error=8.7906,	best estimator xgboost's best error=8.7906
[flaml.automl: 09-23 04:43:24] {2897} INFO - iteration 26, current learner xgboost
[flaml.automl: 09-23 04:43:24] {3072} INFO -  at 4.8s,	estimator xgboost's best error=8.6416,	best estimator xgboost's best error=8.6416
[flaml.automl: 09-23 04:43:24] {2897} INFO - iteration 27, current learner xgboost
[flaml.automl: 09-23 04:44:23] {3072} INFO -  at 63.3s,	estimator xgboost's best error=8.3011,	best estimator xgboost's best error=8.3011
[flaml.automl: 09-23 04:45:16] {3335} INFO - retrain xgboost for 53.5s
[flaml.automl: 09-23 04:45:16] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.8760638167990876, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.15192531481309424,
             max_delta_step=0, max_depth=0, max_leaves=79,
             min_child_weight=0.1574173674782873, missing=nan,
             monotone_constraints='()', n_estimators=13, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.007956966588637563, scale_pos_weight=1,
             subsample=0.8612609659679528, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 04:45:16] {2636} INFO - fit succeeded
[flaml.automl: 09-23 04:45:16] {2637} INFO - Time taken to find the best model: 63.29438138008118
[flaml.automl: 09-23 04:45:16] {2648} WARNING - Time taken to find the best model is 105% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
PM10(0)最佳参数：{'n_estimators': 57, 'max_leaves': 79, 'min_child_weight': 0.1574173674782873, 'learning_rate': 0.15192531481309424, 'subsample': 0.8612609659679528, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8760638167990876, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.007956966588637563, 'FLAML_sample_size': 123387}
PM10(0)最佳损失：-7.301144977923643
PM10(0)最好结果：{'pred_time': 3.041097667424197e-06, 'wall_clock_time': 63.29438138008118, 'metric_for_logging': {'pred_time': 3.041097667424197e-06}, 'val_loss': 8.301144977923643, 'training_iteration': 1, 'config': {'n_estimators': 57, 'max_leaves': 79, 'min_child_weight': 0.1574173674782873, 'learning_rate': 0.15192531481309424, 'subsample': 0.8612609659679528, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8760638167990876, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.007956966588637563, 'FLAML_sample_size': 123387}, 'config/n_estimators': 57, 'config/max_leaves': 79, 'config/min_child_weight': 0.1574173674782873, 'config/learning_rate': 0.15192531481309424, 'config/subsample': 0.8612609659679528, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.8760638167990876, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.007956966588637563, 'config/FLAML_sample_size': 123387, 'experiment_tag': 'exp', 'time_total_s': 58.50074005126953}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.8760638167990876, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.15192531481309424,
             max_delta_step=0, max_depth=0, max_leaves=79,
             min_child_weight=0.1574173674782873, missing=nan,
             monotone_constraints='()', n_estimators=13, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.007956966588637563, scale_pos_weight=1,
             subsample=0.8612609659679528, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.8340002190677719
PM10(0)的mse=316.44653942598814
PM10(0)的mae=11.682150750419092
PM10(0)的mar=0.19578670910086016
总共花费的时间为：118.43
石家庄市
1030A
1032A
1033A
1035A
2862A
3456A
3572A
3573A
3574A
[flaml.automl: 09-23 05:06:50] {2390} INFO - task = regression
[flaml.automl: 09-23 05:06:50] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 05:06:50] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 05:06:50] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 05:06:50] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 05:06:50] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 05:06:52] {3025} INFO - Estimated sufficient time budget=109996s. Estimated necessary time budget=110s.
[flaml.automl: 09-23 05:06:52] {3072} INFO -  at 1.5s,	estimator xgboost's best error=56.9034,	best estimator xgboost's best error=56.9034
[flaml.automl: 09-23 05:06:52] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 05:06:54] {3072} INFO -  at 3.5s,	estimator xgboost's best error=26.9344,	best estimator xgboost's best error=26.9344
[flaml.automl: 09-23 05:06:54] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 05:06:55] {3072} INFO -  at 4.6s,	estimator xgboost's best error=26.9344,	best estimator xgboost's best error=26.9344
[flaml.automl: 09-23 05:06:55] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 05:06:57] {3072} INFO -  at 7.1s,	estimator xgboost's best error=26.9344,	best estimator xgboost's best error=26.9344
[flaml.automl: 09-23 05:06:57] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 05:06:58] {3072} INFO -  at 8.2s,	estimator xgboost's best error=19.7975,	best estimator xgboost's best error=19.7975
[flaml.automl: 09-23 05:06:58] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 05:07:00] {3072} INFO -  at 9.7s,	estimator xgboost's best error=16.2601,	best estimator xgboost's best error=16.2601
[flaml.automl: 09-23 05:07:00] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 05:07:01] {3072} INFO -  at 11.2s,	estimator xgboost's best error=15.1534,	best estimator xgboost's best error=15.1534
[flaml.automl: 09-23 05:07:01] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 05:07:03] {3072} INFO -  at 12.6s,	estimator xgboost's best error=15.1534,	best estimator xgboost's best error=15.1534
[flaml.automl: 09-23 05:07:03] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 05:07:04] {3072} INFO -  at 14.1s,	estimator xgboost's best error=15.1534,	best estimator xgboost's best error=15.1534
[flaml.automl: 09-23 05:07:04] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 05:07:06] {3072} INFO -  at 16.1s,	estimator xgboost's best error=15.1534,	best estimator xgboost's best error=15.1534
[flaml.automl: 09-23 05:07:06] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 05:07:07] {3072} INFO -  at 17.4s,	estimator xgboost's best error=15.1534,	best estimator xgboost's best error=15.1534
[flaml.automl: 09-23 05:07:07] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 05:07:08] {3072} INFO -  at 17.6s,	estimator xgboost's best error=14.9290,	best estimator xgboost's best error=14.9290
[flaml.automl: 09-23 05:07:08] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 05:07:08] {3072} INFO -  at 17.7s,	estimator xgboost's best error=14.9290,	best estimator xgboost's best error=14.9290
[flaml.automl: 09-23 05:07:08] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 05:07:09] {3072} INFO -  at 18.7s,	estimator xgboost's best error=11.1643,	best estimator xgboost's best error=11.1643
[flaml.automl: 09-23 05:07:09] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 05:07:09] {3072} INFO -  at 18.9s,	estimator xgboost's best error=10.9564,	best estimator xgboost's best error=10.9564
[flaml.automl: 09-23 05:07:09] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 05:07:09] {3072} INFO -  at 19.2s,	estimator xgboost's best error=10.9564,	best estimator xgboost's best error=10.9564
[flaml.automl: 09-23 05:07:09] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 05:07:11] {3072} INFO -  at 20.5s,	estimator xgboost's best error=10.9564,	best estimator xgboost's best error=10.9564
[flaml.automl: 09-23 05:07:11] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 05:07:11] {3072} INFO -  at 20.7s,	estimator xgboost's best error=10.9564,	best estimator xgboost's best error=10.9564
[flaml.automl: 09-23 05:07:11] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 05:07:11] {3072} INFO -  at 21.3s,	estimator xgboost's best error=10.9564,	best estimator xgboost's best error=10.9564
[flaml.automl: 09-23 05:07:11] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 05:07:12] {3072} INFO -  at 21.7s,	estimator xgboost's best error=10.9564,	best estimator xgboost's best error=10.9564
[flaml.automl: 09-23 05:07:12] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 05:07:12] {3072} INFO -  at 21.9s,	estimator xgboost's best error=10.9564,	best estimator xgboost's best error=10.9564
[flaml.automl: 09-23 05:07:12] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 05:07:12] {3072} INFO -  at 22.2s,	estimator xgboost's best error=10.9564,	best estimator xgboost's best error=10.9564
[flaml.automl: 09-23 05:07:12] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 05:07:14] {3072} INFO -  at 23.6s,	estimator xgboost's best error=10.6803,	best estimator xgboost's best error=10.6803
[flaml.automl: 09-23 05:07:14] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 05:07:14] {3072} INFO -  at 23.8s,	estimator xgboost's best error=10.6803,	best estimator xgboost's best error=10.6803
[flaml.automl: 09-23 05:07:14] {2897} INFO - iteration 24, current learner xgboost
[flaml.automl: 09-23 05:07:15] {3072} INFO -  at 25.0s,	estimator xgboost's best error=10.6803,	best estimator xgboost's best error=10.6803
[flaml.automl: 09-23 05:07:15] {2897} INFO - iteration 25, current learner xgboost
[flaml.automl: 09-23 05:07:15] {3072} INFO -  at 25.4s,	estimator xgboost's best error=10.6803,	best estimator xgboost's best error=10.6803
[flaml.automl: 09-23 05:07:15] {2897} INFO - iteration 26, current learner xgboost
[flaml.automl: 09-23 05:07:16] {3072} INFO -  at 25.6s,	estimator xgboost's best error=10.6803,	best estimator xgboost's best error=10.6803
[flaml.automl: 09-23 05:07:16] {2897} INFO - iteration 27, current learner xgboost
[flaml.automl: 09-23 05:07:18] {3072} INFO -  at 28.1s,	estimator xgboost's best error=10.6803,	best estimator xgboost's best error=10.6803
[flaml.automl: 09-23 05:07:18] {2897} INFO - iteration 28, current learner xgboost
[flaml.automl: 09-23 05:07:20] {3072} INFO -  at 29.8s,	estimator xgboost's best error=10.6803,	best estimator xgboost's best error=10.6803
[flaml.automl: 09-23 05:07:20] {2897} INFO - iteration 29, current learner xgboost
[flaml.automl: 09-23 05:07:20] {3072} INFO -  at 30.3s,	estimator xgboost's best error=10.6803,	best estimator xgboost's best error=10.6803
[flaml.automl: 09-23 05:07:20] {2897} INFO - iteration 30, current learner xgboost
[flaml.automl: 09-23 05:07:51] {3072} INFO -  at 60.9s,	estimator xgboost's best error=10.6803,	best estimator xgboost's best error=10.6803
[flaml.automl: 09-23 05:08:44] {3335} INFO - retrain xgboost for 53.6s
[flaml.automl: 09-23 05:08:44] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.854235328728148, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.32574645181965844,
             max_delta_step=0, max_depth=0, max_leaves=13,
             min_child_weight=0.4144266683421042, missing=nan,
             monotone_constraints='()', n_estimators=79, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.004076555569395179, scale_pos_weight=1,
             subsample=0.9201135836766717, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 05:08:44] {2636} INFO - fit succeeded
[flaml.automl: 09-23 05:08:44] {2637} INFO - Time taken to find the best model: 23.598478317260742
PM10(0)最佳参数：{'n_estimators': 79, 'max_leaves': 13, 'min_child_weight': 0.4144266683421042, 'learning_rate': 0.32574645181965844, 'subsample': 0.9201135836766717, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.854235328728148, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.004076555569395179, 'FLAML_sample_size': 95871}
PM10(0)最佳损失：-9.680347522032672
PM10(0)最好结果：{'pred_time': 5.514087066464185e-07, 'wall_clock_time': 23.598478317260742, 'metric_for_logging': {'pred_time': 5.514087066464185e-07}, 'val_loss': 10.680347522032672, 'training_iteration': 1, 'config': {'n_estimators': 79, 'max_leaves': 13, 'min_child_weight': 0.4144266683421042, 'learning_rate': 0.32574645181965844, 'subsample': 0.9201135836766717, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.854235328728148, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.004076555569395179, 'FLAML_sample_size': 95871}, 'config/n_estimators': 79, 'config/max_leaves': 13, 'config/min_child_weight': 0.4144266683421042, 'config/learning_rate': 0.32574645181965844, 'config/subsample': 0.9201135836766717, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.854235328728148, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.004076555569395179, 'config/FLAML_sample_size': 95871, 'experiment_tag': 'exp', 'time_total_s': 1.3853588104248047}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.854235328728148, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.32574645181965844,
             max_delta_step=0, max_depth=0, max_leaves=13,
             min_child_weight=0.4144266683421042, missing=nan,
             monotone_constraints='()', n_estimators=79, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.004076555569395179, scale_pos_weight=1,
             subsample=0.9201135836766717, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.9179839008774967
PM10(0)的mse=261.684066432
PM10(0)的mae=10.611961250300341
PM10(0)的mar=0.1538032776053923
总共花费的时间为：115.75
唐山市
1041A
3575A
3576A
3577A
3578A
3692A
[flaml.automl: 09-23 05:23:44] {2390} INFO - task = regression
[flaml.automl: 09-23 05:23:44] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 05:23:44] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 05:23:44] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 05:23:44] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 05:23:44] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 05:23:45] {3025} INFO - Estimated sufficient time budget=67067s. Estimated necessary time budget=67s.
[flaml.automl: 09-23 05:23:45] {3072} INFO -  at 1.3s,	estimator xgboost's best error=50.9789,	best estimator xgboost's best error=50.9789
[flaml.automl: 09-23 05:23:45] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 05:23:47] {3072} INFO -  at 3.3s,	estimator xgboost's best error=24.5612,	best estimator xgboost's best error=24.5612
[flaml.automl: 09-23 05:23:47] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 05:23:48] {3072} INFO -  at 4.4s,	estimator xgboost's best error=24.5612,	best estimator xgboost's best error=24.5612
[flaml.automl: 09-23 05:23:48] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 05:23:52] {3072} INFO -  at 8.5s,	estimator xgboost's best error=24.5612,	best estimator xgboost's best error=24.5612
[flaml.automl: 09-23 05:23:52] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 05:23:53] {3072} INFO -  at 9.0s,	estimator xgboost's best error=16.8049,	best estimator xgboost's best error=16.8049
[flaml.automl: 09-23 05:23:53] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 05:23:55] {3072} INFO -  at 10.5s,	estimator xgboost's best error=15.8312,	best estimator xgboost's best error=15.8312
[flaml.automl: 09-23 05:23:55] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 05:23:56] {3072} INFO -  at 11.9s,	estimator xgboost's best error=13.7757,	best estimator xgboost's best error=13.7757
[flaml.automl: 09-23 05:23:56] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 05:23:58] {3072} INFO -  at 14.4s,	estimator xgboost's best error=13.7757,	best estimator xgboost's best error=13.7757
[flaml.automl: 09-23 05:23:58] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 05:24:00] {3072} INFO -  at 15.9s,	estimator xgboost's best error=13.7757,	best estimator xgboost's best error=13.7757
[flaml.automl: 09-23 05:24:00] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 05:24:01] {3072} INFO -  at 16.8s,	estimator xgboost's best error=13.4158,	best estimator xgboost's best error=13.4158
[flaml.automl: 09-23 05:24:01] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 05:24:01] {3072} INFO -  at 16.8s,	estimator xgboost's best error=13.4158,	best estimator xgboost's best error=13.4158
[flaml.automl: 09-23 05:24:01] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 05:24:01] {3072} INFO -  at 16.8s,	estimator xgboost's best error=13.4158,	best estimator xgboost's best error=13.4158
[flaml.automl: 09-23 05:24:01] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 05:24:01] {3072} INFO -  at 16.9s,	estimator xgboost's best error=12.3345,	best estimator xgboost's best error=12.3345
[flaml.automl: 09-23 05:24:01] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 05:24:01] {3072} INFO -  at 17.1s,	estimator xgboost's best error=11.7323,	best estimator xgboost's best error=11.7323
[flaml.automl: 09-23 05:24:01] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 05:24:02] {3072} INFO -  at 18.2s,	estimator xgboost's best error=11.7323,	best estimator xgboost's best error=11.7323
[flaml.automl: 09-23 05:24:02] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 05:24:02] {3072} INFO -  at 18.4s,	estimator xgboost's best error=11.7323,	best estimator xgboost's best error=11.7323
[flaml.automl: 09-23 05:24:02] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 05:24:03] {3072} INFO -  at 18.5s,	estimator xgboost's best error=11.7323,	best estimator xgboost's best error=11.7323
[flaml.automl: 09-23 05:24:03] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 05:24:03] {3072} INFO -  at 19.1s,	estimator xgboost's best error=11.5413,	best estimator xgboost's best error=11.5413
[flaml.automl: 09-23 05:24:03] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 05:24:03] {3072} INFO -  at 19.2s,	estimator xgboost's best error=11.5413,	best estimator xgboost's best error=11.5413
[flaml.automl: 09-23 05:24:03] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 05:24:03] {3072} INFO -  at 19.3s,	estimator xgboost's best error=11.5413,	best estimator xgboost's best error=11.5413
[flaml.automl: 09-23 05:24:03] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 05:24:04] {3072} INFO -  at 19.7s,	estimator xgboost's best error=11.5413,	best estimator xgboost's best error=11.5413
[flaml.automl: 09-23 05:24:04] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 05:24:04] {3072} INFO -  at 19.9s,	estimator xgboost's best error=11.3154,	best estimator xgboost's best error=11.3154
[flaml.automl: 09-23 05:24:04] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 05:24:04] {3072} INFO -  at 20.1s,	estimator xgboost's best error=11.3154,	best estimator xgboost's best error=11.3154
[flaml.automl: 09-23 05:24:04] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 05:24:05] {3072} INFO -  at 20.7s,	estimator xgboost's best error=11.3154,	best estimator xgboost's best error=11.3154
[flaml.automl: 09-23 05:24:05] {2897} INFO - iteration 24, current learner xgboost
[flaml.automl: 09-23 05:24:05] {3072} INFO -  at 21.2s,	estimator xgboost's best error=11.3154,	best estimator xgboost's best error=11.3154
[flaml.automl: 09-23 05:24:05] {2897} INFO - iteration 25, current learner xgboost
[flaml.automl: 09-23 05:24:05] {3072} INFO -  at 21.3s,	estimator xgboost's best error=11.3154,	best estimator xgboost's best error=11.3154
[flaml.automl: 09-23 05:24:05] {2897} INFO - iteration 26, current learner xgboost
[flaml.automl: 09-23 05:24:06] {3072} INFO -  at 21.8s,	estimator xgboost's best error=11.2375,	best estimator xgboost's best error=11.2375
[flaml.automl: 09-23 05:24:06] {2897} INFO - iteration 27, current learner xgboost
[flaml.automl: 09-23 05:24:44] {3072} INFO -  at 60.4s,	estimator xgboost's best error=11.2375,	best estimator xgboost's best error=11.2375
[flaml.automl: 09-23 05:25:21] {3335} INFO - retrain xgboost for 36.5s
[flaml.automl: 09-23 05:25:21] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9071731209990146, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.08250552244126755,
             max_delta_step=0, max_depth=0, max_leaves=9,
             min_child_weight=0.057873934461007526, missing=nan,
             monotone_constraints='()', n_estimators=77, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.0033897000104921803, scale_pos_weight=1,
             subsample=0.7675050216867961, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 05:25:21] {2636} INFO - fit succeeded
[flaml.automl: 09-23 05:25:21] {2637} INFO - Time taken to find the best model: 21.79518699645996
PM10(0)最佳参数：{'n_estimators': 77, 'max_leaves': 9, 'min_child_weight': 0.057873934461007526, 'learning_rate': 0.08250552244126755, 'subsample': 0.7675050216867961, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9071731209990146, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0033897000104921803, 'FLAML_sample_size': 60075}
PM10(0)最佳损失：-10.237498349097763
PM10(0)最好结果：{'pred_time': 5.76761541715134e-07, 'wall_clock_time': 21.79518699645996, 'metric_for_logging': {'pred_time': 5.76761541715134e-07}, 'val_loss': 11.237498349097763, 'training_iteration': 1, 'config': {'n_estimators': 77, 'max_leaves': 9, 'min_child_weight': 0.057873934461007526, 'learning_rate': 0.08250552244126755, 'subsample': 0.7675050216867961, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9071731209990146, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0033897000104921803, 'FLAML_sample_size': 60075}, 'config/n_estimators': 77, 'config/max_leaves': 9, 'config/min_child_weight': 0.057873934461007526, 'config/learning_rate': 0.08250552244126755, 'config/subsample': 0.7675050216867961, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9071731209990146, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.0033897000104921803, 'config/FLAML_sample_size': 60075, 'experiment_tag': 'exp', 'time_total_s': 0.5048563480377197}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9071731209990146, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.08250552244126755,
             max_delta_step=0, max_depth=0, max_leaves=9,
             min_child_weight=0.057873934461007526, missing=nan,
             monotone_constraints='()', n_estimators=77, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.0033897000104921803, scale_pos_weight=1,
             subsample=0.7675050216867961, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.9029651083026174
PM10(0)的mse=276.6285966896494
PM10(0)的mae=11.40077045109453
PM10(0)的mar=0.22508492059148294
总共花费的时间为：97.89
秦皇岛市
1043A
1044A
3132A
[flaml.automl: 09-23 05:32:48] {2390} INFO - task = regression
[flaml.automl: 09-23 05:32:48] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 05:32:48] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 05:32:48] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 05:32:48] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 05:32:48] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 05:32:48] {3025} INFO - Estimated sufficient time budget=2310s. Estimated necessary time budget=2s.
[flaml.automl: 09-23 05:32:48] {3072} INFO -  at 0.3s,	estimator xgboost's best error=39.4227,	best estimator xgboost's best error=39.4227
[flaml.automl: 09-23 05:32:48] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 05:32:48] {3072} INFO -  at 0.4s,	estimator xgboost's best error=18.7408,	best estimator xgboost's best error=18.7408
[flaml.automl: 09-23 05:32:48] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 05:32:49] {3072} INFO -  at 0.4s,	estimator xgboost's best error=18.7408,	best estimator xgboost's best error=18.7408
[flaml.automl: 09-23 05:32:49] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 05:32:49] {3072} INFO -  at 0.6s,	estimator xgboost's best error=18.7408,	best estimator xgboost's best error=18.7408
[flaml.automl: 09-23 05:32:49] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 05:32:49] {3072} INFO -  at 0.6s,	estimator xgboost's best error=13.9162,	best estimator xgboost's best error=13.9162
[flaml.automl: 09-23 05:32:49] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 05:32:49] {3072} INFO -  at 0.9s,	estimator xgboost's best error=11.3907,	best estimator xgboost's best error=11.3907
[flaml.automl: 09-23 05:32:49] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 05:32:49] {3072} INFO -  at 0.9s,	estimator xgboost's best error=10.8844,	best estimator xgboost's best error=10.8844
[flaml.automl: 09-23 05:32:49] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 05:32:49] {3072} INFO -  at 1.0s,	estimator xgboost's best error=10.8844,	best estimator xgboost's best error=10.8844
[flaml.automl: 09-23 05:32:49] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 05:32:49] {3072} INFO -  at 1.0s,	estimator xgboost's best error=10.8844,	best estimator xgboost's best error=10.8844
[flaml.automl: 09-23 05:32:49] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 05:32:49] {3072} INFO -  at 1.1s,	estimator xgboost's best error=10.1141,	best estimator xgboost's best error=10.1141
[flaml.automl: 09-23 05:32:49] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 05:32:49] {3072} INFO -  at 1.1s,	estimator xgboost's best error=10.1141,	best estimator xgboost's best error=10.1141
[flaml.automl: 09-23 05:32:49] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 05:32:49] {3072} INFO -  at 1.2s,	estimator xgboost's best error=10.1141,	best estimator xgboost's best error=10.1141
[flaml.automl: 09-23 05:32:49] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 05:32:49] {3072} INFO -  at 1.3s,	estimator xgboost's best error=8.5227,	best estimator xgboost's best error=8.5227
[flaml.automl: 09-23 05:32:49] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 05:32:50] {3072} INFO -  at 1.5s,	estimator xgboost's best error=8.0406,	best estimator xgboost's best error=8.0406
[flaml.automl: 09-23 05:32:50] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 05:32:50] {3072} INFO -  at 1.6s,	estimator xgboost's best error=8.0406,	best estimator xgboost's best error=8.0406
[flaml.automl: 09-23 05:32:50] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 05:32:50] {3072} INFO -  at 1.9s,	estimator xgboost's best error=8.0406,	best estimator xgboost's best error=8.0406
[flaml.automl: 09-23 05:32:50] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 05:32:50] {3072} INFO -  at 2.0s,	estimator xgboost's best error=8.0406,	best estimator xgboost's best error=8.0406
[flaml.automl: 09-23 05:32:50] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 05:32:50] {3072} INFO -  at 2.2s,	estimator xgboost's best error=8.0406,	best estimator xgboost's best error=8.0406
[flaml.automl: 09-23 05:32:50] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 05:32:51] {3072} INFO -  at 2.5s,	estimator xgboost's best error=8.0406,	best estimator xgboost's best error=8.0406
[flaml.automl: 09-23 05:32:51] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 05:32:51] {3072} INFO -  at 2.7s,	estimator xgboost's best error=8.0406,	best estimator xgboost's best error=8.0406
[flaml.automl: 09-23 05:32:51] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 05:32:51] {3072} INFO -  at 3.0s,	estimator xgboost's best error=8.0406,	best estimator xgboost's best error=8.0406
[flaml.automl: 09-23 05:32:51] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 05:32:52] {3072} INFO -  at 3.5s,	estimator xgboost's best error=7.9959,	best estimator xgboost's best error=7.9959
[flaml.automl: 09-23 05:32:52] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 05:32:52] {3072} INFO -  at 3.7s,	estimator xgboost's best error=7.9959,	best estimator xgboost's best error=7.9959
[flaml.automl: 09-23 05:32:52] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 05:32:54] {3072} INFO -  at 5.8s,	estimator xgboost's best error=7.9959,	best estimator xgboost's best error=7.9959
[flaml.automl: 09-23 05:32:54] {2897} INFO - iteration 24, current learner xgboost
[flaml.automl: 09-23 05:32:54] {3072} INFO -  at 6.1s,	estimator xgboost's best error=7.9959,	best estimator xgboost's best error=7.9959
[flaml.automl: 09-23 05:32:54] {2897} INFO - iteration 25, current learner xgboost
[flaml.automl: 09-23 05:32:54] {3072} INFO -  at 6.3s,	estimator xgboost's best error=7.9959,	best estimator xgboost's best error=7.9959
[flaml.automl: 09-23 05:32:54] {2897} INFO - iteration 26, current learner xgboost
[flaml.automl: 09-23 05:33:48] {3072} INFO -  at 60.2s,	estimator xgboost's best error=7.9959,	best estimator xgboost's best error=7.9959
[flaml.automl: 09-23 05:34:47] {3335} INFO - retrain xgboost for 58.9s
[flaml.automl: 09-23 05:34:47] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.8887712781640978, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.2668750112003922,
             max_delta_step=0, max_depth=0, max_leaves=22,
             min_child_weight=0.020043815319299642, missing=nan,
             monotone_constraints='()', n_estimators=51, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.002579071746643704, scale_pos_weight=1,
             subsample=0.8306436401058418, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 05:34:47] {2636} INFO - fit succeeded
[flaml.automl: 09-23 05:34:47] {2637} INFO - Time taken to find the best model: 3.5418972969055176
PM10(0)最佳参数：{'n_estimators': 89, 'max_leaves': 22, 'min_child_weight': 0.020043815319299642, 'learning_rate': 0.2668750112003922, 'subsample': 0.8306436401058418, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8887712781640978, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.002579071746643704}
PM10(0)最佳损失：-6.995852369648369
PM10(0)最好结果：{'pred_time': 1.0026571715511081e-06, 'wall_clock_time': 3.5418972969055176, 'metric_for_logging': {'pred_time': 1.0026571715511081e-06}, 'val_loss': 7.995852369648369, 'training_iteration': 1, 'config': {'n_estimators': 89, 'max_leaves': 22, 'min_child_weight': 0.020043815319299642, 'learning_rate': 0.2668750112003922, 'subsample': 0.8306436401058418, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8887712781640978, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.002579071746643704}, 'config/n_estimators': 89, 'config/max_leaves': 22, 'config/min_child_weight': 0.020043815319299642, 'config/learning_rate': 0.2668750112003922, 'config/subsample': 0.8306436401058418, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.8887712781640978, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.002579071746643704, 'experiment_tag': 'exp', 'time_total_s': 0.5771605968475342}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.8887712781640978, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.2668750112003922,
             max_delta_step=0, max_depth=0, max_leaves=22,
             min_child_weight=0.020043815319299642, missing=nan,
             monotone_constraints='()', n_estimators=51, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.002579071746643704, scale_pos_weight=1,
             subsample=0.8306436401058418, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.9115857022054146
PM10(0)的mse=149.01909985498307
PM10(0)的mae=7.763964773864784
PM10(0)的mar=0.15455390349610953
总共花费的时间为：119.61
邯郸市
1050A
3579A
3580A
[flaml.automl: 09-23 05:42:03] {2390} INFO - task = regression
[flaml.automl: 09-23 05:42:03] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 05:42:03] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 05:42:03] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 05:42:03] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 05:42:03] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 05:42:04] {3025} INFO - Estimated sufficient time budget=11206s. Estimated necessary time budget=11s.
[flaml.automl: 09-23 05:42:04] {3072} INFO -  at 1.2s,	estimator xgboost's best error=53.5262,	best estimator xgboost's best error=53.5262
[flaml.automl: 09-23 05:42:04] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 05:42:06] {3072} INFO -  at 3.2s,	estimator xgboost's best error=25.2397,	best estimator xgboost's best error=25.2397
[flaml.automl: 09-23 05:42:06] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 05:42:07] {3072} INFO -  at 4.3s,	estimator xgboost's best error=25.2397,	best estimator xgboost's best error=25.2397
[flaml.automl: 09-23 05:42:07] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 05:42:17] {3072} INFO -  at 13.7s,	estimator xgboost's best error=25.2397,	best estimator xgboost's best error=25.2397
[flaml.automl: 09-23 05:42:17] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 05:42:18] {3072} INFO -  at 14.8s,	estimator xgboost's best error=18.1172,	best estimator xgboost's best error=18.1172
[flaml.automl: 09-23 05:42:18] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 05:42:19] {3072} INFO -  at 16.4s,	estimator xgboost's best error=18.1172,	best estimator xgboost's best error=18.1172
[flaml.automl: 09-23 05:42:19] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 05:42:21] {3072} INFO -  at 18.0s,	estimator xgboost's best error=11.9693,	best estimator xgboost's best error=11.9693
[flaml.automl: 09-23 05:42:21] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 05:42:23] {3072} INFO -  at 20.5s,	estimator xgboost's best error=11.9693,	best estimator xgboost's best error=11.9693
[flaml.automl: 09-23 05:42:23] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 05:42:25] {3072} INFO -  at 22.0s,	estimator xgboost's best error=11.9693,	best estimator xgboost's best error=11.9693
[flaml.automl: 09-23 05:42:25] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 05:42:28] {3072} INFO -  at 24.8s,	estimator xgboost's best error=11.9693,	best estimator xgboost's best error=11.9693
[flaml.automl: 09-23 05:42:28] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 05:42:29] {3072} INFO -  at 26.2s,	estimator xgboost's best error=11.9693,	best estimator xgboost's best error=11.9693
[flaml.automl: 09-23 05:42:29] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 05:42:30] {3072} INFO -  at 27.3s,	estimator xgboost's best error=11.9693,	best estimator xgboost's best error=11.9693
[flaml.automl: 09-23 05:42:30] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 05:42:37] {3072} INFO -  at 33.9s,	estimator xgboost's best error=10.2812,	best estimator xgboost's best error=10.2812
[flaml.automl: 09-23 05:42:37] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 05:42:49] {3072} INFO -  at 46.0s,	estimator xgboost's best error=10.0784,	best estimator xgboost's best error=10.0784
[flaml.automl: 09-23 05:42:49] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 05:42:55] {3072} INFO -  at 52.6s,	estimator xgboost's best error=10.0784,	best estimator xgboost's best error=10.0784
[flaml.automl: 09-23 05:43:07] {3335} INFO - retrain xgboost for 12.0s
[flaml.automl: 09-23 05:43:07] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 05:43:07] {2636} INFO - fit succeeded
[flaml.automl: 09-23 05:43:07] {2637} INFO - Time taken to find the best model: 45.96683955192566
[flaml.automl: 09-23 05:43:07] {2648} WARNING - Time taken to find the best model is 77% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
PM10(0)最佳参数：{'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649}
PM10(0)最佳损失：-9.078394939507767
PM10(0)最好结果：{'pred_time': 9.997340018365747e-06, 'wall_clock_time': 45.96683955192566, 'metric_for_logging': {'pred_time': 9.997340018365747e-06}, 'val_loss': 10.078394939507767, 'training_iteration': 1, 'config': {'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649}, 'config/n_estimators': 31, 'config/max_leaves': 7, 'config/min_child_weight': 0.6186300892591503, 'config/learning_rate': 0.48254477352294606, 'config/subsample': 0.8921566499079494, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9831203893408513, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.011522990442748649, 'experiment_tag': 'exp', 'time_total_s': 12.077999114990234}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.9111699780252467
PM10(0)的mse=229.23595973647966
PM10(0)的mae=10.122046554536933
PM10(0)的mar=0.17309469085490686
总共花费的时间为：65.01
保定市
1051A
1053A
1054A
1055A
1056A
3581A
3582A
3583A
[flaml.automl: 09-23 06:01:52] {2390} INFO - task = regression
[flaml.automl: 09-23 06:01:52] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 06:01:52] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 06:01:52] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 06:01:52] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 06:01:52] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 06:01:53] {3025} INFO - Estimated sufficient time budget=95334s. Estimated necessary time budget=95s.
[flaml.automl: 09-23 06:01:53] {3072} INFO -  at 1.4s,	estimator xgboost's best error=52.9801,	best estimator xgboost's best error=52.9801
[flaml.automl: 09-23 06:01:53] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 06:01:55] {3072} INFO -  at 3.5s,	estimator xgboost's best error=25.3478,	best estimator xgboost's best error=25.3478
[flaml.automl: 09-23 06:01:55] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 06:01:56] {3072} INFO -  at 4.6s,	estimator xgboost's best error=25.3478,	best estimator xgboost's best error=25.3478
[flaml.automl: 09-23 06:01:56] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 06:01:59] {3072} INFO -  at 7.7s,	estimator xgboost's best error=25.3478,	best estimator xgboost's best error=25.3478
[flaml.automl: 09-23 06:01:59] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 06:02:00] {3072} INFO -  at 8.7s,	estimator xgboost's best error=19.2384,	best estimator xgboost's best error=19.2384
[flaml.automl: 09-23 06:02:00] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 06:02:01] {3072} INFO -  at 10.2s,	estimator xgboost's best error=15.9394,	best estimator xgboost's best error=15.9394
[flaml.automl: 09-23 06:02:01] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 06:02:03] {3072} INFO -  at 11.7s,	estimator xgboost's best error=14.7735,	best estimator xgboost's best error=14.7735
[flaml.automl: 09-23 06:02:03] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 06:02:05] {3072} INFO -  at 14.2s,	estimator xgboost's best error=14.7735,	best estimator xgboost's best error=14.7735
[flaml.automl: 09-23 06:02:05] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 06:02:07] {3072} INFO -  at 15.8s,	estimator xgboost's best error=14.7735,	best estimator xgboost's best error=14.7735
[flaml.automl: 09-23 06:02:07] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 06:02:09] {3072} INFO -  at 18.2s,	estimator xgboost's best error=13.9961,	best estimator xgboost's best error=13.9961
[flaml.automl: 09-23 06:02:09] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 06:02:11] {3072} INFO -  at 19.8s,	estimator xgboost's best error=13.9961,	best estimator xgboost's best error=13.9961
[flaml.automl: 09-23 06:02:11] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 06:02:12] {3072} INFO -  at 20.8s,	estimator xgboost's best error=13.9961,	best estimator xgboost's best error=13.9961
[flaml.automl: 09-23 06:02:12] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 06:02:14] {3072} INFO -  at 22.7s,	estimator xgboost's best error=12.8929,	best estimator xgboost's best error=12.8929
[flaml.automl: 09-23 06:02:14] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 06:02:16] {3072} INFO -  at 24.7s,	estimator xgboost's best error=12.8929,	best estimator xgboost's best error=12.8929
[flaml.automl: 09-23 06:02:16] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 06:02:17] {3072} INFO -  at 26.0s,	estimator xgboost's best error=12.6674,	best estimator xgboost's best error=12.6674
[flaml.automl: 09-23 06:02:17] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 06:02:19] {3072} INFO -  at 28.1s,	estimator xgboost's best error=12.6674,	best estimator xgboost's best error=12.6674
[flaml.automl: 09-23 06:02:19] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 06:02:21] {3072} INFO -  at 29.5s,	estimator xgboost's best error=12.6674,	best estimator xgboost's best error=12.6674
[flaml.automl: 09-23 06:02:21] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 06:02:22] {3072} INFO -  at 31.2s,	estimator xgboost's best error=12.6674,	best estimator xgboost's best error=12.6674
[flaml.automl: 09-23 06:02:22] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 06:02:25] {3072} INFO -  at 33.8s,	estimator xgboost's best error=12.6674,	best estimator xgboost's best error=12.6674
[flaml.automl: 09-23 06:02:25] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 06:02:32] {3072} INFO -  at 40.7s,	estimator xgboost's best error=12.2798,	best estimator xgboost's best error=12.2798
[flaml.automl: 09-23 06:02:32] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 06:02:34] {3072} INFO -  at 43.2s,	estimator xgboost's best error=12.2798,	best estimator xgboost's best error=12.2798
[flaml.automl: 09-23 06:02:34] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 06:02:50] {3072} INFO -  at 58.4s,	estimator xgboost's best error=11.8000,	best estimator xgboost's best error=11.8000
[flaml.automl: 09-23 06:03:01] {3335} INFO - retrain xgboost for 11.4s
[flaml.automl: 09-23 06:03:01] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.7869551594064775, colsample_bynode=1,
             colsample_bytree=0.7933397443475808, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=1.0, max_delta_step=0,
             max_depth=0, max_leaves=41, min_child_weight=0.009416638758491828,
             missing=nan, monotone_constraints='()', n_estimators=10, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.009169417918441369, reg_lambda=0.1716204668378346,
             scale_pos_weight=1, subsample=1.0, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 06:03:01] {2636} INFO - fit succeeded
[flaml.automl: 09-23 06:03:01] {2637} INFO - Time taken to find the best model: 58.43380808830261
[flaml.automl: 09-23 06:03:01] {2648} WARNING - Time taken to find the best model is 97% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
PM10(0)最佳参数：{'n_estimators': 10, 'max_leaves': 41, 'min_child_weight': 0.009416638758491828, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.7869551594064775, 'colsample_bytree': 0.7933397443475808, 'reg_alpha': 0.009169417918441369, 'reg_lambda': 0.1716204668378346, 'FLAML_sample_size': 85590}
PM10(0)最佳损失：-10.799997815022834
PM10(0)最好结果：{'pred_time': 4.186163941392387e-06, 'wall_clock_time': 58.43380808830261, 'metric_for_logging': {'pred_time': 4.186163941392387e-06}, 'val_loss': 11.799997815022834, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_leaves': 41, 'min_child_weight': 0.009416638758491828, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.7869551594064775, 'colsample_bytree': 0.7933397443475808, 'reg_alpha': 0.009169417918441369, 'reg_lambda': 0.1716204668378346, 'FLAML_sample_size': 85590}, 'config/n_estimators': 10, 'config/max_leaves': 41, 'config/min_child_weight': 0.009416638758491828, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.7869551594064775, 'config/colsample_bytree': 0.7933397443475808, 'config/reg_alpha': 0.009169417918441369, 'config/reg_lambda': 0.1716204668378346, 'config/FLAML_sample_size': 85590, 'experiment_tag': 'exp', 'time_total_s': 15.184828281402588}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.7869551594064775, colsample_bynode=1,
             colsample_bytree=0.7933397443475808, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=1.0, max_delta_step=0,
             max_depth=0, max_leaves=41, min_child_weight=0.009416638758491828,
             missing=nan, monotone_constraints='()', n_estimators=10, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.009169417918441369, reg_lambda=0.1716204668378346,
             scale_pos_weight=1, subsample=1.0, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.8846158712826362
PM10(0)的mse=292.81981797663786
PM10(0)的mae=11.496202523462186
PM10(0)的mar=0.1876947001933013
总共花费的时间为：70.93
张家口市
1060A
1061A
3131A
3323A
[flaml.automl: 09-23 06:12:57] {2390} INFO - task = regression
[flaml.automl: 09-23 06:12:57] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 06:12:57] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 06:12:57] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 06:12:57] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 06:12:57] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 06:12:58] {3025} INFO - Estimated sufficient time budget=47616s. Estimated necessary time budget=48s.
[flaml.automl: 09-23 06:12:58] {3072} INFO -  at 1.3s,	estimator xgboost's best error=33.1362,	best estimator xgboost's best error=33.1362
[flaml.automl: 09-23 06:12:58] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 06:13:00] {3072} INFO -  at 3.2s,	estimator xgboost's best error=17.6229,	best estimator xgboost's best error=17.6229
[flaml.automl: 09-23 06:13:00] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 06:13:01] {3072} INFO -  at 4.4s,	estimator xgboost's best error=17.6229,	best estimator xgboost's best error=17.6229
[flaml.automl: 09-23 06:13:01] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 06:13:08] {3072} INFO -  at 10.8s,	estimator xgboost's best error=17.6229,	best estimator xgboost's best error=17.6229
[flaml.automl: 09-23 06:13:08] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 06:13:09] {3072} INFO -  at 11.9s,	estimator xgboost's best error=14.4662,	best estimator xgboost's best error=14.4662
[flaml.automl: 09-23 06:13:09] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 06:13:10] {3072} INFO -  at 13.4s,	estimator xgboost's best error=14.4662,	best estimator xgboost's best error=14.4662
[flaml.automl: 09-23 06:13:10] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 06:13:12] {3072} INFO -  at 14.8s,	estimator xgboost's best error=11.6645,	best estimator xgboost's best error=11.6645
[flaml.automl: 09-23 06:13:12] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 06:13:14] {3072} INFO -  at 17.2s,	estimator xgboost's best error=11.6645,	best estimator xgboost's best error=11.6645
[flaml.automl: 09-23 06:13:14] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 06:13:16] {3072} INFO -  at 18.8s,	estimator xgboost's best error=11.6645,	best estimator xgboost's best error=11.6645
[flaml.automl: 09-23 06:13:16] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 06:13:18] {3072} INFO -  at 21.6s,	estimator xgboost's best error=11.6645,	best estimator xgboost's best error=11.6645
[flaml.automl: 09-23 06:13:18] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 06:13:20] {3072} INFO -  at 22.9s,	estimator xgboost's best error=11.6645,	best estimator xgboost's best error=11.6645
[flaml.automl: 09-23 06:13:20] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 06:13:21] {3072} INFO -  at 24.5s,	estimator xgboost's best error=11.2657,	best estimator xgboost's best error=11.2657
[flaml.automl: 09-23 06:13:21] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 06:13:22] {3072} INFO -  at 25.6s,	estimator xgboost's best error=11.2657,	best estimator xgboost's best error=11.2657
[flaml.automl: 09-23 06:13:22] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 06:13:23] {3072} INFO -  at 26.1s,	estimator xgboost's best error=10.7785,	best estimator xgboost's best error=10.7785
[flaml.automl: 09-23 06:13:23] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 06:13:23] {3072} INFO -  at 26.2s,	estimator xgboost's best error=10.5529,	best estimator xgboost's best error=10.5529
[flaml.automl: 09-23 06:13:23] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 06:13:23] {3072} INFO -  at 26.3s,	estimator xgboost's best error=10.5529,	best estimator xgboost's best error=10.5529
[flaml.automl: 09-23 06:13:23] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 06:13:24] {3072} INFO -  at 27.5s,	estimator xgboost's best error=10.5529,	best estimator xgboost's best error=10.5529
[flaml.automl: 09-23 06:13:24] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 06:13:24] {3072} INFO -  at 27.6s,	estimator xgboost's best error=10.5529,	best estimator xgboost's best error=10.5529
[flaml.automl: 09-23 06:13:24] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 06:13:25] {3072} INFO -  at 27.8s,	estimator xgboost's best error=10.5529,	best estimator xgboost's best error=10.5529
[flaml.automl: 09-23 06:13:25] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 06:13:25] {3072} INFO -  at 28.7s,	estimator xgboost's best error=10.5529,	best estimator xgboost's best error=10.5529
[flaml.automl: 09-23 06:13:25] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 06:13:26] {3072} INFO -  at 28.8s,	estimator xgboost's best error=10.5529,	best estimator xgboost's best error=10.5529
[flaml.automl: 09-23 06:13:26] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 06:13:26] {3072} INFO -  at 29.4s,	estimator xgboost's best error=10.5529,	best estimator xgboost's best error=10.5529
[flaml.automl: 09-23 06:13:26] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 06:13:27] {3072} INFO -  at 29.8s,	estimator xgboost's best error=10.4698,	best estimator xgboost's best error=10.4698
[flaml.automl: 09-23 06:13:27] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 06:13:27] {3072} INFO -  at 29.9s,	estimator xgboost's best error=10.4698,	best estimator xgboost's best error=10.4698
[flaml.automl: 09-23 06:13:27] {2897} INFO - iteration 24, current learner xgboost
[flaml.automl: 09-23 06:13:28] {3072} INFO -  at 30.9s,	estimator xgboost's best error=10.4698,	best estimator xgboost's best error=10.4698
[flaml.automl: 09-23 06:13:28] {2897} INFO - iteration 25, current learner xgboost
[flaml.automl: 09-23 06:13:28] {3072} INFO -  at 31.3s,	estimator xgboost's best error=10.3907,	best estimator xgboost's best error=10.3907
[flaml.automl: 09-23 06:13:28] {2897} INFO - iteration 26, current learner xgboost
[flaml.automl: 09-23 06:13:28] {3072} INFO -  at 31.4s,	estimator xgboost's best error=10.3907,	best estimator xgboost's best error=10.3907
[flaml.automl: 09-23 06:13:28] {2897} INFO - iteration 27, current learner xgboost
[flaml.automl: 09-23 06:13:29] {3072} INFO -  at 31.9s,	estimator xgboost's best error=10.3375,	best estimator xgboost's best error=10.3375
[flaml.automl: 09-23 06:13:29] {2897} INFO - iteration 28, current learner xgboost
[flaml.automl: 09-23 06:14:04] {3072} INFO -  at 66.8s,	estimator xgboost's best error=10.3375,	best estimator xgboost's best error=10.3375
[flaml.automl: 09-23 06:14:57] {3335} INFO - retrain xgboost for 53.1s
[flaml.automl: 09-23 06:14:57] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.9810093405091559, colsample_bynode=1,
             colsample_bytree=0.9734771013030347, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.22854813715314864,
             max_delta_step=0, max_depth=0, max_leaves=17,
             min_child_weight=14.568527157383746, missing=nan,
             monotone_constraints='()', n_estimators=59, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.10948612945352608,
             reg_lambda=0.0032706974315770423, scale_pos_weight=1,
             subsample=0.8351597898934683, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 06:14:57] {2636} INFO - fit succeeded
[flaml.automl: 09-23 06:14:57] {2637} INFO - Time taken to find the best model: 31.891674995422363
PM10(0)最佳参数：{'n_estimators': 106, 'max_leaves': 17, 'min_child_weight': 14.568527157383746, 'learning_rate': 0.22854813715314864, 'subsample': 0.8351597898934683, 'colsample_bylevel': 0.9810093405091559, 'colsample_bytree': 0.9734771013030347, 'reg_alpha': 0.10948612945352608, 'reg_lambda': 0.0032706974315770423, 'FLAML_sample_size': 41716}
PM10(0)最佳损失：-9.337501503790731
PM10(0)最好结果：{'pred_time': 8.905211638746023e-07, 'wall_clock_time': 31.891674995422363, 'metric_for_logging': {'pred_time': 8.905211638746023e-07}, 'val_loss': 10.337501503790731, 'training_iteration': 1, 'config': {'n_estimators': 106, 'max_leaves': 17, 'min_child_weight': 14.568527157383746, 'learning_rate': 0.22854813715314864, 'subsample': 0.8351597898934683, 'colsample_bylevel': 0.9810093405091559, 'colsample_bytree': 0.9734771013030347, 'reg_alpha': 0.10948612945352608, 'reg_lambda': 0.0032706974315770423, 'FLAML_sample_size': 41716}, 'config/n_estimators': 106, 'config/max_leaves': 17, 'config/min_child_weight': 14.568527157383746, 'config/learning_rate': 0.22854813715314864, 'config/subsample': 0.8351597898934683, 'config/colsample_bylevel': 0.9810093405091559, 'config/colsample_bytree': 0.9734771013030347, 'config/reg_alpha': 0.10948612945352608, 'config/reg_lambda': 0.0032706974315770423, 'config/FLAML_sample_size': 41716, 'experiment_tag': 'exp', 'time_total_s': 0.5250990390777588}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.9810093405091559, colsample_bynode=1,
             colsample_bytree=0.9734771013030347, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.22854813715314864,
             max_delta_step=0, max_depth=0, max_leaves=17,
             min_child_weight=14.568527157383746, missing=nan,
             monotone_constraints='()', n_estimators=59, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.10948612945352608,
             reg_lambda=0.0032706974315770423, scale_pos_weight=1,
             subsample=0.8351597898934683, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.8385825412068734
PM10(0)的mse=359.9527328675172
PM10(0)的mae=10.410514034500078
PM10(0)的mar=0.3416536882713667
总共花费的时间为：120.41
承德市
1063A
1064A
1065A
[flaml.automl: 09-23 06:22:05] {2390} INFO - task = regression
[flaml.automl: 09-23 06:22:05] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 06:22:05] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 06:22:05] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 06:22:05] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 06:22:05] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 06:22:06] {3025} INFO - Estimated sufficient time budget=6263s. Estimated necessary time budget=6s.
[flaml.automl: 09-23 06:22:06] {3072} INFO -  at 0.7s,	estimator xgboost's best error=35.0080,	best estimator xgboost's best error=35.0080
[flaml.automl: 09-23 06:22:06] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 06:22:08] {3072} INFO -  at 2.7s,	estimator xgboost's best error=17.2478,	best estimator xgboost's best error=17.2478
[flaml.automl: 09-23 06:22:08] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 06:22:09] {3072} INFO -  at 3.9s,	estimator xgboost's best error=17.2478,	best estimator xgboost's best error=17.2478
[flaml.automl: 09-23 06:22:09] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 06:22:13] {3072} INFO -  at 8.5s,	estimator xgboost's best error=17.2478,	best estimator xgboost's best error=17.2478
[flaml.automl: 09-23 06:22:13] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 06:22:15] {3072} INFO -  at 9.6s,	estimator xgboost's best error=12.0533,	best estimator xgboost's best error=12.0533
[flaml.automl: 09-23 06:22:15] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 06:22:16] {3072} INFO -  at 11.1s,	estimator xgboost's best error=12.0533,	best estimator xgboost's best error=12.0533
[flaml.automl: 09-23 06:22:16] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 06:22:18] {3072} INFO -  at 12.7s,	estimator xgboost's best error=9.3820,	best estimator xgboost's best error=9.3820
[flaml.automl: 09-23 06:22:18] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 06:22:20] {3072} INFO -  at 15.2s,	estimator xgboost's best error=9.3820,	best estimator xgboost's best error=9.3820
[flaml.automl: 09-23 06:22:20] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 06:22:22] {3072} INFO -  at 16.8s,	estimator xgboost's best error=9.3820,	best estimator xgboost's best error=9.3820
[flaml.automl: 09-23 06:22:22] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 06:22:25] {3072} INFO -  at 19.6s,	estimator xgboost's best error=9.3820,	best estimator xgboost's best error=9.3820
[flaml.automl: 09-23 06:22:25] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 06:22:26] {3072} INFO -  at 20.9s,	estimator xgboost's best error=9.3820,	best estimator xgboost's best error=9.3820
[flaml.automl: 09-23 06:22:26] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 06:22:27] {3072} INFO -  at 22.0s,	estimator xgboost's best error=9.3820,	best estimator xgboost's best error=9.3820
[flaml.automl: 09-23 06:22:27] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 06:22:34] {3072} INFO -  at 28.6s,	estimator xgboost's best error=8.4463,	best estimator xgboost's best error=8.4463
[flaml.automl: 09-23 06:22:34] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 06:22:46] {3072} INFO -  at 40.7s,	estimator xgboost's best error=8.2290,	best estimator xgboost's best error=8.2290
[flaml.automl: 09-23 06:22:46] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 06:22:52] {3072} INFO -  at 47.3s,	estimator xgboost's best error=8.2290,	best estimator xgboost's best error=8.2290
[flaml.automl: 09-23 06:22:52] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 06:23:05] {3072} INFO -  at 59.6s,	estimator xgboost's best error=8.2290,	best estimator xgboost's best error=8.2290
[flaml.automl: 09-23 06:23:17] {3335} INFO - retrain xgboost for 11.9s
[flaml.automl: 09-23 06:23:17] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 06:23:17] {2636} INFO - fit succeeded
[flaml.automl: 09-23 06:23:17] {2637} INFO - Time taken to find the best model: 40.67598342895508
PM10(0)最佳参数：{'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649}
PM10(0)最佳损失：-7.228976846957359
PM10(0)最好结果：{'pred_time': 1.0617284824738398e-05, 'wall_clock_time': 40.67598342895508, 'metric_for_logging': {'pred_time': 1.0617284824738398e-05}, 'val_loss': 8.228976846957359, 'training_iteration': 1, 'config': {'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649}, 'config/n_estimators': 31, 'config/max_leaves': 7, 'config/min_child_weight': 0.6186300892591503, 'config/learning_rate': 0.48254477352294606, 'config/subsample': 0.8921566499079494, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9831203893408513, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.011522990442748649, 'experiment_tag': 'exp', 'time_total_s': 12.03290843963623}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.8561641085423878
PM10(0)的mse=201.80806848169442
PM10(0)的mae=8.36749303964905
PM10(0)的mar=0.23881105040370557
总共花费的时间为：71.98
廊坊市
1070A
2919A
[flaml.automl: 09-23 06:28:30] {2390} INFO - task = regression
[flaml.automl: 09-23 06:28:30] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 06:28:30] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 06:28:30] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 06:28:30] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 06:28:30] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 06:28:30] {3025} INFO - Estimated sufficient time budget=551s. Estimated necessary time budget=1s.
[flaml.automl: 09-23 06:28:30] {3072} INFO -  at 0.1s,	estimator xgboost's best error=46.3662,	best estimator xgboost's best error=46.3662
[flaml.automl: 09-23 06:28:30] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 1.5s,	estimator xgboost's best error=21.6787,	best estimator xgboost's best error=21.6787
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 1.6s,	estimator xgboost's best error=21.6787,	best estimator xgboost's best error=21.6787
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 1.6s,	estimator xgboost's best error=21.6787,	best estimator xgboost's best error=21.6787
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 1.7s,	estimator xgboost's best error=14.1660,	best estimator xgboost's best error=14.1660
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 1.8s,	estimator xgboost's best error=14.1660,	best estimator xgboost's best error=14.1660
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 1.8s,	estimator xgboost's best error=10.8913,	best estimator xgboost's best error=10.8913
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 2.1s,	estimator xgboost's best error=10.8913,	best estimator xgboost's best error=10.8913
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 2.1s,	estimator xgboost's best error=10.8913,	best estimator xgboost's best error=10.8913
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 2.2s,	estimator xgboost's best error=10.8913,	best estimator xgboost's best error=10.8913
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 2.2s,	estimator xgboost's best error=10.7456,	best estimator xgboost's best error=10.7456
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 2.3s,	estimator xgboost's best error=10.7456,	best estimator xgboost's best error=10.7456
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 06:28:32] {3072} INFO -  at 2.3s,	estimator xgboost's best error=10.0208,	best estimator xgboost's best error=10.0208
[flaml.automl: 09-23 06:28:32] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 06:28:33] {3072} INFO -  at 2.9s,	estimator xgboost's best error=9.6510,	best estimator xgboost's best error=9.6510
[flaml.automl: 09-23 06:28:33] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 06:28:33] {3072} INFO -  at 3.0s,	estimator xgboost's best error=9.6510,	best estimator xgboost's best error=9.6510
[flaml.automl: 09-23 06:28:33] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 06:28:33] {3072} INFO -  at 3.1s,	estimator xgboost's best error=9.6510,	best estimator xgboost's best error=9.6510
[flaml.automl: 09-23 06:28:33] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 06:28:33] {3072} INFO -  at 3.2s,	estimator xgboost's best error=9.6510,	best estimator xgboost's best error=9.6510
[flaml.automl: 09-23 06:28:33] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 06:28:34] {3072} INFO -  at 3.8s,	estimator xgboost's best error=9.6510,	best estimator xgboost's best error=9.6510
[flaml.automl: 09-23 06:28:34] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 06:28:34] {3072} INFO -  at 3.9s,	estimator xgboost's best error=9.6510,	best estimator xgboost's best error=9.6510
[flaml.automl: 09-23 06:28:34] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 06:28:34] {3072} INFO -  at 4.0s,	estimator xgboost's best error=9.6510,	best estimator xgboost's best error=9.6510
[flaml.automl: 09-23 06:28:34] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 06:28:35] {3072} INFO -  at 4.5s,	estimator xgboost's best error=9.6510,	best estimator xgboost's best error=9.6510
[flaml.automl: 09-23 06:28:35] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 06:28:35] {3072} INFO -  at 4.8s,	estimator xgboost's best error=9.4303,	best estimator xgboost's best error=9.4303
[flaml.automl: 09-23 06:28:35] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 06:28:35] {3072} INFO -  at 4.9s,	estimator xgboost's best error=9.4303,	best estimator xgboost's best error=9.4303
[flaml.automl: 09-23 06:28:35] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 06:28:36] {3072} INFO -  at 5.5s,	estimator xgboost's best error=9.4303,	best estimator xgboost's best error=9.4303
[flaml.automl: 09-23 06:28:36] {2897} INFO - iteration 24, current learner xgboost
[flaml.automl: 09-23 06:28:36] {3072} INFO -  at 5.7s,	estimator xgboost's best error=9.4303,	best estimator xgboost's best error=9.4303
[flaml.automl: 09-23 06:28:36] {2897} INFO - iteration 25, current learner xgboost
[flaml.automl: 09-23 06:28:36] {3072} INFO -  at 5.8s,	estimator xgboost's best error=9.4303,	best estimator xgboost's best error=9.4303
[flaml.automl: 09-23 06:28:36] {2897} INFO - iteration 26, current learner xgboost
[flaml.automl: 09-23 06:29:32] {3072} INFO -  at 61.5s,	estimator xgboost's best error=9.4303,	best estimator xgboost's best error=9.4303
[flaml.automl: 09-23 06:30:17] {3335} INFO - retrain xgboost for 45.9s
[flaml.automl: 09-23 06:30:17] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.8847573016342755, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.32574645181965844,
             max_delta_step=0, max_depth=0, max_leaves=13,
             min_child_weight=16.77893167663663, missing=nan,
             monotone_constraints='()', n_estimators=66, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.0011659783776181629, scale_pos_weight=1,
             subsample=0.9206503952902233, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 06:30:17] {2636} INFO - fit succeeded
[flaml.automl: 09-23 06:30:17] {2637} INFO - Time taken to find the best model: 4.754860877990723
PM10(0)最佳参数：{'n_estimators': 66, 'max_leaves': 13, 'min_child_weight': 16.77893167663663, 'learning_rate': 0.32574645181965844, 'subsample': 0.9206503952902233, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8847573016342755, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0011659783776181629}
PM10(0)最佳损失：-8.430321600388508
PM10(0)最好结果：{'pred_time': 1.5021927502690529e-05, 'wall_clock_time': 4.754860877990723, 'metric_for_logging': {'pred_time': 1.5021927502690529e-05}, 'val_loss': 9.430321600388508, 'training_iteration': 1, 'config': {'n_estimators': 66, 'max_leaves': 13, 'min_child_weight': 16.77893167663663, 'learning_rate': 0.32574645181965844, 'subsample': 0.9206503952902233, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8847573016342755, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0011659783776181629}, 'config/n_estimators': 66, 'config/max_leaves': 13, 'config/min_child_weight': 16.77893167663663, 'config/learning_rate': 0.32574645181965844, 'config/subsample': 0.9206503952902233, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.8847573016342755, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.0011659783776181629, 'experiment_tag': 'exp', 'time_total_s': 0.2969791889190674}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.8847573016342755, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.32574645181965844,
             max_delta_step=0, max_depth=0, max_leaves=13,
             min_child_weight=16.77893167663663, missing=nan,
             monotone_constraints='()', n_estimators=66, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.0011659783776181629, scale_pos_weight=1,
             subsample=0.9206503952902233, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.9313640688626608
PM10(0)的mse=181.33387143223305
PM10(0)的mae=9.243980955324306
PM10(0)的mar=0.1929025281510301
总共花费的时间为：107.71
沧州市
1071A
1073A
3324A
[flaml.automl: 09-23 06:37:12] {2390} INFO - task = regression
[flaml.automl: 09-23 06:37:12] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 06:37:12] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 06:37:12] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 06:37:12] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 06:37:12] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 06:37:13] {3025} INFO - Estimated sufficient time budget=11311s. Estimated necessary time budget=11s.
[flaml.automl: 09-23 06:37:13] {3072} INFO -  at 1.2s,	estimator xgboost's best error=44.8709,	best estimator xgboost's best error=44.8709
[flaml.automl: 09-23 06:37:13] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 06:37:15] {3072} INFO -  at 3.3s,	estimator xgboost's best error=21.4175,	best estimator xgboost's best error=21.4175
[flaml.automl: 09-23 06:37:15] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 06:37:16] {3072} INFO -  at 4.4s,	estimator xgboost's best error=21.4175,	best estimator xgboost's best error=21.4175
[flaml.automl: 09-23 06:37:16] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 06:37:25] {3072} INFO -  at 13.7s,	estimator xgboost's best error=21.4175,	best estimator xgboost's best error=21.4175
[flaml.automl: 09-23 06:37:25] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 06:37:26] {3072} INFO -  at 14.8s,	estimator xgboost's best error=15.8620,	best estimator xgboost's best error=15.8620
[flaml.automl: 09-23 06:37:26] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 06:37:28] {3072} INFO -  at 16.3s,	estimator xgboost's best error=13.2114,	best estimator xgboost's best error=13.2114
[flaml.automl: 09-23 06:37:28] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 06:37:30] {3072} INFO -  at 17.8s,	estimator xgboost's best error=11.9819,	best estimator xgboost's best error=11.9819
[flaml.automl: 09-23 06:37:30] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 06:37:32] {3072} INFO -  at 20.4s,	estimator xgboost's best error=11.9819,	best estimator xgboost's best error=11.9819
[flaml.automl: 09-23 06:37:32] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 06:37:34] {3072} INFO -  at 21.9s,	estimator xgboost's best error=11.5966,	best estimator xgboost's best error=11.5966
[flaml.automl: 09-23 06:37:34] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 06:37:36] {3072} INFO -  at 24.8s,	estimator xgboost's best error=10.9923,	best estimator xgboost's best error=10.9923
[flaml.automl: 09-23 06:37:36] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 06:37:38] {3072} INFO -  at 25.8s,	estimator xgboost's best error=10.9923,	best estimator xgboost's best error=10.9923
[flaml.automl: 09-23 06:37:38] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 06:37:50] {3072} INFO -  at 38.6s,	estimator xgboost's best error=9.6380,	best estimator xgboost's best error=9.6380
[flaml.automl: 09-23 06:37:50] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 06:38:12] {3072} INFO -  at 59.8s,	estimator xgboost's best error=9.5466,	best estimator xgboost's best error=9.5466
[flaml.automl: 09-23 06:38:27] {3335} INFO - retrain xgboost for 15.7s
[flaml.automl: 09-23 06:38:27] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.948506134666318, colsample_bynode=1,
             colsample_bytree=0.8223167301060249, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5408133424638543,
             max_delta_step=0, max_depth=0, max_leaves=12,
             min_child_weight=0.006967902231194494, missing=nan,
             monotone_constraints='()', n_estimators=35, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.0038027739156058313, reg_lambda=0.5403518701157697,
             scale_pos_weight=1, subsample=0.7520708370056695,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
[flaml.automl: 09-23 06:38:27] {2636} INFO - fit succeeded
[flaml.automl: 09-23 06:38:27] {2637} INFO - Time taken to find the best model: 59.83064389228821
[flaml.automl: 09-23 06:38:27] {2648} WARNING - Time taken to find the best model is 100% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
PM10(0)最佳参数：{'n_estimators': 35, 'max_leaves': 12, 'min_child_weight': 0.006967902231194494, 'learning_rate': 0.5408133424638543, 'subsample': 0.7520708370056695, 'colsample_bylevel': 0.948506134666318, 'colsample_bytree': 0.8223167301060249, 'reg_alpha': 0.0038027739156058313, 'reg_lambda': 0.5403518701157697}
PM10(0)最佳损失：-8.54655849378403
PM10(0)最好结果：{'pred_time': 1.0742553292888485e-05, 'wall_clock_time': 59.83064389228821, 'metric_for_logging': {'pred_time': 1.0742553292888485e-05}, 'val_loss': 9.54655849378403, 'training_iteration': 1, 'config': {'n_estimators': 35, 'max_leaves': 12, 'min_child_weight': 0.006967902231194494, 'learning_rate': 0.5408133424638543, 'subsample': 0.7520708370056695, 'colsample_bylevel': 0.948506134666318, 'colsample_bytree': 0.8223167301060249, 'reg_alpha': 0.0038027739156058313, 'reg_lambda': 0.5403518701157697}, 'config/n_estimators': 35, 'config/max_leaves': 12, 'config/min_child_weight': 0.006967902231194494, 'config/learning_rate': 0.5408133424638543, 'config/subsample': 0.7520708370056695, 'config/colsample_bylevel': 0.948506134666318, 'config/colsample_bytree': 0.8223167301060249, 'config/reg_alpha': 0.0038027739156058313, 'config/reg_lambda': 0.5403518701157697, 'experiment_tag': 'exp', 'time_total_s': 21.25761389732361}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.948506134666318, colsample_bynode=1,
             colsample_bytree=0.8223167301060249, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5408133424638543,
             max_delta_step=0, max_depth=0, max_leaves=12,
             min_child_weight=0.006967902231194494, missing=nan,
             monotone_constraints='()', n_estimators=35, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.0038027739156058313, reg_lambda=0.5403518701157697,
             scale_pos_weight=1, subsample=0.7520708370056695,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
PM10(0)的R2=0.8938780859556674
PM10(0)的mse=220.2827273761914
PM10(0)的mae=9.47013668596524
PM10(0)的mar=0.17562491738938876
总共花费的时间为：76.00
衡水市
1074A
1075A
3188A
3459A
[flaml.automl: 09-23 06:48:23] {2390} INFO - task = regression
[flaml.automl: 09-23 06:48:23] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 06:48:23] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 06:48:23] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 06:48:23] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 06:48:23] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 06:48:24] {3025} INFO - Estimated sufficient time budget=50801s. Estimated necessary time budget=51s.
[flaml.automl: 09-23 06:48:24] {3072} INFO -  at 1.3s,	estimator xgboost's best error=47.1038,	best estimator xgboost's best error=47.1038
[flaml.automl: 09-23 06:48:24] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 06:48:24] {3072} INFO -  at 1.9s,	estimator xgboost's best error=22.3976,	best estimator xgboost's best error=22.3976
[flaml.automl: 09-23 06:48:24] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 06:48:25] {3072} INFO -  at 2.9s,	estimator xgboost's best error=22.3976,	best estimator xgboost's best error=22.3976
[flaml.automl: 09-23 06:48:25] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 06:48:31] {3072} INFO -  at 8.9s,	estimator xgboost's best error=22.3976,	best estimator xgboost's best error=22.3976
[flaml.automl: 09-23 06:48:31] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 06:48:33] {3072} INFO -  at 10.0s,	estimator xgboost's best error=16.1826,	best estimator xgboost's best error=16.1826
[flaml.automl: 09-23 06:48:33] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 06:48:34] {3072} INFO -  at 11.5s,	estimator xgboost's best error=16.1826,	best estimator xgboost's best error=16.1826
[flaml.automl: 09-23 06:48:34] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 06:48:36] {3072} INFO -  at 13.1s,	estimator xgboost's best error=10.9261,	best estimator xgboost's best error=10.9261
[flaml.automl: 09-23 06:48:36] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 06:48:38] {3072} INFO -  at 15.7s,	estimator xgboost's best error=10.9261,	best estimator xgboost's best error=10.9261
[flaml.automl: 09-23 06:48:38] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 06:48:40] {3072} INFO -  at 17.2s,	estimator xgboost's best error=10.9261,	best estimator xgboost's best error=10.9261
[flaml.automl: 09-23 06:48:40] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 06:48:42] {3072} INFO -  at 20.0s,	estimator xgboost's best error=10.9261,	best estimator xgboost's best error=10.9261
[flaml.automl: 09-23 06:48:42] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 06:48:44] {3072} INFO -  at 21.3s,	estimator xgboost's best error=10.9261,	best estimator xgboost's best error=10.9261
[flaml.automl: 09-23 06:48:44] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 06:48:45] {3072} INFO -  at 22.9s,	estimator xgboost's best error=10.9261,	best estimator xgboost's best error=10.9261
[flaml.automl: 09-23 06:48:45] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 06:48:47] {3072} INFO -  at 24.0s,	estimator xgboost's best error=10.9261,	best estimator xgboost's best error=10.9261
[flaml.automl: 09-23 06:48:47] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 06:48:53] {3072} INFO -  at 30.6s,	estimator xgboost's best error=9.5571,	best estimator xgboost's best error=9.5571
[flaml.automl: 09-23 06:48:53] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 06:49:05] {3072} INFO -  at 42.7s,	estimator xgboost's best error=9.3418,	best estimator xgboost's best error=9.3418
[flaml.automl: 09-23 06:49:05] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 06:49:12] {3072} INFO -  at 49.3s,	estimator xgboost's best error=9.3418,	best estimator xgboost's best error=9.3418
[flaml.automl: 09-23 06:49:24] {3335} INFO - retrain xgboost for 12.0s
[flaml.automl: 09-23 06:49:24] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 06:49:24] {2636} INFO - fit succeeded
[flaml.automl: 09-23 06:49:24] {2637} INFO - Time taken to find the best model: 42.65875244140625
[flaml.automl: 09-23 06:49:24] {2648} WARNING - Time taken to find the best model is 71% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
PM10(0)最佳参数：{'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 43596}
PM10(0)最佳损失：-8.341838344476324
PM10(0)最好结果：{'pred_time': 7.783795663091784e-06, 'wall_clock_time': 42.65875244140625, 'metric_for_logging': {'pred_time': 7.783795663091784e-06}, 'val_loss': 9.341838344476324, 'training_iteration': 1, 'config': {'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 43596}, 'config/n_estimators': 31, 'config/max_leaves': 7, 'config/min_child_weight': 0.6186300892591503, 'config/learning_rate': 0.48254477352294606, 'config/subsample': 0.8921566499079494, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9831203893408513, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.011522990442748649, 'config/FLAML_sample_size': 43596, 'experiment_tag': 'exp', 'time_total_s': 12.051801681518555}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.9084704440654384
PM10(0)的mse=190.73998979463423
PM10(0)的mae=9.198471858956303
PM10(0)的mar=0.18918863579565218
总共花费的时间为：61.76
邢台市
1078A
1079A
1080A
[flaml.automl: 09-23 06:56:28] {2390} INFO - task = regression
[flaml.automl: 09-23 06:56:28] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 06:56:28] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 06:56:28] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 06:56:28] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 06:56:28] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 06:56:29] {3025} INFO - Estimated sufficient time budget=11303s. Estimated necessary time budget=11s.
[flaml.automl: 09-23 06:56:29] {3072} INFO -  at 1.2s,	estimator xgboost's best error=52.7191,	best estimator xgboost's best error=52.7191
[flaml.automl: 09-23 06:56:29] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 06:56:31] {3072} INFO -  at 3.2s,	estimator xgboost's best error=24.6386,	best estimator xgboost's best error=24.6386
[flaml.automl: 09-23 06:56:31] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 06:56:33] {3072} INFO -  at 4.3s,	estimator xgboost's best error=24.6386,	best estimator xgboost's best error=24.6386
[flaml.automl: 09-23 06:56:33] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 06:56:42] {3072} INFO -  at 13.7s,	estimator xgboost's best error=24.6386,	best estimator xgboost's best error=24.6386
[flaml.automl: 09-23 06:56:42] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 06:56:43] {3072} INFO -  at 14.8s,	estimator xgboost's best error=17.2487,	best estimator xgboost's best error=17.2487
[flaml.automl: 09-23 06:56:43] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 06:56:44] {3072} INFO -  at 16.3s,	estimator xgboost's best error=14.1664,	best estimator xgboost's best error=14.1664
[flaml.automl: 09-23 06:56:44] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 06:56:46] {3072} INFO -  at 17.8s,	estimator xgboost's best error=13.4189,	best estimator xgboost's best error=13.4189
[flaml.automl: 09-23 06:56:46] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 06:56:48] {3072} INFO -  at 20.3s,	estimator xgboost's best error=13.4189,	best estimator xgboost's best error=13.4189
[flaml.automl: 09-23 06:56:48] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 06:56:50] {3072} INFO -  at 21.8s,	estimator xgboost's best error=12.2557,	best estimator xgboost's best error=12.2557
[flaml.automl: 09-23 06:56:50] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 06:56:53] {3072} INFO -  at 24.7s,	estimator xgboost's best error=11.5349,	best estimator xgboost's best error=11.5349
[flaml.automl: 09-23 06:56:53] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 06:56:54] {3072} INFO -  at 25.7s,	estimator xgboost's best error=11.5349,	best estimator xgboost's best error=11.5349
[flaml.automl: 09-23 06:56:54] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 06:57:07] {3072} INFO -  at 38.5s,	estimator xgboost's best error=10.2700,	best estimator xgboost's best error=10.2700
[flaml.automl: 09-23 06:57:07] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 06:57:28] {3072} INFO -  at 59.6s,	estimator xgboost's best error=10.0134,	best estimator xgboost's best error=10.0134
[flaml.automl: 09-23 06:57:46] {3335} INFO - retrain xgboost for 17.8s
[flaml.automl: 09-23 06:57:46] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.948506134666318, colsample_bynode=1,
             colsample_bytree=0.8223167301060249, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5408133424638543,
             max_delta_step=0, max_depth=0, max_leaves=12,
             min_child_weight=0.006967902231194494, missing=nan,
             monotone_constraints='()', n_estimators=35, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.0038027739156058313, reg_lambda=0.5403518701157697,
             scale_pos_weight=1, subsample=0.7520708370056695,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
[flaml.automl: 09-23 06:57:46] {2636} INFO - fit succeeded
[flaml.automl: 09-23 06:57:46] {2637} INFO - Time taken to find the best model: 59.64147663116455
[flaml.automl: 09-23 06:57:46] {2648} WARNING - Time taken to find the best model is 99% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
PM10(0)最佳参数：{'n_estimators': 35, 'max_leaves': 12, 'min_child_weight': 0.006967902231194494, 'learning_rate': 0.5408133424638543, 'subsample': 0.7520708370056695, 'colsample_bylevel': 0.948506134666318, 'colsample_bytree': 0.8223167301060249, 'reg_alpha': 0.0038027739156058313, 'reg_lambda': 0.5403518701157697}
PM10(0)最佳损失：-9.013393170930943
PM10(0)最好结果：{'pred_time': 1.0309238693453836e-05, 'wall_clock_time': 59.64147663116455, 'metric_for_logging': {'pred_time': 1.0309238693453836e-05}, 'val_loss': 10.013393170930943, 'training_iteration': 1, 'config': {'n_estimators': 35, 'max_leaves': 12, 'min_child_weight': 0.006967902231194494, 'learning_rate': 0.5408133424638543, 'subsample': 0.7520708370056695, 'colsample_bylevel': 0.948506134666318, 'colsample_bytree': 0.8223167301060249, 'reg_alpha': 0.0038027739156058313, 'reg_lambda': 0.5403518701157697}, 'config/n_estimators': 35, 'config/max_leaves': 12, 'config/min_child_weight': 0.006967902231194494, 'config/learning_rate': 0.5408133424638543, 'config/subsample': 0.7520708370056695, 'config/colsample_bylevel': 0.948506134666318, 'config/colsample_bytree': 0.8223167301060249, 'config/reg_alpha': 0.0038027739156058313, 'config/reg_lambda': 0.5403518701157697, 'experiment_tag': 'exp', 'time_total_s': 21.128648042678833}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.948506134666318, colsample_bynode=1,
             colsample_bytree=0.8223167301060249, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5408133424638543,
             max_delta_step=0, max_depth=0, max_leaves=12,
             min_child_weight=0.006967902231194494, missing=nan,
             monotone_constraints='()', n_estimators=35, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.0038027739156058313, reg_lambda=0.5403518701157697,
             scale_pos_weight=1, subsample=0.7520708370056695,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
PM10(0)的R2=0.924054707676351
PM10(0)的mse=208.2907188715416
PM10(0)的mae=9.934608490913835
PM10(0)的mar=0.16519321503309103
总共花费的时间为：77.86
太原市
1081A
1084A
1085A
1086A
1087A
3185A
[flaml.automl: 09-23 07:12:29] {2390} INFO - task = regression
[flaml.automl: 09-23 07:12:29] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 07:12:29] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 07:12:29] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 07:12:29] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 07:12:29] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 07:12:30] {3025} INFO - Estimated sufficient time budget=75009s. Estimated necessary time budget=75s.
[flaml.automl: 09-23 07:12:30] {3072} INFO -  at 1.4s,	estimator xgboost's best error=58.3169,	best estimator xgboost's best error=58.3169
[flaml.automl: 09-23 07:12:30] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 07:12:32] {3072} INFO -  at 3.3s,	estimator xgboost's best error=27.7359,	best estimator xgboost's best error=27.7359
[flaml.automl: 09-23 07:12:32] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 07:12:33] {3072} INFO -  at 4.5s,	estimator xgboost's best error=27.7359,	best estimator xgboost's best error=27.7359
[flaml.automl: 09-23 07:12:33] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 07:12:37] {3072} INFO -  at 8.5s,	estimator xgboost's best error=27.7359,	best estimator xgboost's best error=27.7359
[flaml.automl: 09-23 07:12:37] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 07:12:38] {3072} INFO -  at 9.6s,	estimator xgboost's best error=17.9288,	best estimator xgboost's best error=17.9288
[flaml.automl: 09-23 07:12:38] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 07:12:39] {3072} INFO -  at 10.6s,	estimator xgboost's best error=17.9288,	best estimator xgboost's best error=17.9288
[flaml.automl: 09-23 07:12:39] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 07:12:41] {3072} INFO -  at 12.2s,	estimator xgboost's best error=13.6204,	best estimator xgboost's best error=13.6204
[flaml.automl: 09-23 07:12:41] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 07:12:44] {3072} INFO -  at 14.7s,	estimator xgboost's best error=13.6204,	best estimator xgboost's best error=13.6204
[flaml.automl: 09-23 07:12:44] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 07:12:44] {3072} INFO -  at 15.6s,	estimator xgboost's best error=13.6204,	best estimator xgboost's best error=13.6204
[flaml.automl: 09-23 07:12:44] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 07:12:45] {3072} INFO -  at 15.7s,	estimator xgboost's best error=13.6204,	best estimator xgboost's best error=13.6204
[flaml.automl: 09-23 07:12:45] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 07:12:45] {3072} INFO -  at 15.7s,	estimator xgboost's best error=13.5653,	best estimator xgboost's best error=13.5653
[flaml.automl: 09-23 07:12:45] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 07:12:45] {3072} INFO -  at 15.7s,	estimator xgboost's best error=13.5653,	best estimator xgboost's best error=13.5653
[flaml.automl: 09-23 07:12:45] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 07:12:45] {3072} INFO -  at 15.7s,	estimator xgboost's best error=11.8805,	best estimator xgboost's best error=11.8805
[flaml.automl: 09-23 07:12:45] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 07:12:45] {3072} INFO -  at 15.8s,	estimator xgboost's best error=11.6125,	best estimator xgboost's best error=11.6125
[flaml.automl: 09-23 07:12:45] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 07:12:45] {3072} INFO -  at 15.9s,	estimator xgboost's best error=11.6125,	best estimator xgboost's best error=11.6125
[flaml.automl: 09-23 07:12:45] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 07:12:46] {3072} INFO -  at 16.8s,	estimator xgboost's best error=11.6125,	best estimator xgboost's best error=11.6125
[flaml.automl: 09-23 07:12:46] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 07:12:46] {3072} INFO -  at 16.8s,	estimator xgboost's best error=11.6125,	best estimator xgboost's best error=11.6125
[flaml.automl: 09-23 07:12:46] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 07:12:46] {3072} INFO -  at 16.9s,	estimator xgboost's best error=11.6125,	best estimator xgboost's best error=11.6125
[flaml.automl: 09-23 07:12:46] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 07:12:46] {3072} INFO -  at 17.2s,	estimator xgboost's best error=11.1036,	best estimator xgboost's best error=11.1036
[flaml.automl: 09-23 07:12:46] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 07:12:46] {3072} INFO -  at 17.3s,	estimator xgboost's best error=11.1036,	best estimator xgboost's best error=11.1036
[flaml.automl: 09-23 07:12:46] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 07:12:47] {3072} INFO -  at 17.7s,	estimator xgboost's best error=11.1036,	best estimator xgboost's best error=11.1036
[flaml.automl: 09-23 07:12:47] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 07:12:47] {3072} INFO -  at 18.1s,	estimator xgboost's best error=10.7558,	best estimator xgboost's best error=10.7558
[flaml.automl: 09-23 07:12:47] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 07:12:47] {3072} INFO -  at 18.3s,	estimator xgboost's best error=10.7558,	best estimator xgboost's best error=10.7558
[flaml.automl: 09-23 07:12:47] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 07:12:49] {3072} INFO -  at 20.1s,	estimator xgboost's best error=10.7558,	best estimator xgboost's best error=10.7558
[flaml.automl: 09-23 07:12:49] {2897} INFO - iteration 24, current learner xgboost
[flaml.automl: 09-23 07:12:49] {3072} INFO -  at 20.4s,	estimator xgboost's best error=10.7558,	best estimator xgboost's best error=10.7558
[flaml.automl: 09-23 07:12:49] {2897} INFO - iteration 25, current learner xgboost
[flaml.automl: 09-23 07:12:49] {3072} INFO -  at 20.6s,	estimator xgboost's best error=10.7558,	best estimator xgboost's best error=10.7558
[flaml.automl: 09-23 07:12:49] {2897} INFO - iteration 26, current learner xgboost
[flaml.automl: 09-23 07:12:52] {3072} INFO -  at 23.1s,	estimator xgboost's best error=10.5863,	best estimator xgboost's best error=10.5863
[flaml.automl: 09-23 07:12:52] {2897} INFO - iteration 27, current learner xgboost
[flaml.automl: 09-23 07:13:33] {3072} INFO -  at 64.3s,	estimator xgboost's best error=10.5863,	best estimator xgboost's best error=10.5863
[flaml.automl: 09-23 07:14:28] {3335} INFO - retrain xgboost for 55.3s
[flaml.automl: 09-23 07:14:28] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.9972944539306997, colsample_bynode=1,
             colsample_bytree=0.8582344029373101, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5624700060309398,
             max_delta_step=0, max_depth=0, max_leaves=44,
             min_child_weight=128.0, missing=nan, monotone_constraints='()',
             n_estimators=24, n_jobs=-1, num_parallel_tree=1, random_state=0,
             reg_alpha=0.007089621497907744, reg_lambda=0.0033793272635173712,
             scale_pos_weight=1, subsample=0.9150749711616197,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
[flaml.automl: 09-23 07:14:28] {2636} INFO - fit succeeded
[flaml.automl: 09-23 07:14:28] {2637} INFO - Time taken to find the best model: 23.083104848861694
PM10(0)最佳参数：{'n_estimators': 132, 'max_leaves': 44, 'min_child_weight': 128.0, 'learning_rate': 0.5624700060309398, 'subsample': 0.9150749711616197, 'colsample_bylevel': 0.9972944539306997, 'colsample_bytree': 0.8582344029373101, 'reg_alpha': 0.007089621497907744, 'reg_lambda': 0.0033793272635173712, 'FLAML_sample_size': 66576}
PM10(0)最佳损失：-9.586291797525595
PM10(0)最好结果：{'pred_time': 5.928817134381758e-06, 'wall_clock_time': 23.083104848861694, 'metric_for_logging': {'pred_time': 5.928817134381758e-06}, 'val_loss': 10.586291797525595, 'training_iteration': 1, 'config': {'n_estimators': 132, 'max_leaves': 44, 'min_child_weight': 128.0, 'learning_rate': 0.5624700060309398, 'subsample': 0.9150749711616197, 'colsample_bylevel': 0.9972944539306997, 'colsample_bytree': 0.8582344029373101, 'reg_alpha': 0.007089621497907744, 'reg_lambda': 0.0033793272635173712, 'FLAML_sample_size': 66576}, 'config/n_estimators': 132, 'config/max_leaves': 44, 'config/min_child_weight': 128.0, 'config/learning_rate': 0.5624700060309398, 'config/subsample': 0.9150749711616197, 'config/colsample_bylevel': 0.9972944539306997, 'config/colsample_bytree': 0.8582344029373101, 'config/reg_alpha': 0.007089621497907744, 'config/reg_lambda': 0.0033793272635173712, 'config/FLAML_sample_size': 66576, 'experiment_tag': 'exp', 'time_total_s': 2.4947941303253174}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.9972944539306997, colsample_bynode=1,
             colsample_bytree=0.8582344029373101, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5624700060309398,
             max_delta_step=0, max_depth=0, max_leaves=44,
             min_child_weight=128.0, missing=nan, monotone_constraints='()',
             n_estimators=24, n_jobs=-1, num_parallel_tree=1, random_state=0,
             reg_alpha=0.007089621497907744, reg_lambda=0.0033793272635173712,
             scale_pos_weight=1, subsample=0.9150749711616197,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
PM10(0)的R2=0.9032555145107622
PM10(0)的mse=296.83006844308545
PM10(0)的mae=10.923316206353425
PM10(0)的mar=0.15595434717061363
总共花费的时间为：120.47
呼和浩特市
1095A
1097A
3698A
3699A
[flaml.automl: 09-23 07:24:09] {2390} INFO - task = regression
[flaml.automl: 09-23 07:24:09] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 07:24:09] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 07:24:09] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 07:24:09] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 07:24:09] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 07:24:10] {3025} INFO - Estimated sufficient time budget=48998s. Estimated necessary time budget=49s.
[flaml.automl: 09-23 07:24:10] {3072} INFO -  at 1.3s,	estimator xgboost's best error=38.8200,	best estimator xgboost's best error=38.8200
[flaml.automl: 09-23 07:24:10] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 07:24:12] {3072} INFO -  at 3.2s,	estimator xgboost's best error=19.8351,	best estimator xgboost's best error=19.8351
[flaml.automl: 09-23 07:24:12] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 07:24:13] {3072} INFO -  at 4.3s,	estimator xgboost's best error=19.8351,	best estimator xgboost's best error=19.8351
[flaml.automl: 09-23 07:24:13] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 07:24:19] {3072} INFO -  at 10.2s,	estimator xgboost's best error=19.8351,	best estimator xgboost's best error=19.8351
[flaml.automl: 09-23 07:24:19] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 07:24:20] {3072} INFO -  at 11.3s,	estimator xgboost's best error=17.0147,	best estimator xgboost's best error=17.0147
[flaml.automl: 09-23 07:24:20] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 07:24:22] {3072} INFO -  at 12.8s,	estimator xgboost's best error=17.0147,	best estimator xgboost's best error=17.0147
[flaml.automl: 09-23 07:24:22] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 07:24:23] {3072} INFO -  at 14.4s,	estimator xgboost's best error=12.7397,	best estimator xgboost's best error=12.7397
[flaml.automl: 09-23 07:24:23] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 07:24:26] {3072} INFO -  at 16.9s,	estimator xgboost's best error=12.7397,	best estimator xgboost's best error=12.7397
[flaml.automl: 09-23 07:24:26] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 07:24:27] {3072} INFO -  at 18.4s,	estimator xgboost's best error=12.7397,	best estimator xgboost's best error=12.7397
[flaml.automl: 09-23 07:24:27] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 07:24:30] {3072} INFO -  at 21.3s,	estimator xgboost's best error=12.7397,	best estimator xgboost's best error=12.7397
[flaml.automl: 09-23 07:24:30] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 07:24:32] {3072} INFO -  at 22.6s,	estimator xgboost's best error=12.7397,	best estimator xgboost's best error=12.7397
[flaml.automl: 09-23 07:24:32] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 07:24:33] {3072} INFO -  at 24.2s,	estimator xgboost's best error=12.5093,	best estimator xgboost's best error=12.5093
[flaml.automl: 09-23 07:24:33] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 07:24:34] {3072} INFO -  at 25.3s,	estimator xgboost's best error=12.5093,	best estimator xgboost's best error=12.5093
[flaml.automl: 09-23 07:24:34] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 07:24:41] {3072} INFO -  at 31.9s,	estimator xgboost's best error=11.3947,	best estimator xgboost's best error=11.3947
[flaml.automl: 09-23 07:24:41] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 07:24:53] {3072} INFO -  at 43.9s,	estimator xgboost's best error=11.0798,	best estimator xgboost's best error=11.0798
[flaml.automl: 09-23 07:24:53] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 07:25:00] {3072} INFO -  at 50.6s,	estimator xgboost's best error=11.0798,	best estimator xgboost's best error=11.0798
[flaml.automl: 09-23 07:25:09] {3335} INFO - retrain xgboost for 8.9s
[flaml.automl: 09-23 07:25:09] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 07:25:09] {2636} INFO - fit succeeded
[flaml.automl: 09-23 07:25:09] {2637} INFO - Time taken to find the best model: 43.94226336479187
[flaml.automl: 09-23 07:25:09] {2648} WARNING - Time taken to find the best model is 73% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
PM10(0)最佳参数：{'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 43526}
PM10(0)最佳损失：-10.079822654243046
PM10(0)最好结果：{'pred_time': 8.139157802920117e-06, 'wall_clock_time': 43.94226336479187, 'metric_for_logging': {'pred_time': 8.139157802920117e-06}, 'val_loss': 11.079822654243046, 'training_iteration': 1, 'config': {'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 43526}, 'config/n_estimators': 31, 'config/max_leaves': 7, 'config/min_child_weight': 0.6186300892591503, 'config/learning_rate': 0.48254477352294606, 'config/subsample': 0.8921566499079494, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9831203893408513, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.011522990442748649, 'config/FLAML_sample_size': 43526, 'experiment_tag': 'exp', 'time_total_s': 12.073888540267944}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.8407643819918618
PM10(0)的mse=346.2526647834812
PM10(0)的mae=11.200424782086094
PM10(0)的mar=0.3022054393848766
总共花费的时间为：60.10
沈阳市
1098A
1099A
1100A
1104A
1105A
1106A
2900A
[flaml.automl: 09-23 07:41:58] {2390} INFO - task = regression
[flaml.automl: 09-23 07:41:58] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 07:41:58] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 07:41:58] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 07:41:58] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 07:41:58] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 07:41:59] {3025} INFO - Estimated sufficient time budget=84975s. Estimated necessary time budget=85s.
[flaml.automl: 09-23 07:41:59] {3072} INFO -  at 1.4s,	estimator xgboost's best error=36.2529,	best estimator xgboost's best error=36.2529
[flaml.automl: 09-23 07:41:59] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 07:42:01] {3072} INFO -  at 3.4s,	estimator xgboost's best error=17.1023,	best estimator xgboost's best error=17.1023
[flaml.automl: 09-23 07:42:01] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 07:42:02] {3072} INFO -  at 4.5s,	estimator xgboost's best error=17.1023,	best estimator xgboost's best error=17.1023
[flaml.automl: 09-23 07:42:02] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 07:42:05] {3072} INFO -  at 8.1s,	estimator xgboost's best error=17.1023,	best estimator xgboost's best error=17.1023
[flaml.automl: 09-23 07:42:05] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 07:42:06] {3072} INFO -  at 9.1s,	estimator xgboost's best error=12.9022,	best estimator xgboost's best error=12.9022
[flaml.automl: 09-23 07:42:06] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 07:42:08] {3072} INFO -  at 10.6s,	estimator xgboost's best error=12.9022,	best estimator xgboost's best error=12.9022
[flaml.automl: 09-23 07:42:08] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 07:42:10] {3072} INFO -  at 12.2s,	estimator xgboost's best error=8.5472,	best estimator xgboost's best error=8.5472
[flaml.automl: 09-23 07:42:10] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 07:42:12] {3072} INFO -  at 14.7s,	estimator xgboost's best error=8.5472,	best estimator xgboost's best error=8.5472
[flaml.automl: 09-23 07:42:12] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 07:42:14] {3072} INFO -  at 16.2s,	estimator xgboost's best error=8.5472,	best estimator xgboost's best error=8.5472
[flaml.automl: 09-23 07:42:14] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 07:42:16] {3072} INFO -  at 18.7s,	estimator xgboost's best error=8.5472,	best estimator xgboost's best error=8.5472
[flaml.automl: 09-23 07:42:16] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 07:42:17] {3072} INFO -  at 20.0s,	estimator xgboost's best error=8.5472,	best estimator xgboost's best error=8.5472
[flaml.automl: 09-23 07:42:17] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 07:42:19] {3072} INFO -  at 21.7s,	estimator xgboost's best error=8.5472,	best estimator xgboost's best error=8.5472
[flaml.automl: 09-23 07:42:19] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 07:42:20] {3072} INFO -  at 22.8s,	estimator xgboost's best error=8.5472,	best estimator xgboost's best error=8.5472
[flaml.automl: 09-23 07:42:20] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 07:42:26] {3072} INFO -  at 29.0s,	estimator xgboost's best error=7.4542,	best estimator xgboost's best error=7.4542
[flaml.automl: 09-23 07:42:26] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 07:42:38] {3072} INFO -  at 41.0s,	estimator xgboost's best error=7.3376,	best estimator xgboost's best error=7.3376
[flaml.automl: 09-23 07:42:38] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 07:42:45] {3072} INFO -  at 47.7s,	estimator xgboost's best error=7.3376,	best estimator xgboost's best error=7.3376
[flaml.automl: 09-23 07:42:45] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 07:42:57] {3072} INFO -  at 59.4s,	estimator xgboost's best error=7.3376,	best estimator xgboost's best error=7.3376
[flaml.automl: 09-23 07:43:09] {3335} INFO - retrain xgboost for 12.0s
[flaml.automl: 09-23 07:43:09] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 07:43:09] {2636} INFO - fit succeeded
[flaml.automl: 09-23 07:43:09] {2637} INFO - Time taken to find the best model: 41.01471972465515
PM10(0)最佳参数：{'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 75784}
PM10(0)最佳损失：-6.337610280651078
PM10(0)最好结果：{'pred_time': 4.252066961618461e-06, 'wall_clock_time': 41.01471972465515, 'metric_for_logging': {'pred_time': 4.252066961618461e-06}, 'val_loss': 7.337610280651078, 'training_iteration': 1, 'config': {'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 75784}, 'config/n_estimators': 31, 'config/max_leaves': 7, 'config/min_child_weight': 0.6186300892591503, 'config/learning_rate': 0.48254477352294606, 'config/subsample': 0.8921566499079494, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9831203893408513, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.011522990442748649, 'config/FLAML_sample_size': 75784, 'experiment_tag': 'exp', 'time_total_s': 11.973483800888062}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.8947366856291218
PM10(0)的mse=141.65459102936072
PM10(0)的mae=7.3921063660021025
PM10(0)的mar=0.14529465755151777
总共花费的时间为：72.43
大连市
1110A
1117A
[flaml.automl: 09-23 07:48:07] {2390} INFO - task = regression
[flaml.automl: 09-23 07:48:07] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 07:48:07] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 07:48:07] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 07:48:07] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 07:48:07] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 07:48:08] {3025} INFO - Estimated sufficient time budget=11479s. Estimated necessary time budget=11s.
[flaml.automl: 09-23 07:48:08] {3072} INFO -  at 1.2s,	estimator xgboost's best error=30.8574,	best estimator xgboost's best error=30.8574
[flaml.automl: 09-23 07:48:08] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 07:48:10] {3072} INFO -  at 3.2s,	estimator xgboost's best error=14.2659,	best estimator xgboost's best error=14.2659
[flaml.automl: 09-23 07:48:10] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 07:48:11] {3072} INFO -  at 4.3s,	estimator xgboost's best error=14.2659,	best estimator xgboost's best error=14.2659
[flaml.automl: 09-23 07:48:11] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 07:48:17] {3072} INFO -  at 9.7s,	estimator xgboost's best error=14.2659,	best estimator xgboost's best error=14.2659
[flaml.automl: 09-23 07:48:17] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 07:48:18] {3072} INFO -  at 10.8s,	estimator xgboost's best error=8.7806,	best estimator xgboost's best error=8.7806
[flaml.automl: 09-23 07:48:18] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 07:48:19] {3072} INFO -  at 12.3s,	estimator xgboost's best error=8.2809,	best estimator xgboost's best error=8.2809
[flaml.automl: 09-23 07:48:19] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 07:48:21] {3072} INFO -  at 13.8s,	estimator xgboost's best error=6.7463,	best estimator xgboost's best error=6.7463
[flaml.automl: 09-23 07:48:21] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 07:48:23] {3072} INFO -  at 16.3s,	estimator xgboost's best error=6.7463,	best estimator xgboost's best error=6.7463
[flaml.automl: 09-23 07:48:23] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 07:48:24] {3072} INFO -  at 16.6s,	estimator xgboost's best error=6.7463,	best estimator xgboost's best error=6.7463
[flaml.automl: 09-23 07:48:24] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 07:48:26] {3072} INFO -  at 19.4s,	estimator xgboost's best error=6.7463,	best estimator xgboost's best error=6.7463
[flaml.automl: 09-23 07:48:26] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 07:48:28] {3072} INFO -  at 21.0s,	estimator xgboost's best error=6.4836,	best estimator xgboost's best error=6.4836
[flaml.automl: 09-23 07:48:28] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 07:48:29] {3072} INFO -  at 22.0s,	estimator xgboost's best error=6.4836,	best estimator xgboost's best error=6.4836
[flaml.automl: 09-23 07:48:29] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 07:48:33] {3072} INFO -  at 26.1s,	estimator xgboost's best error=5.4425,	best estimator xgboost's best error=5.4425
[flaml.automl: 09-23 07:48:33] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 07:48:33] {3072} INFO -  at 26.2s,	estimator xgboost's best error=5.2525,	best estimator xgboost's best error=5.2525
[flaml.automl: 09-23 07:48:33] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 07:48:33] {3072} INFO -  at 26.2s,	estimator xgboost's best error=5.2525,	best estimator xgboost's best error=5.2525
[flaml.automl: 09-23 07:48:33] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 07:48:34] {3072} INFO -  at 27.1s,	estimator xgboost's best error=5.2525,	best estimator xgboost's best error=5.2525
[flaml.automl: 09-23 07:48:34] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 07:48:34] {3072} INFO -  at 27.2s,	estimator xgboost's best error=5.2525,	best estimator xgboost's best error=5.2525
[flaml.automl: 09-23 07:48:34] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 07:48:34] {3072} INFO -  at 27.3s,	estimator xgboost's best error=5.2525,	best estimator xgboost's best error=5.2525
[flaml.automl: 09-23 07:48:34] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 07:48:35] {3072} INFO -  at 27.5s,	estimator xgboost's best error=5.2525,	best estimator xgboost's best error=5.2525
[flaml.automl: 09-23 07:48:35] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 07:48:35] {3072} INFO -  at 27.6s,	estimator xgboost's best error=5.2525,	best estimator xgboost's best error=5.2525
[flaml.automl: 09-23 07:48:35] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 07:48:35] {3072} INFO -  at 27.8s,	estimator xgboost's best error=5.2525,	best estimator xgboost's best error=5.2525
[flaml.automl: 09-23 07:48:35] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 07:48:35] {3072} INFO -  at 28.1s,	estimator xgboost's best error=5.1910,	best estimator xgboost's best error=5.1910
[flaml.automl: 09-23 07:48:35] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 07:48:35] {3072} INFO -  at 28.2s,	estimator xgboost's best error=5.1910,	best estimator xgboost's best error=5.1910
[flaml.automl: 09-23 07:48:35] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 07:48:37] {3072} INFO -  at 29.8s,	estimator xgboost's best error=5.1910,	best estimator xgboost's best error=5.1910
[flaml.automl: 09-23 07:48:37] {2897} INFO - iteration 24, current learner xgboost
[flaml.automl: 09-23 07:48:37] {3072} INFO -  at 29.9s,	estimator xgboost's best error=5.1741,	best estimator xgboost's best error=5.1741
[flaml.automl: 09-23 07:48:37] {2897} INFO - iteration 25, current learner xgboost
[flaml.automl: 09-23 07:48:37] {3072} INFO -  at 30.0s,	estimator xgboost's best error=5.1741,	best estimator xgboost's best error=5.1741
[flaml.automl: 09-23 07:48:37] {2897} INFO - iteration 26, current learner xgboost
[flaml.automl: 09-23 07:48:38] {3072} INFO -  at 30.7s,	estimator xgboost's best error=5.0815,	best estimator xgboost's best error=5.0815
[flaml.automl: 09-23 07:48:38] {2897} INFO - iteration 27, current learner xgboost
[flaml.automl: 09-23 07:48:40] {3072} INFO -  at 33.0s,	estimator xgboost's best error=5.0815,	best estimator xgboost's best error=5.0815
[flaml.automl: 09-23 07:48:40] {2897} INFO - iteration 28, current learner xgboost
[flaml.automl: 09-23 07:48:41] {3072} INFO -  at 33.6s,	estimator xgboost's best error=5.0815,	best estimator xgboost's best error=5.0815
[flaml.automl: 09-23 07:48:41] {2897} INFO - iteration 29, current learner xgboost
[flaml.automl: 09-23 07:48:43] {3072} INFO -  at 36.4s,	estimator xgboost's best error=5.0291,	best estimator xgboost's best error=5.0291
[flaml.automl: 09-23 07:48:43] {2897} INFO - iteration 30, current learner xgboost
[flaml.automl: 09-23 07:48:44] {3072} INFO -  at 36.7s,	estimator xgboost's best error=5.0291,	best estimator xgboost's best error=5.0291
[flaml.automl: 09-23 07:48:44] {2897} INFO - iteration 31, current learner xgboost
[flaml.automl: 09-23 07:49:07] {3072} INFO -  at 60.3s,	estimator xgboost's best error=5.0291,	best estimator xgboost's best error=5.0291
[flaml.automl: 09-23 07:50:07] {3335} INFO - retrain xgboost for 59.5s
[flaml.automl: 09-23 07:50:07] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.8096554503734712, colsample_bynode=1,
             colsample_bytree=0.9320260053333108, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.09695404497967328,
             max_delta_step=0, max_depth=0, max_leaves=25,
             min_child_weight=122.59049382167811, missing=nan,
             monotone_constraints='()', n_estimators=49, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.06225238170530472,
             reg_lambda=0.028589441863113674, scale_pos_weight=1,
             subsample=0.8088527898668396, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 07:50:07] {2636} INFO - fit succeeded
[flaml.automl: 09-23 07:50:07] {2637} INFO - Time taken to find the best model: 36.38297891616821
PM10(0)最佳参数：{'n_estimators': 454, 'max_leaves': 25, 'min_child_weight': 122.59049382167811, 'learning_rate': 0.09695404497967328, 'subsample': 0.8088527898668396, 'colsample_bylevel': 0.8096554503734712, 'colsample_bytree': 0.9320260053333108, 'reg_alpha': 0.06225238170530472, 'reg_lambda': 0.028589441863113674}
PM10(0)最佳损失：-4.02913454890203
PM10(0)最好结果：{'pred_time': 1.708479942652148e-05, 'wall_clock_time': 36.38297891616821, 'metric_for_logging': {'pred_time': 1.708479942652148e-05}, 'val_loss': 5.02913454890203, 'training_iteration': 1, 'config': {'n_estimators': 454, 'max_leaves': 25, 'min_child_weight': 122.59049382167811, 'learning_rate': 0.09695404497967328, 'subsample': 0.8088527898668396, 'colsample_bylevel': 0.8096554503734712, 'colsample_bytree': 0.9320260053333108, 'reg_alpha': 0.06225238170530472, 'reg_lambda': 0.028589441863113674}, 'config/n_estimators': 454, 'config/max_leaves': 25, 'config/min_child_weight': 122.59049382167811, 'config/learning_rate': 0.09695404497967328, 'config/subsample': 0.8088527898668396, 'config/colsample_bylevel': 0.8096554503734712, 'config/colsample_bytree': 0.9320260053333108, 'config/reg_alpha': 0.06225238170530472, 'config/reg_lambda': 0.028589441863113674, 'experiment_tag': 'exp', 'time_total_s': 2.8040378093719482}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.8096554503734712, colsample_bynode=1,
             colsample_bytree=0.9320260053333108, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.09695404497967328,
             max_delta_step=0, max_depth=0, max_leaves=25,
             min_child_weight=122.59049382167811, missing=nan,
             monotone_constraints='()', n_estimators=49, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.06225238170530472,
             reg_lambda=0.028589441863113674, scale_pos_weight=1,
             subsample=0.8088527898668396, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.9272836257555295
PM10(0)的mse=86.73313812390217
PM10(0)的mae=5.288179470194276
PM10(0)的mar=0.11554157786237454
总共花费的时间为：120.19
长春市
1119A
1120A
1121A
1122A
1124A
1125A
1126A
1128A
[flaml.automl: 09-23 08:10:05] {2390} INFO - task = regression
[flaml.automl: 09-23 08:10:05] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 08:10:05] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 08:10:05] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 08:10:05] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 08:10:05] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 08:10:06] {3025} INFO - Estimated sufficient time budget=95017s. Estimated necessary time budget=95s.
[flaml.automl: 09-23 08:10:06] {3072} INFO -  at 1.4s,	estimator xgboost's best error=33.0637,	best estimator xgboost's best error=33.0637
[flaml.automl: 09-23 08:10:06] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 08:10:08] {3072} INFO -  at 3.4s,	estimator xgboost's best error=16.4231,	best estimator xgboost's best error=16.4231
[flaml.automl: 09-23 08:10:08] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 08:10:10] {3072} INFO -  at 4.6s,	estimator xgboost's best error=16.4231,	best estimator xgboost's best error=16.4231
[flaml.automl: 09-23 08:10:10] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 08:10:13] {3072} INFO -  at 7.7s,	estimator xgboost's best error=16.4231,	best estimator xgboost's best error=16.4231
[flaml.automl: 09-23 08:10:13] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 08:10:14] {3072} INFO -  at 8.8s,	estimator xgboost's best error=12.8435,	best estimator xgboost's best error=12.8435
[flaml.automl: 09-23 08:10:14] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 08:10:15] {3072} INFO -  at 10.3s,	estimator xgboost's best error=11.2567,	best estimator xgboost's best error=11.2567
[flaml.automl: 09-23 08:10:15] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 08:10:17] {3072} INFO -  at 11.8s,	estimator xgboost's best error=10.6116,	best estimator xgboost's best error=10.6116
[flaml.automl: 09-23 08:10:17] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 08:10:19] {3072} INFO -  at 14.3s,	estimator xgboost's best error=10.6116,	best estimator xgboost's best error=10.6116
[flaml.automl: 09-23 08:10:19] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 08:10:21] {3072} INFO -  at 15.8s,	estimator xgboost's best error=10.6116,	best estimator xgboost's best error=10.6116
[flaml.automl: 09-23 08:10:21] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 08:10:23] {3072} INFO -  at 18.3s,	estimator xgboost's best error=10.0003,	best estimator xgboost's best error=10.0003
[flaml.automl: 09-23 08:10:23] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 08:10:25] {3072} INFO -  at 19.8s,	estimator xgboost's best error=10.0003,	best estimator xgboost's best error=10.0003
[flaml.automl: 09-23 08:10:25] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 08:10:26] {3072} INFO -  at 20.9s,	estimator xgboost's best error=10.0003,	best estimator xgboost's best error=10.0003
[flaml.automl: 09-23 08:10:26] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 08:10:28] {3072} INFO -  at 22.7s,	estimator xgboost's best error=9.4263,	best estimator xgboost's best error=9.4263
[flaml.automl: 09-23 08:10:28] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 08:10:30] {3072} INFO -  at 24.8s,	estimator xgboost's best error=9.4263,	best estimator xgboost's best error=9.4263
[flaml.automl: 09-23 08:10:30] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 08:10:31] {3072} INFO -  at 26.1s,	estimator xgboost's best error=9.4263,	best estimator xgboost's best error=9.4263
[flaml.automl: 09-23 08:10:31] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 08:10:33] {3072} INFO -  at 27.8s,	estimator xgboost's best error=9.4263,	best estimator xgboost's best error=9.4263
[flaml.automl: 09-23 08:10:33] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 08:10:34] {3072} INFO -  at 29.4s,	estimator xgboost's best error=9.3730,	best estimator xgboost's best error=9.3730
[flaml.automl: 09-23 08:10:34] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 08:10:36] {3072} INFO -  at 31.1s,	estimator xgboost's best error=9.3730,	best estimator xgboost's best error=9.3730
[flaml.automl: 09-23 08:10:36] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 08:10:37] {3072} INFO -  at 32.3s,	estimator xgboost's best error=9.1971,	best estimator xgboost's best error=9.1971
[flaml.automl: 09-23 08:10:37] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 08:10:38] {3072} INFO -  at 33.6s,	estimator xgboost's best error=9.1971,	best estimator xgboost's best error=9.1971
[flaml.automl: 09-23 08:10:38] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 08:10:41] {3072} INFO -  at 35.8s,	estimator xgboost's best error=9.1971,	best estimator xgboost's best error=9.1971
[flaml.automl: 09-23 08:10:41] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 08:10:43] {3072} INFO -  at 37.9s,	estimator xgboost's best error=9.1971,	best estimator xgboost's best error=9.1971
[flaml.automl: 09-23 08:10:43] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 08:10:44] {3072} INFO -  at 38.6s,	estimator xgboost's best error=9.1971,	best estimator xgboost's best error=9.1971
[flaml.automl: 09-23 08:10:44] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 08:10:59] {3072} INFO -  at 54.3s,	estimator xgboost's best error=9.0190,	best estimator xgboost's best error=9.0190
[flaml.automl: 09-23 08:11:16] {3335} INFO - retrain xgboost for 16.7s
[flaml.automl: 09-23 08:11:16] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.8193436379278645, colsample_bynode=1,
             colsample_bytree=0.9324261831198668, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=1.0, max_delta_step=0,
             max_depth=0, max_leaves=20, min_child_weight=0.002301726356589306,
             missing=nan, monotone_constraints='()', n_estimators=18, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.0010669077022962851, reg_lambda=0.0799156556628313,
             scale_pos_weight=1, subsample=0.9199833031469933,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
[flaml.automl: 09-23 08:11:16] {2636} INFO - fit succeeded
[flaml.automl: 09-23 08:11:16] {2637} INFO - Time taken to find the best model: 54.28471064567566
[flaml.automl: 09-23 08:11:16] {2648} WARNING - Time taken to find the best model is 90% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
PM10(0)最佳参数：{'n_estimators': 18, 'max_leaves': 20, 'min_child_weight': 0.002301726356589306, 'learning_rate': 1.0, 'subsample': 0.9199833031469933, 'colsample_bylevel': 0.8193436379278645, 'colsample_bytree': 0.9324261831198668, 'reg_alpha': 0.0010669077022962851, 'reg_lambda': 0.0799156556628313, 'FLAML_sample_size': 84805}
PM10(0)最佳损失：-8.019009413504618
PM10(0)最好结果：{'pred_time': 3.961118608855473e-06, 'wall_clock_time': 54.28471064567566, 'metric_for_logging': {'pred_time': 3.961118608855473e-06}, 'val_loss': 9.019009413504618, 'training_iteration': 1, 'config': {'n_estimators': 18, 'max_leaves': 20, 'min_child_weight': 0.002301726356589306, 'learning_rate': 1.0, 'subsample': 0.9199833031469933, 'colsample_bylevel': 0.8193436379278645, 'colsample_bytree': 0.9324261831198668, 'reg_alpha': 0.0010669077022962851, 'reg_lambda': 0.0799156556628313, 'FLAML_sample_size': 84805}, 'config/n_estimators': 18, 'config/max_leaves': 20, 'config/min_child_weight': 0.002301726356589306, 'config/learning_rate': 1.0, 'config/subsample': 0.9199833031469933, 'config/colsample_bylevel': 0.8193436379278645, 'config/colsample_bytree': 0.9324261831198668, 'config/reg_alpha': 0.0010669077022962851, 'config/reg_lambda': 0.0799156556628313, 'config/FLAML_sample_size': 84805, 'experiment_tag': 'exp', 'time_total_s': 15.658126831054688}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.8193436379278645, colsample_bynode=1,
             colsample_bytree=0.9324261831198668, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=1.0, max_delta_step=0,
             max_depth=0, max_leaves=20, min_child_weight=0.002301726356589306,
             missing=nan, monotone_constraints='()', n_estimators=18, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.0010669077022962851, reg_lambda=0.0799156556628313,
             scale_pos_weight=1, subsample=0.9199833031469933,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
PM10(0)的R2=0.829533714170288
PM10(0)的mse=201.52004127493137
PM10(0)的mae=8.989827983051454
PM10(0)的mar=0.24128326653125579
总共花费的时间为：72.14
哈尔滨市
1129A
1130A
1139A
1140A
[flaml.automl: 09-23 08:21:16] {2390} INFO - task = regression
[flaml.automl: 09-23 08:21:16] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 08:21:16] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 08:21:16] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 08:21:16] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 08:21:16] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 08:21:17] {3025} INFO - Estimated sufficient time budget=46974s. Estimated necessary time budget=47s.
[flaml.automl: 09-23 08:21:17] {3072} INFO -  at 1.3s,	estimator xgboost's best error=33.3931,	best estimator xgboost's best error=33.3931
[flaml.automl: 09-23 08:21:17] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 08:21:19] {3072} INFO -  at 3.3s,	estimator xgboost's best error=16.6184,	best estimator xgboost's best error=16.6184
[flaml.automl: 09-23 08:21:19] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 08:21:20] {3072} INFO -  at 4.4s,	estimator xgboost's best error=16.6184,	best estimator xgboost's best error=16.6184
[flaml.automl: 09-23 08:21:20] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 08:21:27] {3072} INFO -  at 10.8s,	estimator xgboost's best error=16.6184,	best estimator xgboost's best error=16.6184
[flaml.automl: 09-23 08:21:27] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 08:21:28] {3072} INFO -  at 11.9s,	estimator xgboost's best error=13.8203,	best estimator xgboost's best error=13.8203
[flaml.automl: 09-23 08:21:28] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 08:21:29] {3072} INFO -  at 13.4s,	estimator xgboost's best error=12.5477,	best estimator xgboost's best error=12.5477
[flaml.automl: 09-23 08:21:29] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 08:21:31] {3072} INFO -  at 14.9s,	estimator xgboost's best error=11.6587,	best estimator xgboost's best error=11.6587
[flaml.automl: 09-23 08:21:31] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 08:21:34] {3072} INFO -  at 17.5s,	estimator xgboost's best error=11.6587,	best estimator xgboost's best error=11.6587
[flaml.automl: 09-23 08:21:34] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 08:21:35] {3072} INFO -  at 19.0s,	estimator xgboost's best error=11.4560,	best estimator xgboost's best error=11.4560
[flaml.automl: 09-23 08:21:35] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 08:21:38] {3072} INFO -  at 21.8s,	estimator xgboost's best error=11.0205,	best estimator xgboost's best error=11.0205
[flaml.automl: 09-23 08:21:38] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 08:21:39] {3072} INFO -  at 22.9s,	estimator xgboost's best error=11.0205,	best estimator xgboost's best error=11.0205
[flaml.automl: 09-23 08:21:39] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 08:21:43] {3072} INFO -  at 27.3s,	estimator xgboost's best error=10.2034,	best estimator xgboost's best error=10.2034
[flaml.automl: 09-23 08:21:43] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 08:21:47] {3072} INFO -  at 30.7s,	estimator xgboost's best error=10.0197,	best estimator xgboost's best error=10.0197
[flaml.automl: 09-23 08:21:47] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 08:21:50] {3072} INFO -  at 34.0s,	estimator xgboost's best error=10.0197,	best estimator xgboost's best error=10.0197
[flaml.automl: 09-23 08:21:50] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 08:21:52] {3072} INFO -  at 36.4s,	estimator xgboost's best error=10.0197,	best estimator xgboost's best error=10.0197
[flaml.automl: 09-23 08:21:52] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 08:21:55] {3072} INFO -  at 38.8s,	estimator xgboost's best error=9.9317,	best estimator xgboost's best error=9.9317
[flaml.automl: 09-23 08:21:55] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 08:21:57] {3072} INFO -  at 41.2s,	estimator xgboost's best error=9.9317,	best estimator xgboost's best error=9.9317
[flaml.automl: 09-23 08:21:57] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 08:21:59] {3072} INFO -  at 43.1s,	estimator xgboost's best error=9.9317,	best estimator xgboost's best error=9.9317
[flaml.automl: 09-23 08:21:59] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 08:22:01] {3072} INFO -  at 44.9s,	estimator xgboost's best error=9.9317,	best estimator xgboost's best error=9.9317
[flaml.automl: 09-23 08:22:01] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 08:22:03] {3072} INFO -  at 46.5s,	estimator xgboost's best error=9.9317,	best estimator xgboost's best error=9.9317
[flaml.automl: 09-23 08:22:03] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 08:22:16] {3072} INFO -  at 59.6s,	estimator xgboost's best error=9.4604,	best estimator xgboost's best error=9.4604
[flaml.automl: 09-23 08:22:28] {3335} INFO - retrain xgboost for 12.8s
[flaml.automl: 09-23 08:22:28] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.902249106663565, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5508049883873372,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.0017454776322958724, missing=nan,
             monotone_constraints='()', n_estimators=35, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.003919588748975853, reg_lambda=0.27794049904081597,
             scale_pos_weight=1, subsample=0.6989222769179986,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
[flaml.automl: 09-23 08:22:28] {2636} INFO - fit succeeded
[flaml.automl: 09-23 08:22:28] {2637} INFO - Time taken to find the best model: 59.643179416656494
[flaml.automl: 09-23 08:22:28] {2648} WARNING - Time taken to find the best model is 99% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
PM10(0)最佳参数：{'n_estimators': 35, 'max_leaves': 7, 'min_child_weight': 0.0017454776322958724, 'learning_rate': 0.5508049883873372, 'subsample': 0.6989222769179986, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.902249106663565, 'reg_alpha': 0.003919588748975853, 'reg_lambda': 0.27794049904081597, 'FLAML_sample_size': 41190}
PM10(0)最佳损失：-8.460397506036273
PM10(0)最好结果：{'pred_time': 7.4010815244328386e-06, 'wall_clock_time': 59.643179416656494, 'metric_for_logging': {'pred_time': 7.4010815244328386e-06}, 'val_loss': 9.460397506036273, 'training_iteration': 1, 'config': {'n_estimators': 35, 'max_leaves': 7, 'min_child_weight': 0.0017454776322958724, 'learning_rate': 0.5508049883873372, 'subsample': 0.6989222769179986, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.902249106663565, 'reg_alpha': 0.003919588748975853, 'reg_lambda': 0.27794049904081597, 'FLAML_sample_size': 41190}, 'config/n_estimators': 35, 'config/max_leaves': 7, 'config/min_child_weight': 0.0017454776322958724, 'config/learning_rate': 0.5508049883873372, 'config/subsample': 0.6989222769179986, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.902249106663565, 'config/reg_alpha': 0.003919588748975853, 'config/reg_lambda': 0.27794049904081597, 'config/FLAML_sample_size': 41190, 'experiment_tag': 'exp', 'time_total_s': 13.13891887664795}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.902249106663565, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5508049883873372,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.0017454776322958724, missing=nan,
             monotone_constraints='()', n_estimators=35, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.003919588748975853, reg_lambda=0.27794049904081597,
             scale_pos_weight=1, subsample=0.6989222769179986,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
PM10(0)的R2=0.8525943689305266
PM10(0)的mse=215.77227306978648
PM10(0)的mae=9.21879666535066
PM10(0)的mar=0.271719714207865
总共花费的时间为：73.03
上海市
1143A
1144A
1145A
1148A
1150A
3265A
3266A
3269A
3270A
3271A
3272A
3273A
3274A
3544A
[flaml.automl: 09-23 08:55:39] {2390} INFO - task = regression
[flaml.automl: 09-23 08:55:39] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 08:55:39] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 08:55:39] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 08:55:39] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 08:55:39] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 08:55:40] {3025} INFO - Estimated sufficient time budget=245204s. Estimated necessary time budget=245s.
[flaml.automl: 09-23 08:55:40] {3072} INFO -  at 2.5s,	estimator xgboost's best error=25.8679,	best estimator xgboost's best error=25.8679
[flaml.automl: 09-23 08:55:40] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 08:55:42] {3072} INFO -  at 4.1s,	estimator xgboost's best error=21.4152,	best estimator xgboost's best error=21.4152
[flaml.automl: 09-23 08:55:42] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 08:55:43] {3072} INFO -  at 5.6s,	estimator xgboost's best error=21.4152,	best estimator xgboost's best error=21.4152
[flaml.automl: 09-23 08:55:43] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 08:55:45] {3072} INFO -  at 7.0s,	estimator xgboost's best error=21.4152,	best estimator xgboost's best error=21.4152
[flaml.automl: 09-23 08:55:45] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 08:55:46] {3072} INFO -  at 8.3s,	estimator xgboost's best error=8.4699,	best estimator xgboost's best error=8.4699
[flaml.automl: 09-23 08:55:46] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 08:55:47] {3072} INFO -  at 9.5s,	estimator xgboost's best error=8.4699,	best estimator xgboost's best error=8.4699
[flaml.automl: 09-23 08:55:47] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 08:55:49] {3072} INFO -  at 10.9s,	estimator xgboost's best error=8.4061,	best estimator xgboost's best error=8.4061
[flaml.automl: 09-23 08:55:49] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 08:55:50] {3072} INFO -  at 12.2s,	estimator xgboost's best error=8.4061,	best estimator xgboost's best error=8.4061
[flaml.automl: 09-23 08:55:50] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 08:55:51] {3072} INFO -  at 13.7s,	estimator xgboost's best error=8.4061,	best estimator xgboost's best error=8.4061
[flaml.automl: 09-23 08:55:51] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 08:55:53] {3072} INFO -  at 14.9s,	estimator xgboost's best error=8.4061,	best estimator xgboost's best error=8.4061
[flaml.automl: 09-23 08:55:53] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 08:55:54] {3072} INFO -  at 16.0s,	estimator xgboost's best error=8.4061,	best estimator xgboost's best error=8.4061
[flaml.automl: 09-23 08:55:54] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 08:55:56] {3072} INFO -  at 18.3s,	estimator xgboost's best error=6.2806,	best estimator xgboost's best error=6.2806
[flaml.automl: 09-23 08:55:56] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 08:55:58] {3072} INFO -  at 19.8s,	estimator xgboost's best error=6.2806,	best estimator xgboost's best error=6.2806
[flaml.automl: 09-23 08:55:58] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 08:56:06] {3072} INFO -  at 28.3s,	estimator xgboost's best error=5.5170,	best estimator xgboost's best error=5.5170
[flaml.automl: 09-23 08:56:06] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 08:56:21] {3072} INFO -  at 43.5s,	estimator xgboost's best error=5.3750,	best estimator xgboost's best error=5.3750
[flaml.automl: 09-23 08:56:21] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 08:56:25] {3072} INFO -  at 47.4s,	estimator xgboost's best error=5.3750,	best estimator xgboost's best error=5.3750
[flaml.automl: 09-23 08:56:26] {3335} INFO - retrain xgboost for 0.4s
[flaml.automl: 09-23 08:56:26] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 08:56:26] {2636} INFO - fit succeeded
[flaml.automl: 09-23 08:56:26] {2637} INFO - Time taken to find the best model: 43.52816677093506
[flaml.automl: 09-23 08:56:26] {2648} WARNING - Time taken to find the best model is 73% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
PM10(0)最佳参数：{'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 152472}
PM10(0)最佳损失：-4.375001740967871
PM10(0)最好结果：{'pred_time': 4.305902583978207e-06, 'wall_clock_time': 43.52816677093506, 'metric_for_logging': {'pred_time': 4.305902583978207e-06}, 'val_loss': 5.375001740967871, 'training_iteration': 1, 'config': {'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 152472}, 'config/n_estimators': 31, 'config/max_leaves': 7, 'config/min_child_weight': 0.6186300892591503, 'config/learning_rate': 0.48254477352294606, 'config/subsample': 0.8921566499079494, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9831203893408513, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.011522990442748649, 'config/FLAML_sample_size': 152472, 'experiment_tag': 'exp', 'time_total_s': 15.17746615409851}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.8821266665114026
PM10(0)的mse=60.578466517726106
PM10(0)的mae=5.270585353393226
PM10(0)的mar=0.196752900265628
总共花费的时间为：50.03
南京市
1151A
1152A
1153A
1154A
3423A
3424A
3427A
[flaml.automl: 09-23 09:14:27] {2390} INFO - task = regression
[flaml.automl: 09-23 09:14:27] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 09:14:27] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 09:14:27] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 09:14:27] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 09:14:27] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 09:14:28] {3025} INFO - Estimated sufficient time budget=85958s. Estimated necessary time budget=86s.
[flaml.automl: 09-23 09:14:28] {3072} INFO -  at 1.4s,	estimator xgboost's best error=35.2903,	best estimator xgboost's best error=35.2903
[flaml.automl: 09-23 09:14:28] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 09:14:30] {3072} INFO -  at 3.4s,	estimator xgboost's best error=16.4732,	best estimator xgboost's best error=16.4732
[flaml.automl: 09-23 09:14:30] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 09:14:31] {3072} INFO -  at 4.5s,	estimator xgboost's best error=16.4732,	best estimator xgboost's best error=16.4732
[flaml.automl: 09-23 09:14:31] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 09:14:35] {3072} INFO -  at 8.1s,	estimator xgboost's best error=16.4732,	best estimator xgboost's best error=16.4732
[flaml.automl: 09-23 09:14:35] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 09:14:36] {3072} INFO -  at 9.1s,	estimator xgboost's best error=10.7511,	best estimator xgboost's best error=10.7511
[flaml.automl: 09-23 09:14:36] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 09:14:37] {3072} INFO -  at 10.6s,	estimator xgboost's best error=10.7511,	best estimator xgboost's best error=10.7511
[flaml.automl: 09-23 09:14:37] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 09:14:39] {3072} INFO -  at 12.2s,	estimator xgboost's best error=7.3506,	best estimator xgboost's best error=7.3506
[flaml.automl: 09-23 09:14:39] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 09:14:42] {3072} INFO -  at 14.8s,	estimator xgboost's best error=7.3506,	best estimator xgboost's best error=7.3506
[flaml.automl: 09-23 09:14:42] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 09:14:43] {3072} INFO -  at 16.3s,	estimator xgboost's best error=7.3506,	best estimator xgboost's best error=7.3506
[flaml.automl: 09-23 09:14:43] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 09:14:46] {3072} INFO -  at 18.8s,	estimator xgboost's best error=7.3506,	best estimator xgboost's best error=7.3506
[flaml.automl: 09-23 09:14:46] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 09:14:47] {3072} INFO -  at 20.2s,	estimator xgboost's best error=7.3506,	best estimator xgboost's best error=7.3506
[flaml.automl: 09-23 09:14:47] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 09:14:49] {3072} INFO -  at 21.7s,	estimator xgboost's best error=7.3258,	best estimator xgboost's best error=7.3258
[flaml.automl: 09-23 09:14:49] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 09:14:50] {3072} INFO -  at 22.7s,	estimator xgboost's best error=7.3258,	best estimator xgboost's best error=7.3258
[flaml.automl: 09-23 09:14:50] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 09:14:56] {3072} INFO -  at 29.4s,	estimator xgboost's best error=6.1923,	best estimator xgboost's best error=6.1923
[flaml.automl: 09-23 09:14:56] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 09:15:08] {3072} INFO -  at 41.4s,	estimator xgboost's best error=6.0880,	best estimator xgboost's best error=6.0880
[flaml.automl: 09-23 09:15:08] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 09:15:15] {3072} INFO -  at 48.0s,	estimator xgboost's best error=6.0880,	best estimator xgboost's best error=6.0880
[flaml.automl: 09-23 09:15:25] {3335} INFO - retrain xgboost for 10.5s
[flaml.automl: 09-23 09:15:25] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 09:15:25] {2636} INFO - fit succeeded
[flaml.automl: 09-23 09:15:25] {2637} INFO - Time taken to find the best model: 41.44468808174133
PM10(0)最佳参数：{'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 75461}
PM10(0)最佳损失：-5.088046858804028
PM10(0)最好结果：{'pred_time': 4.507205851673725e-06, 'wall_clock_time': 41.44468808174133, 'metric_for_logging': {'pred_time': 4.507205851673725e-06}, 'val_loss': 6.088046858804028, 'training_iteration': 1, 'config': {'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.6186300892591503, 'learning_rate': 0.48254477352294606, 'subsample': 0.8921566499079494, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9831203893408513, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011522990442748649, 'FLAML_sample_size': 75461}, 'config/n_estimators': 31, 'config/max_leaves': 7, 'config/min_child_weight': 0.6186300892591503, 'config/learning_rate': 0.48254477352294606, 'config/subsample': 0.8921566499079494, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9831203893408513, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.011522990442748649, 'config/FLAML_sample_size': 75461, 'experiment_tag': 'exp', 'time_total_s': 12.085008382797241}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9831203893408513, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.48254477352294606,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.6186300892591503, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.011522990442748649, scale_pos_weight=1,
             subsample=0.8921566499079494, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
PM10(0)的R2=0.9210268150125122
PM10(0)的mse=75.13504230796403
PM10(0)的mae=6.132144524813901
PM10(0)的mar=0.16685534858487805
总共花费的时间为：59.50
苏州市
1160A
1164A
1165A
1166A
1167A
3289A
3290A
3425A
