nohup: ignoring input
北京市
1005A
1008A
1009A
1010A
1012A
3417A
3418A
3671A
3672A
3673A
3674A
3675A
3695A
3696A
3697A
[flaml.automl: 09-23 06:46:09] {2390} INFO - task = regression
[flaml.automl: 09-23 06:46:09] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 06:46:09] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 06:46:09] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 06:46:09] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 06:46:09] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 06:46:10] {3025} INFO - Estimated sufficient time budget=197047s. Estimated necessary time budget=197s.
[flaml.automl: 09-23 06:46:10] {3072} INFO -  at 1.9s,	estimator xgboost's best error=39.8656,	best estimator xgboost's best error=39.8656
[flaml.automl: 09-23 06:46:10] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 06:46:12] {3072} INFO -  at 3.4s,	estimator xgboost's best error=25.1935,	best estimator xgboost's best error=25.1935
[flaml.automl: 09-23 06:46:12] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 06:46:13] {3072} INFO -  at 4.6s,	estimator xgboost's best error=25.1935,	best estimator xgboost's best error=25.1935
[flaml.automl: 09-23 06:46:13] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 06:46:14] {3072} INFO -  at 5.7s,	estimator xgboost's best error=25.1935,	best estimator xgboost's best error=25.1935
[flaml.automl: 09-23 06:46:14] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 06:46:15] {3072} INFO -  at 6.8s,	estimator xgboost's best error=11.6263,	best estimator xgboost's best error=11.6263
[flaml.automl: 09-23 06:46:15] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 06:46:16] {3072} INFO -  at 8.0s,	estimator xgboost's best error=11.6263,	best estimator xgboost's best error=11.6263
[flaml.automl: 09-23 06:46:16] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 06:46:17] {3072} INFO -  at 9.3s,	estimator xgboost's best error=10.6091,	best estimator xgboost's best error=10.6091
[flaml.automl: 09-23 06:46:17] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 06:46:19] {3072} INFO -  at 10.6s,	estimator xgboost's best error=10.6091,	best estimator xgboost's best error=10.6091
[flaml.automl: 09-23 06:46:19] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 06:46:20] {3072} INFO -  at 11.9s,	estimator xgboost's best error=10.6091,	best estimator xgboost's best error=10.6091
[flaml.automl: 09-23 06:46:20] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 06:46:21] {3072} INFO -  at 13.2s,	estimator xgboost's best error=10.6091,	best estimator xgboost's best error=10.6091
[flaml.automl: 09-23 06:46:21] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 06:46:22] {3072} INFO -  at 14.3s,	estimator xgboost's best error=9.9319,	best estimator xgboost's best error=9.9319
[flaml.automl: 09-23 06:46:22] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 06:46:24] {3072} INFO -  at 15.4s,	estimator xgboost's best error=9.9319,	best estimator xgboost's best error=9.9319
[flaml.automl: 09-23 06:46:24] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 06:46:25] {3072} INFO -  at 16.5s,	estimator xgboost's best error=8.3184,	best estimator xgboost's best error=8.3184
[flaml.automl: 09-23 06:46:25] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 06:46:26] {3072} INFO -  at 17.5s,	estimator xgboost's best error=8.3184,	best estimator xgboost's best error=8.3184
[flaml.automl: 09-23 06:46:26] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 06:46:26] {3072} INFO -  at 18.3s,	estimator xgboost's best error=8.3184,	best estimator xgboost's best error=8.3184
[flaml.automl: 09-23 06:46:26] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 06:46:27] {3072} INFO -  at 19.3s,	estimator xgboost's best error=8.3184,	best estimator xgboost's best error=8.3184
[flaml.automl: 09-23 06:46:27] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 06:46:28] {3072} INFO -  at 20.3s,	estimator xgboost's best error=8.3184,	best estimator xgboost's best error=8.3184
[flaml.automl: 09-23 06:46:28] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 06:46:33] {3072} INFO -  at 25.0s,	estimator xgboost's best error=6.7124,	best estimator xgboost's best error=6.7124
[flaml.automl: 09-23 06:46:33] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 06:46:35] {3072} INFO -  at 27.2s,	estimator xgboost's best error=6.7124,	best estimator xgboost's best error=6.7124
[flaml.automl: 09-23 06:46:35] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 06:46:39] {3072} INFO -  at 30.6s,	estimator xgboost's best error=6.7124,	best estimator xgboost's best error=6.7124
[flaml.automl: 09-23 06:46:39] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 06:46:41] {3072} INFO -  at 32.7s,	estimator xgboost's best error=6.7124,	best estimator xgboost's best error=6.7124
[flaml.automl: 09-23 06:46:41] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 06:46:44] {3072} INFO -  at 35.7s,	estimator xgboost's best error=6.7124,	best estimator xgboost's best error=6.7124
[flaml.automl: 09-23 06:46:44] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 06:46:50] {3072} INFO -  at 41.4s,	estimator xgboost's best error=6.4382,	best estimator xgboost's best error=6.4382
[flaml.automl: 09-23 06:46:50] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 06:47:08] {3072} INFO -  at 59.7s,	estimator xgboost's best error=5.6433,	best estimator xgboost's best error=5.6433
[flaml.automl: 09-23 06:47:33] {3335} INFO - retrain xgboost for 25.6s
[flaml.automl: 09-23 06:47:33] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.803054534596795, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.6023269513573992,
             max_delta_step=0, max_depth=0, max_leaves=17,
             min_child_weight=29.13358596675086, missing=nan,
             monotone_constraints='()', n_estimators=28, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.005909856814262056, scale_pos_weight=1, subsample=1.0,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
[flaml.automl: 09-23 06:47:33] {2636} INFO - fit succeeded
[flaml.automl: 09-23 06:47:33] {2637} INFO - Time taken to find the best model: 59.70598769187927
[flaml.automl: 09-23 06:47:33] {2648} WARNING - Time taken to find the best model is 100% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
O3(0)最佳参数：{'n_estimators': 28, 'max_leaves': 17, 'min_child_weight': 29.13358596675086, 'learning_rate': 0.6023269513573992, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.803054534596795, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.005909856814262056, 'FLAML_sample_size': 166568}
O3(0)最佳损失：-4.6432595507290895
O3(0)最好结果：{'pred_time': 2.3396272290363563e-06, 'wall_clock_time': 59.70598769187927, 'metric_for_logging': {'pred_time': 2.3396272290363563e-06}, 'val_loss': 5.6432595507290895, 'training_iteration': 1, 'config': {'n_estimators': 28, 'max_leaves': 17, 'min_child_weight': 29.13358596675086, 'learning_rate': 0.6023269513573992, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.803054534596795, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.005909856814262056, 'FLAML_sample_size': 166568}, 'config/n_estimators': 28, 'config/max_leaves': 17, 'config/min_child_weight': 29.13358596675086, 'config/learning_rate': 0.6023269513573992, 'config/subsample': 1.0, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.803054534596795, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.005909856814262056, 'config/FLAML_sample_size': 166568, 'experiment_tag': 'exp', 'time_total_s': 18.26513695716858}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.803054534596795, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.6023269513573992,
             max_delta_step=0, max_depth=0, max_leaves=17,
             min_child_weight=29.13358596675086, missing=nan,
             monotone_constraints='()', n_estimators=28, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.005909856814262056, scale_pos_weight=1, subsample=1.0,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
O3(0)的R2=0.9592672853114044
O3(0)的mse=68.04304315004936
O3(0)的mae=5.457030015925489
O3(0)的mar=0.22338389836460343
总共花费的时间为：88.12
天津市
1015A
1019A
2859A
2860A
2922A
3325A
3326A
3327A
3460A
3461A
3462A
[flaml.automl: 09-23 07:15:36] {2390} INFO - task = regression
[flaml.automl: 09-23 07:15:36] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 07:15:36] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 07:15:36] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 07:15:36] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 07:15:36] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 07:15:37] {3025} INFO - Estimated sufficient time budget=139071s. Estimated necessary time budget=139s.
[flaml.automl: 09-23 07:15:37] {3072} INFO -  at 1.6s,	estimator xgboost's best error=43.1656,	best estimator xgboost's best error=43.1656
[flaml.automl: 09-23 07:15:37] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 07:15:39] {3072} INFO -  at 3.6s,	estimator xgboost's best error=21.1080,	best estimator xgboost's best error=21.1080
[flaml.automl: 09-23 07:15:39] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 07:15:40] {3072} INFO -  at 4.7s,	estimator xgboost's best error=21.1080,	best estimator xgboost's best error=21.1080
[flaml.automl: 09-23 07:15:40] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 07:15:42] {3072} INFO -  at 6.8s,	estimator xgboost's best error=21.1080,	best estimator xgboost's best error=21.1080
[flaml.automl: 09-23 07:15:42] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 07:15:43] {3072} INFO -  at 7.9s,	estimator xgboost's best error=12.5969,	best estimator xgboost's best error=12.5969
[flaml.automl: 09-23 07:15:43] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 07:15:45] {3072} INFO -  at 9.4s,	estimator xgboost's best error=10.6016,	best estimator xgboost's best error=10.6016
[flaml.automl: 09-23 07:15:45] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 07:15:46] {3072} INFO -  at 10.9s,	estimator xgboost's best error=9.9551,	best estimator xgboost's best error=9.9551
[flaml.automl: 09-23 07:15:46] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 07:15:48] {3072} INFO -  at 12.7s,	estimator xgboost's best error=9.9551,	best estimator xgboost's best error=9.9551
[flaml.automl: 09-23 07:15:48] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 07:15:49] {3072} INFO -  at 13.5s,	estimator xgboost's best error=9.9551,	best estimator xgboost's best error=9.9551
[flaml.automl: 09-23 07:15:49] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 07:15:50] {3072} INFO -  at 15.2s,	estimator xgboost's best error=9.9551,	best estimator xgboost's best error=9.9551
[flaml.automl: 09-23 07:15:50] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 07:15:52] {3072} INFO -  at 16.5s,	estimator xgboost's best error=9.9551,	best estimator xgboost's best error=9.9551
[flaml.automl: 09-23 07:15:52] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 07:15:53] {3072} INFO -  at 18.1s,	estimator xgboost's best error=9.8586,	best estimator xgboost's best error=9.8586
[flaml.automl: 09-23 07:15:53] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 07:15:54] {3072} INFO -  at 19.2s,	estimator xgboost's best error=9.8586,	best estimator xgboost's best error=9.8586
[flaml.automl: 09-23 07:15:54] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 07:16:01] {3072} INFO -  at 25.7s,	estimator xgboost's best error=6.8032,	best estimator xgboost's best error=6.8032
[flaml.automl: 09-23 07:16:01] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 07:16:13] {3072} INFO -  at 37.8s,	estimator xgboost's best error=6.3055,	best estimator xgboost's best error=6.3055
[flaml.automl: 09-23 07:16:13] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 07:16:20] {3072} INFO -  at 44.3s,	estimator xgboost's best error=6.3055,	best estimator xgboost's best error=6.3055
[flaml.automl: 09-23 07:16:20] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 07:16:35] {3072} INFO -  at 59.8s,	estimator xgboost's best error=6.3055,	best estimator xgboost's best error=6.3055
[flaml.automl: 09-23 07:16:47] {3335} INFO - retrain xgboost for 12.1s
[flaml.automl: 09-23 07:16:47] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.918062466998774, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5408133424638543,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.315923353235719, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.06367926097691767, scale_pos_weight=1,
             subsample=0.8916198382943978, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 07:16:47] {2636} INFO - fit succeeded
[flaml.automl: 09-23 07:16:47] {2637} INFO - Time taken to find the best model: 37.82469153404236
O3(0)最佳参数：{'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.315923353235719, 'learning_rate': 0.5408133424638543, 'subsample': 0.8916198382943978, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.918062466998774, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.06367926097691767, 'FLAML_sample_size': 122646}
O3(0)最佳损失：-5.305511796978196
O3(0)最好结果：{'pred_time': 2.4009807598986233e-06, 'wall_clock_time': 37.82469153404236, 'metric_for_logging': {'pred_time': 2.4009807598986233e-06}, 'val_loss': 6.305511796978196, 'training_iteration': 1, 'config': {'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.315923353235719, 'learning_rate': 0.5408133424638543, 'subsample': 0.8916198382943978, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.918062466998774, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.06367926097691767, 'FLAML_sample_size': 122646}, 'config/n_estimators': 31, 'config/max_leaves': 7, 'config/min_child_weight': 0.315923353235719, 'config/learning_rate': 0.5408133424638543, 'config/subsample': 0.8916198382943978, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.918062466998774, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.06367926097691767, 'config/FLAML_sample_size': 122646, 'experiment_tag': 'exp', 'time_total_s': 12.139342784881592}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.918062466998774, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5408133424638543,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.315923353235719, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.06367926097691767, scale_pos_weight=1,
             subsample=0.8916198382943978, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
O3(0)的R2=0.9585803797005308
O3(0)的mse=81.75778623410366
O3(0)的mae=6.261131651392505
O3(0)的mar=0.21477104277123565
总共花费的时间为：73.84
石家庄市
1030A
1032A
1033A
1035A
2862A
3456A
3572A
3573A
3574A
[flaml.automl: 09-23 07:38:48] {2390} INFO - task = regression
[flaml.automl: 09-23 07:38:48] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 07:38:48] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 07:38:48] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 07:38:48] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 07:38:48] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 07:38:50] {3025} INFO - Estimated sufficient time budget=109102s. Estimated necessary time budget=109s.
[flaml.automl: 09-23 07:38:50] {3072} INFO -  at 1.5s,	estimator xgboost's best error=44.4983,	best estimator xgboost's best error=44.4983
[flaml.automl: 09-23 07:38:50] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 07:38:51] {3072} INFO -  at 3.4s,	estimator xgboost's best error=21.7949,	best estimator xgboost's best error=21.7949
[flaml.automl: 09-23 07:38:51] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 07:38:53] {3072} INFO -  at 4.5s,	estimator xgboost's best error=21.7949,	best estimator xgboost's best error=21.7949
[flaml.automl: 09-23 07:38:53] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 07:38:55] {3072} INFO -  at 7.1s,	estimator xgboost's best error=21.7949,	best estimator xgboost's best error=21.7949
[flaml.automl: 09-23 07:38:55] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 07:38:56] {3072} INFO -  at 8.2s,	estimator xgboost's best error=12.9755,	best estimator xgboost's best error=12.9755
[flaml.automl: 09-23 07:38:56] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 07:38:58] {3072} INFO -  at 9.7s,	estimator xgboost's best error=11.9686,	best estimator xgboost's best error=11.9686
[flaml.automl: 09-23 07:38:58] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 07:38:59] {3072} INFO -  at 11.2s,	estimator xgboost's best error=10.2109,	best estimator xgboost's best error=10.2109
[flaml.automl: 09-23 07:38:59] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 07:39:01] {3072} INFO -  at 13.3s,	estimator xgboost's best error=10.2109,	best estimator xgboost's best error=10.2109
[flaml.automl: 09-23 07:39:01] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 07:39:03] {3072} INFO -  at 14.8s,	estimator xgboost's best error=10.2109,	best estimator xgboost's best error=10.2109
[flaml.automl: 09-23 07:39:03] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 07:39:05] {3072} INFO -  at 16.9s,	estimator xgboost's best error=10.2109,	best estimator xgboost's best error=10.2109
[flaml.automl: 09-23 07:39:05] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 07:39:05] {3072} INFO -  at 17.1s,	estimator xgboost's best error=10.2109,	best estimator xgboost's best error=10.2109
[flaml.automl: 09-23 07:39:05] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 07:39:07] {3072} INFO -  at 18.6s,	estimator xgboost's best error=10.2103,	best estimator xgboost's best error=10.2103
[flaml.automl: 09-23 07:39:07] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 07:39:08] {3072} INFO -  at 19.7s,	estimator xgboost's best error=10.2103,	best estimator xgboost's best error=10.2103
[flaml.automl: 09-23 07:39:08] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 07:39:14] {3072} INFO -  at 25.8s,	estimator xgboost's best error=7.1488,	best estimator xgboost's best error=7.1488
[flaml.automl: 09-23 07:39:14] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 07:39:15] {3072} INFO -  at 26.5s,	estimator xgboost's best error=6.7905,	best estimator xgboost's best error=6.7905
[flaml.automl: 09-23 07:39:15] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 07:39:15] {3072} INFO -  at 26.7s,	estimator xgboost's best error=6.7905,	best estimator xgboost's best error=6.7905
[flaml.automl: 09-23 07:39:15] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 07:39:15] {3072} INFO -  at 26.9s,	estimator xgboost's best error=6.6456,	best estimator xgboost's best error=6.6456
[flaml.automl: 09-23 07:39:15] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 07:39:15] {3072} INFO -  at 27.2s,	estimator xgboost's best error=6.6456,	best estimator xgboost's best error=6.6456
[flaml.automl: 09-23 07:39:15] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 07:39:15] {3072} INFO -  at 27.3s,	estimator xgboost's best error=6.6456,	best estimator xgboost's best error=6.6456
[flaml.automl: 09-23 07:39:15] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 07:39:16] {3072} INFO -  at 27.6s,	estimator xgboost's best error=6.6456,	best estimator xgboost's best error=6.6456
[flaml.automl: 09-23 07:39:16] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 07:39:16] {3072} INFO -  at 27.8s,	estimator xgboost's best error=6.6456,	best estimator xgboost's best error=6.6456
[flaml.automl: 09-23 07:39:16] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 07:39:16] {3072} INFO -  at 28.1s,	estimator xgboost's best error=6.1976,	best estimator xgboost's best error=6.1976
[flaml.automl: 09-23 07:39:16] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 07:39:17] {3072} INFO -  at 29.1s,	estimator xgboost's best error=5.3085,	best estimator xgboost's best error=5.3085
[flaml.automl: 09-23 07:39:17] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 07:39:18] {3072} INFO -  at 29.7s,	estimator xgboost's best error=5.3085,	best estimator xgboost's best error=5.3085
[flaml.automl: 09-23 07:39:18] {2897} INFO - iteration 24, current learner xgboost
[flaml.automl: 09-23 07:39:21] {3072} INFO -  at 32.7s,	estimator xgboost's best error=5.3085,	best estimator xgboost's best error=5.3085
[flaml.automl: 09-23 07:39:21] {2897} INFO - iteration 25, current learner xgboost
[flaml.automl: 09-23 07:39:22] {3072} INFO -  at 33.5s,	estimator xgboost's best error=5.3085,	best estimator xgboost's best error=5.3085
[flaml.automl: 09-23 07:39:22] {2897} INFO - iteration 26, current learner xgboost
[flaml.automl: 09-23 07:39:23] {3072} INFO -  at 35.4s,	estimator xgboost's best error=5.3085,	best estimator xgboost's best error=5.3085
[flaml.automl: 09-23 07:39:23] {2897} INFO - iteration 27, current learner xgboost
[flaml.automl: 09-23 07:39:50] {3072} INFO -  at 61.7s,	estimator xgboost's best error=5.3085,	best estimator xgboost's best error=5.3085
[flaml.automl: 09-23 07:40:47] {3335} INFO - retrain xgboost for 57.5s
[flaml.automl: 09-23 07:40:47] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.947904794098435, colsample_bynode=1,
             colsample_bytree=0.7784498141584256, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.6023269513573992,
             max_delta_step=0, max_depth=0, max_leaves=44,
             min_child_weight=0.3381875847658707, missing=nan,
             monotone_constraints='()', n_estimators=25, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.0013141540442864, scale_pos_weight=1, subsample=1.0,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
[flaml.automl: 09-23 07:40:47] {2636} INFO - fit succeeded
[flaml.automl: 09-23 07:40:47] {2637} INFO - Time taken to find the best model: 29.140926122665405
O3(0)最佳参数：{'n_estimators': 128, 'max_leaves': 44, 'min_child_weight': 0.3381875847658707, 'learning_rate': 0.6023269513573992, 'subsample': 1.0, 'colsample_bylevel': 0.947904794098435, 'colsample_bytree': 0.7784498141584256, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0013141540442864, 'FLAML_sample_size': 97343}
O3(0)最佳损失：-4.308481972932556
O3(0)最好结果：{'pred_time': 1.664631641828097e-06, 'wall_clock_time': 29.140926122665405, 'metric_for_logging': {'pred_time': 1.664631641828097e-06}, 'val_loss': 5.308481972932556, 'training_iteration': 1, 'config': {'n_estimators': 128, 'max_leaves': 44, 'min_child_weight': 0.3381875847658707, 'learning_rate': 0.6023269513573992, 'subsample': 1.0, 'colsample_bylevel': 0.947904794098435, 'colsample_bytree': 0.7784498141584256, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0013141540442864, 'FLAML_sample_size': 97343}, 'config/n_estimators': 128, 'config/max_leaves': 44, 'config/min_child_weight': 0.3381875847658707, 'config/learning_rate': 0.6023269513573992, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.947904794098435, 'config/colsample_bytree': 0.7784498141584256, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.0013141540442864, 'config/FLAML_sample_size': 97343, 'experiment_tag': 'exp', 'time_total_s': 1.0112535953521729}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.947904794098435, colsample_bynode=1,
             colsample_bytree=0.7784498141584256, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.6023269513573992,
             max_delta_step=0, max_depth=0, max_leaves=44,
             min_child_weight=0.3381875847658707, missing=nan,
             monotone_constraints='()', n_estimators=25, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.0013141540442864, scale_pos_weight=1, subsample=1.0,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
O3(0)的R2=0.9657858128353691
O3(0)的mse=75.38920297244749
O3(0)的mae=5.91605504986564
O3(0)的mar=0.1911405043517801
总共花费的时间为：120.76
唐山市
1041A
3575A
3576A
3577A
3578A
3692A
[flaml.automl: 09-23 07:56:02] {2390} INFO - task = regression
[flaml.automl: 09-23 07:56:02] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 07:56:02] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 07:56:02] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 07:56:02] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 07:56:02] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 07:56:04] {3025} INFO - Estimated sufficient time budget=67320s. Estimated necessary time budget=67s.
[flaml.automl: 09-23 07:56:04] {3072} INFO -  at 1.3s,	estimator xgboost's best error=40.0051,	best estimator xgboost's best error=40.0051
[flaml.automl: 09-23 07:56:04] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 07:56:05] {3072} INFO -  at 3.2s,	estimator xgboost's best error=19.8552,	best estimator xgboost's best error=19.8552
[flaml.automl: 09-23 07:56:05] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 07:56:07] {3072} INFO -  at 4.4s,	estimator xgboost's best error=19.8552,	best estimator xgboost's best error=19.8552
[flaml.automl: 09-23 07:56:07] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 07:56:11] {3072} INFO -  at 8.9s,	estimator xgboost's best error=19.8552,	best estimator xgboost's best error=19.8552
[flaml.automl: 09-23 07:56:11] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 07:56:12] {3072} INFO -  at 10.0s,	estimator xgboost's best error=12.4635,	best estimator xgboost's best error=12.4635
[flaml.automl: 09-23 07:56:12] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 07:56:14] {3072} INFO -  at 11.5s,	estimator xgboost's best error=10.9355,	best estimator xgboost's best error=10.9355
[flaml.automl: 09-23 07:56:14] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 07:56:15] {3072} INFO -  at 13.0s,	estimator xgboost's best error=10.1557,	best estimator xgboost's best error=10.1557
[flaml.automl: 09-23 07:56:15] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 07:56:18] {3072} INFO -  at 15.6s,	estimator xgboost's best error=10.1557,	best estimator xgboost's best error=10.1557
[flaml.automl: 09-23 07:56:18] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 07:56:19] {3072} INFO -  at 17.1s,	estimator xgboost's best error=10.1557,	best estimator xgboost's best error=10.1557
[flaml.automl: 09-23 07:56:19] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 07:56:22] {3072} INFO -  at 19.9s,	estimator xgboost's best error=9.1778,	best estimator xgboost's best error=9.1778
[flaml.automl: 09-23 07:56:22] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 07:56:24] {3072} INFO -  at 21.5s,	estimator xgboost's best error=9.1778,	best estimator xgboost's best error=9.1778
[flaml.automl: 09-23 07:56:24] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 07:56:25] {3072} INFO -  at 22.5s,	estimator xgboost's best error=9.1778,	best estimator xgboost's best error=9.1778
[flaml.automl: 09-23 07:56:25] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 07:56:27] {3072} INFO -  at 25.3s,	estimator xgboost's best error=8.6652,	best estimator xgboost's best error=8.6652
[flaml.automl: 09-23 07:56:27] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 07:56:30] {3072} INFO -  at 28.0s,	estimator xgboost's best error=8.6652,	best estimator xgboost's best error=8.6652
[flaml.automl: 09-23 07:56:30] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 07:56:33] {3072} INFO -  at 30.4s,	estimator xgboost's best error=8.6652,	best estimator xgboost's best error=8.6652
[flaml.automl: 09-23 07:56:33] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 07:56:34] {3072} INFO -  at 32.0s,	estimator xgboost's best error=8.6652,	best estimator xgboost's best error=8.6652
[flaml.automl: 09-23 07:56:34] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 07:56:36] {3072} INFO -  at 34.1s,	estimator xgboost's best error=8.4765,	best estimator xgboost's best error=8.4765
[flaml.automl: 09-23 07:56:36] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 07:56:38] {3072} INFO -  at 36.1s,	estimator xgboost's best error=8.4765,	best estimator xgboost's best error=8.4765
[flaml.automl: 09-23 07:56:38] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 07:56:40] {3072} INFO -  at 37.3s,	estimator xgboost's best error=8.4765,	best estimator xgboost's best error=8.4765
[flaml.automl: 09-23 07:56:40] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 07:56:41] {3072} INFO -  at 38.9s,	estimator xgboost's best error=8.4765,	best estimator xgboost's best error=8.4765
[flaml.automl: 09-23 07:56:41] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 07:56:43] {3072} INFO -  at 40.6s,	estimator xgboost's best error=7.8450,	best estimator xgboost's best error=7.8450
[flaml.automl: 09-23 07:56:43] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 07:56:45] {3072} INFO -  at 42.4s,	estimator xgboost's best error=7.8450,	best estimator xgboost's best error=7.8450
[flaml.automl: 09-23 07:56:45] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 07:56:46] {3072} INFO -  at 43.6s,	estimator xgboost's best error=7.8450,	best estimator xgboost's best error=7.8450
[flaml.automl: 09-23 07:56:46] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 07:56:48] {3072} INFO -  at 46.0s,	estimator xgboost's best error=7.8450,	best estimator xgboost's best error=7.8450
[flaml.automl: 09-23 07:56:48] {2897} INFO - iteration 24, current learner xgboost
[flaml.automl: 09-23 07:56:49] {3072} INFO -  at 47.1s,	estimator xgboost's best error=7.8450,	best estimator xgboost's best error=7.8450
[flaml.automl: 09-23 07:56:49] {2897} INFO - iteration 25, current learner xgboost
[flaml.automl: 09-23 07:57:02] {3072} INFO -  at 59.6s,	estimator xgboost's best error=6.8299,	best estimator xgboost's best error=6.8299
[flaml.automl: 09-23 07:57:25] {3335} INFO - retrain xgboost for 22.8s
[flaml.automl: 09-23 07:57:25] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9549748879426012, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=1.0, max_delta_step=0,
             max_depth=0, max_leaves=18, min_child_weight=0.0013585590239522634,
             missing=nan, monotone_constraints='()', n_estimators=24, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.0024323671033404555, reg_lambda=0.0174163759593203,
             scale_pos_weight=1, subsample=0.9485031689135307,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
[flaml.automl: 09-23 07:57:25] {2636} INFO - fit succeeded
[flaml.automl: 09-23 07:57:25] {2637} INFO - Time taken to find the best model: 59.58905076980591
[flaml.automl: 09-23 07:57:25] {2648} WARNING - Time taken to find the best model is 99% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
O3(0)最佳参数：{'n_estimators': 24, 'max_leaves': 18, 'min_child_weight': 0.0013585590239522634, 'learning_rate': 1.0, 'subsample': 0.9485031689135307, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9549748879426012, 'reg_alpha': 0.0024323671033404555, 'reg_lambda': 0.0174163759593203, 'FLAML_sample_size': 60418}
O3(0)最佳损失：-5.829924575402991
O3(0)最好结果：{'pred_time': 5.597367967066397e-06, 'wall_clock_time': 59.58905076980591, 'metric_for_logging': {'pred_time': 5.597367967066397e-06}, 'val_loss': 6.829924575402991, 'training_iteration': 1, 'config': {'n_estimators': 24, 'max_leaves': 18, 'min_child_weight': 0.0013585590239522634, 'learning_rate': 1.0, 'subsample': 0.9485031689135307, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9549748879426012, 'reg_alpha': 0.0024323671033404555, 'reg_lambda': 0.0174163759593203, 'FLAML_sample_size': 60418}, 'config/n_estimators': 24, 'config/max_leaves': 18, 'config/min_child_weight': 0.0013585590239522634, 'config/learning_rate': 1.0, 'config/subsample': 0.9485031689135307, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9549748879426012, 'config/reg_alpha': 0.0024323671033404555, 'config/reg_lambda': 0.0174163759593203, 'config/FLAML_sample_size': 60418, 'experiment_tag': 'exp', 'time_total_s': 12.533370733261108}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9549748879426012, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=1.0, max_delta_step=0,
             max_depth=0, max_leaves=18, min_child_weight=0.0013585590239522634,
             missing=nan, monotone_constraints='()', n_estimators=24, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.0024323671033404555, reg_lambda=0.0174163759593203,
             scale_pos_weight=1, subsample=0.9485031689135307,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
O3(0)的R2=0.9542366228554569
O3(0)的mse=92.04338110012931
O3(0)的mae=6.32480450871403
O3(0)的mar=0.27969562355899336
总共花费的时间为：83.42
秦皇岛市
1043A
1044A
3132A
[flaml.automl: 09-23 08:05:24] {2390} INFO - task = regression
[flaml.automl: 09-23 08:05:24] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 08:05:24] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 08:05:24] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 08:05:24] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 08:05:24] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 08:05:25] {3025} INFO - Estimated sufficient time budget=11125s. Estimated necessary time budget=11s.
[flaml.automl: 09-23 08:05:25] {3072} INFO -  at 1.2s,	estimator xgboost's best error=42.1289,	best estimator xgboost's best error=42.1289
[flaml.automl: 09-23 08:05:25] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 08:05:27] {3072} INFO -  at 3.2s,	estimator xgboost's best error=21.3513,	best estimator xgboost's best error=21.3513
[flaml.automl: 09-23 08:05:27] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 08:05:28] {3072} INFO -  at 4.4s,	estimator xgboost's best error=21.3513,	best estimator xgboost's best error=21.3513
[flaml.automl: 09-23 08:05:28] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 08:05:38] {3072} INFO -  at 13.7s,	estimator xgboost's best error=21.3513,	best estimator xgboost's best error=21.3513
[flaml.automl: 09-23 08:05:38] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 08:05:39] {3072} INFO -  at 14.8s,	estimator xgboost's best error=12.9253,	best estimator xgboost's best error=12.9253
[flaml.automl: 09-23 08:05:39] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 08:05:40] {3072} INFO -  at 16.3s,	estimator xgboost's best error=11.3156,	best estimator xgboost's best error=11.3156
[flaml.automl: 09-23 08:05:40] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 08:05:42] {3072} INFO -  at 17.8s,	estimator xgboost's best error=10.5965,	best estimator xgboost's best error=10.5965
[flaml.automl: 09-23 08:05:42] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 08:05:44] {3072} INFO -  at 20.3s,	estimator xgboost's best error=10.5965,	best estimator xgboost's best error=10.5965
[flaml.automl: 09-23 08:05:44] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 08:05:46] {3072} INFO -  at 21.8s,	estimator xgboost's best error=10.5965,	best estimator xgboost's best error=10.5965
[flaml.automl: 09-23 08:05:46] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 08:05:49] {3072} INFO -  at 24.7s,	estimator xgboost's best error=9.8653,	best estimator xgboost's best error=9.8653
[flaml.automl: 09-23 08:05:49] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 08:05:50] {3072} INFO -  at 26.2s,	estimator xgboost's best error=9.8653,	best estimator xgboost's best error=9.8653
[flaml.automl: 09-23 08:05:50] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 08:05:51] {3072} INFO -  at 27.3s,	estimator xgboost's best error=9.8653,	best estimator xgboost's best error=9.8653
[flaml.automl: 09-23 08:05:51] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 08:06:04] {3072} INFO -  at 40.1s,	estimator xgboost's best error=8.0209,	best estimator xgboost's best error=8.0209
[flaml.automl: 09-23 08:06:04] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 08:06:24] {3072} INFO -  at 59.5s,	estimator xgboost's best error=7.1330,	best estimator xgboost's best error=7.1330
[flaml.automl: 09-23 08:06:46] {3335} INFO - retrain xgboost for 22.4s
[flaml.automl: 09-23 08:06:46] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9525984164347239, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.4430733351694866,
             max_delta_step=0, max_depth=0, max_leaves=12,
             min_child_weight=0.015279685963846733, missing=nan,
             monotone_constraints='()', n_estimators=35, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.040287291571763306, scale_pos_weight=1,
             subsample=0.8021498947235678, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 08:06:46] {2636} INFO - fit succeeded
[flaml.automl: 09-23 08:06:46] {2637} INFO - Time taken to find the best model: 59.52919030189514
[flaml.automl: 09-23 08:06:46] {2648} WARNING - Time taken to find the best model is 99% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
O3(0)最佳参数：{'n_estimators': 35, 'max_leaves': 12, 'min_child_weight': 0.015279685963846733, 'learning_rate': 0.4430733351694866, 'subsample': 0.8021498947235678, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9525984164347239, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.040287291571763306}
O3(0)最佳损失：-6.133014329120393
O3(0)最好结果：{'pred_time': 1.0817334922727125e-05, 'wall_clock_time': 59.52919030189514, 'metric_for_logging': {'pred_time': 1.0817334922727125e-05}, 'val_loss': 7.133014329120393, 'training_iteration': 1, 'config': {'n_estimators': 35, 'max_leaves': 12, 'min_child_weight': 0.015279685963846733, 'learning_rate': 0.4430733351694866, 'subsample': 0.8021498947235678, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9525984164347239, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.040287291571763306}, 'config/n_estimators': 35, 'config/max_leaves': 12, 'config/min_child_weight': 0.015279685963846733, 'config/learning_rate': 0.4430733351694866, 'config/subsample': 0.8021498947235678, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9525984164347239, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.040287291571763306, 'experiment_tag': 'exp', 'time_total_s': 19.411630630493164}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9525984164347239, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.4430733351694866,
             max_delta_step=0, max_depth=0, max_leaves=12,
             min_child_weight=0.015279685963846733, missing=nan,
             monotone_constraints='()', n_estimators=35, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.040287291571763306, scale_pos_weight=1,
             subsample=0.8021498947235678, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
O3(0)的R2=0.9306088659486509
O3(0)的mse=118.1778584359513
O3(0)的mae=7.0263536747169875
O3(0)的mar=0.2572535731722178
总共花费的时间为：82.49
邯郸市
1050A
3579A
3580A
[flaml.automl: 09-23 08:14:14] {2390} INFO - task = regression
[flaml.automl: 09-23 08:14:14] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 08:14:14] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 08:14:14] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 08:14:14] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 08:14:14] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 08:14:15] {3025} INFO - Estimated sufficient time budget=11284s. Estimated necessary time budget=11s.
[flaml.automl: 09-23 08:14:15] {3072} INFO -  at 1.2s,	estimator xgboost's best error=46.4806,	best estimator xgboost's best error=46.4806
[flaml.automl: 09-23 08:14:15] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 08:14:17] {3072} INFO -  at 3.2s,	estimator xgboost's best error=22.3302,	best estimator xgboost's best error=22.3302
[flaml.automl: 09-23 08:14:17] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 08:14:19] {3072} INFO -  at 4.3s,	estimator xgboost's best error=22.3302,	best estimator xgboost's best error=22.3302
[flaml.automl: 09-23 08:14:19] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 08:14:28] {3072} INFO -  at 13.9s,	estimator xgboost's best error=22.3302,	best estimator xgboost's best error=22.3302
[flaml.automl: 09-23 08:14:28] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 08:14:29] {3072} INFO -  at 15.0s,	estimator xgboost's best error=12.5607,	best estimator xgboost's best error=12.5607
[flaml.automl: 09-23 08:14:29] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 08:14:30] {3072} INFO -  at 15.8s,	estimator xgboost's best error=10.6039,	best estimator xgboost's best error=10.6039
[flaml.automl: 09-23 08:14:30] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 08:14:31] {3072} INFO -  at 16.8s,	estimator xgboost's best error=9.8639,	best estimator xgboost's best error=9.8639
[flaml.automl: 09-23 08:14:31] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 08:14:32] {3072} INFO -  at 17.5s,	estimator xgboost's best error=9.8639,	best estimator xgboost's best error=9.8639
[flaml.automl: 09-23 08:14:32] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 08:14:33] {3072} INFO -  at 19.0s,	estimator xgboost's best error=9.8639,	best estimator xgboost's best error=9.8639
[flaml.automl: 09-23 08:14:33] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 08:14:36] {3072} INFO -  at 22.0s,	estimator xgboost's best error=8.8658,	best estimator xgboost's best error=8.8658
[flaml.automl: 09-23 08:14:36] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 08:14:38] {3072} INFO -  at 23.4s,	estimator xgboost's best error=8.8658,	best estimator xgboost's best error=8.8658
[flaml.automl: 09-23 08:14:38] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 08:14:38] {3072} INFO -  at 23.6s,	estimator xgboost's best error=8.8658,	best estimator xgboost's best error=8.8658
[flaml.automl: 09-23 08:14:38] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 08:14:45] {3072} INFO -  at 30.5s,	estimator xgboost's best error=6.8827,	best estimator xgboost's best error=6.8827
[flaml.automl: 09-23 08:14:45] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 08:15:03] {3072} INFO -  at 48.3s,	estimator xgboost's best error=6.0218,	best estimator xgboost's best error=6.0218
[flaml.automl: 09-23 08:15:13] {3335} INFO - retrain xgboost for 10.3s
[flaml.automl: 09-23 08:15:13] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9525984164347239, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.4430733351694866,
             max_delta_step=0, max_depth=0, max_leaves=12,
             min_child_weight=0.015279685963846733, missing=nan,
             monotone_constraints='()', n_estimators=35, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.040287291571763306, scale_pos_weight=1,
             subsample=0.8021498947235678, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 08:15:13] {2636} INFO - fit succeeded
[flaml.automl: 09-23 08:15:13] {2637} INFO - Time taken to find the best model: 48.33842658996582
[flaml.automl: 09-23 08:15:13] {2648} WARNING - Time taken to find the best model is 81% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
O3(0)最佳参数：{'n_estimators': 35, 'max_leaves': 12, 'min_child_weight': 0.015279685963846733, 'learning_rate': 0.4430733351694866, 'subsample': 0.8021498947235678, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9525984164347239, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.040287291571763306}
O3(0)最佳损失：-5.021822316239455
O3(0)最好结果：{'pred_time': 1.0502258581774576e-05, 'wall_clock_time': 48.33842658996582, 'metric_for_logging': {'pred_time': 1.0502258581774576e-05}, 'val_loss': 6.021822316239455, 'training_iteration': 1, 'config': {'n_estimators': 35, 'max_leaves': 12, 'min_child_weight': 0.015279685963846733, 'learning_rate': 0.4430733351694866, 'subsample': 0.8021498947235678, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9525984164347239, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.040287291571763306}, 'config/n_estimators': 35, 'config/max_leaves': 12, 'config/min_child_weight': 0.015279685963846733, 'config/learning_rate': 0.4430733351694866, 'config/subsample': 0.8021498947235678, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.9525984164347239, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.040287291571763306, 'experiment_tag': 'exp', 'time_total_s': 17.867384910583496}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.9525984164347239, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.4430733351694866,
             max_delta_step=0, max_depth=0, max_leaves=12,
             min_child_weight=0.015279685963846733, missing=nan,
             monotone_constraints='()', n_estimators=35, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.040287291571763306, scale_pos_weight=1,
             subsample=0.8021498947235678, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
O3(0)的R2=0.9595676790733463
O3(0)的mse=83.56586460520244
O3(0)的mae=6.121145775432206
O3(0)的mar=0.19108162331413625
总共花费的时间为：59.11
保定市
1051A
1053A
1054A
1055A
1056A
3581A
3582A
3583A
[flaml.automl: 09-23 08:34:59] {2390} INFO - task = regression
[flaml.automl: 09-23 08:34:59] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 08:34:59] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 08:35:00] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 08:35:00] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 08:35:00] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 08:35:01] {3025} INFO - Estimated sufficient time budget=98821s. Estimated necessary time budget=99s.
[flaml.automl: 09-23 08:35:01] {3072} INFO -  at 1.4s,	estimator xgboost's best error=42.8248,	best estimator xgboost's best error=42.8248
[flaml.automl: 09-23 08:35:01] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 08:35:03] {3072} INFO -  at 3.4s,	estimator xgboost's best error=21.1980,	best estimator xgboost's best error=21.1980
[flaml.automl: 09-23 08:35:03] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 08:35:04] {3072} INFO -  at 4.6s,	estimator xgboost's best error=21.1980,	best estimator xgboost's best error=21.1980
[flaml.automl: 09-23 08:35:04] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 08:35:07] {3072} INFO -  at 7.7s,	estimator xgboost's best error=21.1980,	best estimator xgboost's best error=21.1980
[flaml.automl: 09-23 08:35:07] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 08:35:08] {3072} INFO -  at 8.7s,	estimator xgboost's best error=12.5897,	best estimator xgboost's best error=12.5897
[flaml.automl: 09-23 08:35:08] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 08:35:09] {3072} INFO -  at 10.2s,	estimator xgboost's best error=11.4687,	best estimator xgboost's best error=11.4687
[flaml.automl: 09-23 08:35:09] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 08:35:11] {3072} INFO -  at 11.7s,	estimator xgboost's best error=10.0541,	best estimator xgboost's best error=10.0541
[flaml.automl: 09-23 08:35:11] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 08:35:13] {3072} INFO -  at 14.2s,	estimator xgboost's best error=10.0541,	best estimator xgboost's best error=10.0541
[flaml.automl: 09-23 08:35:13] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 08:35:15] {3072} INFO -  at 15.7s,	estimator xgboost's best error=10.0541,	best estimator xgboost's best error=10.0541
[flaml.automl: 09-23 08:35:15] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 08:35:17] {3072} INFO -  at 17.8s,	estimator xgboost's best error=10.0541,	best estimator xgboost's best error=10.0541
[flaml.automl: 09-23 08:35:17] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 08:35:18] {3072} INFO -  at 19.2s,	estimator xgboost's best error=10.0541,	best estimator xgboost's best error=10.0541
[flaml.automl: 09-23 08:35:18] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 08:35:20] {3072} INFO -  at 20.7s,	estimator xgboost's best error=10.0541,	best estimator xgboost's best error=10.0541
[flaml.automl: 09-23 08:35:20] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 08:35:21] {3072} INFO -  at 21.8s,	estimator xgboost's best error=10.0541,	best estimator xgboost's best error=10.0541
[flaml.automl: 09-23 08:35:21] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 08:35:28] {3072} INFO -  at 28.3s,	estimator xgboost's best error=7.2664,	best estimator xgboost's best error=7.2664
[flaml.automl: 09-23 08:35:28] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 08:35:40] {3072} INFO -  at 40.4s,	estimator xgboost's best error=6.7288,	best estimator xgboost's best error=6.7288
[flaml.automl: 09-23 08:35:40] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 08:35:46] {3072} INFO -  at 46.9s,	estimator xgboost's best error=6.7288,	best estimator xgboost's best error=6.7288
[flaml.automl: 09-23 08:35:46] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 08:35:59] {3072} INFO -  at 59.8s,	estimator xgboost's best error=6.7288,	best estimator xgboost's best error=6.7288
[flaml.automl: 09-23 08:36:11] {3335} INFO - retrain xgboost for 12.0s
[flaml.automl: 09-23 08:36:11] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.918062466998774, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5408133424638543,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.315923353235719, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.06367926097691767, scale_pos_weight=1,
             subsample=0.8916198382943978, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 08:36:11] {2636} INFO - fit succeeded
[flaml.automl: 09-23 08:36:11] {2637} INFO - Time taken to find the best model: 40.370009899139404
O3(0)最佳参数：{'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.315923353235719, 'learning_rate': 0.5408133424638543, 'subsample': 0.8916198382943978, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.918062466998774, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.06367926097691767, 'FLAML_sample_size': 87892}
O3(0)最佳损失：-5.728797697814034
O3(0)最好结果：{'pred_time': 4.018498033425517e-06, 'wall_clock_time': 40.370009899139404, 'metric_for_logging': {'pred_time': 4.018498033425517e-06}, 'val_loss': 6.728797697814034, 'training_iteration': 1, 'config': {'n_estimators': 31, 'max_leaves': 7, 'min_child_weight': 0.315923353235719, 'learning_rate': 0.5408133424638543, 'subsample': 0.8916198382943978, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.918062466998774, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.06367926097691767, 'FLAML_sample_size': 87892}, 'config/n_estimators': 31, 'config/max_leaves': 7, 'config/min_child_weight': 0.315923353235719, 'config/learning_rate': 0.5408133424638543, 'config/subsample': 0.8916198382943978, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.918062466998774, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.06367926097691767, 'config/FLAML_sample_size': 87892, 'experiment_tag': 'exp', 'time_total_s': 12.050972938537598}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.918062466998774, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5408133424638543,
             max_delta_step=0, max_depth=0, max_leaves=7,
             min_child_weight=0.315923353235719, missing=nan,
             monotone_constraints='()', n_estimators=31, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.06367926097691767, scale_pos_weight=1,
             subsample=0.8916198382943978, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
O3(0)的R2=0.9588863440913863
O3(0)的mse=93.04813058324054
O3(0)的mae=6.649362128621043
O3(0)的mar=0.23666437154568826
总共花费的时间为：73.11
张家口市
1060A
1061A
3131A
3323A
[flaml.automl: 09-23 08:46:24] {2390} INFO - task = regression
[flaml.automl: 09-23 08:46:24] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 08:46:24] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 08:46:24] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 08:46:24] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 08:46:24] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 08:46:25] {3025} INFO - Estimated sufficient time budget=47748s. Estimated necessary time budget=48s.
[flaml.automl: 09-23 08:46:25] {3072} INFO -  at 1.3s,	estimator xgboost's best error=48.2145,	best estimator xgboost's best error=48.2145
[flaml.automl: 09-23 08:46:25] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 08:46:27] {3072} INFO -  at 3.3s,	estimator xgboost's best error=22.2940,	best estimator xgboost's best error=22.2940
[flaml.automl: 09-23 08:46:27] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 08:46:29] {3072} INFO -  at 4.4s,	estimator xgboost's best error=22.2940,	best estimator xgboost's best error=22.2940
[flaml.automl: 09-23 08:46:29] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 08:46:35] {3072} INFO -  at 10.9s,	estimator xgboost's best error=22.2940,	best estimator xgboost's best error=22.2940
[flaml.automl: 09-23 08:46:35] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 08:46:36] {3072} INFO -  at 11.9s,	estimator xgboost's best error=10.6075,	best estimator xgboost's best error=10.6075
[flaml.automl: 09-23 08:46:36] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 08:46:38] {3072} INFO -  at 13.4s,	estimator xgboost's best error=8.9201,	best estimator xgboost's best error=8.9201
[flaml.automl: 09-23 08:46:38] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 08:46:39] {3072} INFO -  at 14.9s,	estimator xgboost's best error=7.6751,	best estimator xgboost's best error=7.6751
[flaml.automl: 09-23 08:46:39] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 08:46:42] {3072} INFO -  at 17.5s,	estimator xgboost's best error=7.6751,	best estimator xgboost's best error=7.6751
[flaml.automl: 09-23 08:46:42] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 08:46:43] {3072} INFO -  at 19.0s,	estimator xgboost's best error=7.6751,	best estimator xgboost's best error=7.6751
[flaml.automl: 09-23 08:46:43] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 08:46:46] {3072} INFO -  at 21.8s,	estimator xgboost's best error=7.6634,	best estimator xgboost's best error=7.6634
[flaml.automl: 09-23 08:46:46] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 08:46:48] {3072} INFO -  at 23.3s,	estimator xgboost's best error=7.6634,	best estimator xgboost's best error=7.6634
[flaml.automl: 09-23 08:46:48] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 08:46:49] {3072} INFO -  at 24.4s,	estimator xgboost's best error=7.6634,	best estimator xgboost's best error=7.6634
[flaml.automl: 09-23 08:46:49] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 08:46:52] {3072} INFO -  at 27.9s,	estimator xgboost's best error=6.7171,	best estimator xgboost's best error=6.7171
[flaml.automl: 09-23 08:46:52] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 08:46:55] {3072} INFO -  at 31.2s,	estimator xgboost's best error=6.7171,	best estimator xgboost's best error=6.7171
[flaml.automl: 09-23 08:46:55] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 08:46:58] {3072} INFO -  at 33.7s,	estimator xgboost's best error=6.7171,	best estimator xgboost's best error=6.7171
[flaml.automl: 09-23 08:46:58] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 08:47:00] {3072} INFO -  at 35.4s,	estimator xgboost's best error=6.7171,	best estimator xgboost's best error=6.7171
[flaml.automl: 09-23 08:47:00] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 08:47:02] {3072} INFO -  at 37.9s,	estimator xgboost's best error=6.4304,	best estimator xgboost's best error=6.4304
[flaml.automl: 09-23 08:47:02] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 08:47:05] {3072} INFO -  at 40.3s,	estimator xgboost's best error=6.4304,	best estimator xgboost's best error=6.4304
[flaml.automl: 09-23 08:47:05] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 08:47:06] {3072} INFO -  at 41.5s,	estimator xgboost's best error=6.4304,	best estimator xgboost's best error=6.4304
[flaml.automl: 09-23 08:47:06] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 08:47:08] {3072} INFO -  at 43.7s,	estimator xgboost's best error=6.4304,	best estimator xgboost's best error=6.4304
[flaml.automl: 09-23 08:47:08] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 08:47:09] {3072} INFO -  at 44.8s,	estimator xgboost's best error=6.4304,	best estimator xgboost's best error=6.4304
[flaml.automl: 09-23 08:47:09] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 08:47:16] {3072} INFO -  at 52.2s,	estimator xgboost's best error=5.4307,	best estimator xgboost's best error=5.4307
[flaml.automl: 09-23 08:47:16] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 08:47:24] {3072} INFO -  at 59.6s,	estimator xgboost's best error=5.1434,	best estimator xgboost's best error=5.1434
[flaml.automl: 09-23 08:47:58] {3335} INFO - retrain xgboost for 34.1s
[flaml.automl: 09-23 08:47:58] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.8870008876841574, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5025866867945519,
             max_delta_step=0, max_depth=0, max_leaves=17,
             min_child_weight=0.008718108515031738, missing=nan,
             monotone_constraints='()', n_estimators=38, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.00672395905185771, scale_pos_weight=1,
             subsample=0.8853384301102215, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 08:47:58] {2636} INFO - fit succeeded
[flaml.automl: 09-23 08:47:58] {2637} INFO - Time taken to find the best model: 59.64584398269653
[flaml.automl: 09-23 08:47:58] {2648} WARNING - Time taken to find the best model is 99% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
O3(0)最佳参数：{'n_estimators': 38, 'max_leaves': 17, 'min_child_weight': 0.008718108515031738, 'learning_rate': 0.5025866867945519, 'subsample': 0.8853384301102215, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8870008876841574, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.00672395905185771, 'FLAML_sample_size': 41919}
O3(0)最佳损失：-4.143423976791729
O3(0)最好结果：{'pred_time': 8.489400749812571e-06, 'wall_clock_time': 59.64584398269653, 'metric_for_logging': {'pred_time': 8.489400749812571e-06}, 'val_loss': 5.143423976791729, 'training_iteration': 1, 'config': {'n_estimators': 38, 'max_leaves': 17, 'min_child_weight': 0.008718108515031738, 'learning_rate': 0.5025866867945519, 'subsample': 0.8853384301102215, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8870008876841574, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.00672395905185771, 'FLAML_sample_size': 41919}, 'config/n_estimators': 38, 'config/max_leaves': 17, 'config/min_child_weight': 0.008718108515031738, 'config/learning_rate': 0.5025866867945519, 'config/subsample': 0.8853384301102215, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.8870008876841574, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.00672395905185771, 'config/FLAML_sample_size': 41919, 'experiment_tag': 'exp', 'time_total_s': 7.412174940109253}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.8870008876841574, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5025866867945519,
             max_delta_step=0, max_depth=0, max_leaves=17,
             min_child_weight=0.008718108515031738, missing=nan,
             monotone_constraints='()', n_estimators=38, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.00672395905185771, scale_pos_weight=1,
             subsample=0.8853384301102215, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
O3(0)的R2=0.9542587080774456
O3(0)的mse=47.02604384650169
O3(0)的mae=4.482334431761752
O3(0)的mar=0.07177475789666499
总共花费的时间为：94.75
承德市
1063A
1064A
1065A
[flaml.automl: 09-23 08:55:23] {2390} INFO - task = regression
[flaml.automl: 09-23 08:55:23] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 08:55:23] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 08:55:23] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 08:55:23] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 08:55:23] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 08:55:24] {3025} INFO - Estimated sufficient time budget=11297s. Estimated necessary time budget=11s.
[flaml.automl: 09-23 08:55:24] {3072} INFO -  at 1.2s,	estimator xgboost's best error=35.5323,	best estimator xgboost's best error=35.5323
[flaml.automl: 09-23 08:55:24] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 08:55:26] {3072} INFO -  at 3.2s,	estimator xgboost's best error=17.6453,	best estimator xgboost's best error=17.6453
[flaml.automl: 09-23 08:55:26] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 08:55:27] {3072} INFO -  at 4.3s,	estimator xgboost's best error=17.6453,	best estimator xgboost's best error=17.6453
[flaml.automl: 09-23 08:55:27] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 08:55:37] {3072} INFO -  at 13.3s,	estimator xgboost's best error=17.6453,	best estimator xgboost's best error=17.6453
[flaml.automl: 09-23 08:55:37] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 08:55:38] {3072} INFO -  at 14.4s,	estimator xgboost's best error=10.7268,	best estimator xgboost's best error=10.7268
[flaml.automl: 09-23 08:55:38] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 08:55:39] {3072} INFO -  at 16.0s,	estimator xgboost's best error=10.0284,	best estimator xgboost's best error=10.0284
[flaml.automl: 09-23 08:55:39] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 08:55:41] {3072} INFO -  at 17.9s,	estimator xgboost's best error=8.5344,	best estimator xgboost's best error=8.5344
[flaml.automl: 09-23 08:55:41] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 08:55:44] {3072} INFO -  at 21.2s,	estimator xgboost's best error=8.5344,	best estimator xgboost's best error=8.5344
[flaml.automl: 09-23 08:55:44] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 08:55:46] {3072} INFO -  at 23.0s,	estimator xgboost's best error=8.5344,	best estimator xgboost's best error=8.5344
[flaml.automl: 09-23 08:55:46] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 08:55:50] {3072} INFO -  at 26.9s,	estimator xgboost's best error=7.6712,	best estimator xgboost's best error=7.6712
[flaml.automl: 09-23 08:55:50] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 08:55:52] {3072} INFO -  at 29.2s,	estimator xgboost's best error=7.6712,	best estimator xgboost's best error=7.6712
[flaml.automl: 09-23 08:55:52] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 08:55:54] {3072} INFO -  at 30.6s,	estimator xgboost's best error=7.6712,	best estimator xgboost's best error=7.6712
[flaml.automl: 09-23 08:55:54] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 08:56:10] {3072} INFO -  at 46.6s,	estimator xgboost's best error=5.7803,	best estimator xgboost's best error=5.7803
[flaml.automl: 09-23 08:56:25] {3335} INFO - retrain xgboost for 15.3s
[flaml.automl: 09-23 08:56:25] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.8647803489281933, colsample_bynode=1,
             colsample_bytree=0.8708956493972435, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.8192721968561636,
             max_delta_step=0, max_depth=0, max_leaves=16,
             min_child_weight=0.026530416426483502, missing=nan,
             monotone_constraints='()', n_estimators=15, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.003048836975765305, reg_lambda=0.20419943387794007,
             scale_pos_weight=1, subsample=0.9099932448156185,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
[flaml.automl: 09-23 08:56:25] {2636} INFO - fit succeeded
[flaml.automl: 09-23 08:56:25] {2637} INFO - Time taken to find the best model: 46.55185890197754
[flaml.automl: 09-23 08:56:25] {2648} WARNING - Time taken to find the best model is 78% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
O3(0)最佳参数：{'n_estimators': 15, 'max_leaves': 16, 'min_child_weight': 0.026530416426483502, 'learning_rate': 0.8192721968561636, 'subsample': 0.9099932448156185, 'colsample_bylevel': 0.8647803489281933, 'colsample_bytree': 0.8708956493972435, 'reg_alpha': 0.003048836975765305, 'reg_lambda': 0.20419943387794007}
O3(0)最佳损失：-4.7802980578901
O3(0)最好结果：{'pred_time': 1.8239482077098827e-05, 'wall_clock_time': 46.55185890197754, 'metric_for_logging': {'pred_time': 1.8239482077098827e-05}, 'val_loss': 5.7802980578901, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_leaves': 16, 'min_child_weight': 0.026530416426483502, 'learning_rate': 0.8192721968561636, 'subsample': 0.9099932448156185, 'colsample_bylevel': 0.8647803489281933, 'colsample_bytree': 0.8708956493972435, 'reg_alpha': 0.003048836975765305, 'reg_lambda': 0.20419943387794007}, 'config/n_estimators': 15, 'config/max_leaves': 16, 'config/min_child_weight': 0.026530416426483502, 'config/learning_rate': 0.8192721968561636, 'config/subsample': 0.9099932448156185, 'config/colsample_bylevel': 0.8647803489281933, 'config/colsample_bytree': 0.8708956493972435, 'config/reg_alpha': 0.003048836975765305, 'config/reg_lambda': 0.20419943387794007, 'experiment_tag': 'exp', 'time_total_s': 15.993689060211182}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.8647803489281933, colsample_bynode=1,
             colsample_bytree=0.8708956493972435, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.8192721968561636,
             max_delta_step=0, max_depth=0, max_leaves=16,
             min_child_weight=0.026530416426483502, missing=nan,
             monotone_constraints='()', n_estimators=15, n_jobs=-1,
             num_parallel_tree=1, random_state=0,
             reg_alpha=0.003048836975765305, reg_lambda=0.20419943387794007,
             scale_pos_weight=1, subsample=0.9099932448156185,
             tree_method='hist', use_label_encoder=False, validate_parameters=1,
             verbosity=0)
O3(0)的R2=0.94855060834922
O3(0)的mse=86.32209105903479
O3(0)的mae=6.2063507632931945
O3(0)的mar=0.2282968728831158
总共花费的时间为：62.35
廊坊市
1070A
2919A
[flaml.automl: 09-23 09:01:50] {2390} INFO - task = regression
[flaml.automl: 09-23 09:01:50] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 09:01:50] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 09:01:50] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 09:01:50] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 09:01:50] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 09:01:50] {3025} INFO - Estimated sufficient time budget=704s. Estimated necessary time budget=1s.
[flaml.automl: 09-23 09:01:50] {3072} INFO -  at 0.1s,	estimator xgboost's best error=44.1073,	best estimator xgboost's best error=44.1073
[flaml.automl: 09-23 09:01:50] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.2s,	estimator xgboost's best error=21.1674,	best estimator xgboost's best error=21.1674
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.2s,	estimator xgboost's best error=21.1674,	best estimator xgboost's best error=21.1674
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.3s,	estimator xgboost's best error=21.1674,	best estimator xgboost's best error=21.1674
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.3s,	estimator xgboost's best error=12.4658,	best estimator xgboost's best error=12.4658
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.4s,	estimator xgboost's best error=10.4833,	best estimator xgboost's best error=10.4833
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.5s,	estimator xgboost's best error=9.7092,	best estimator xgboost's best error=9.7092
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.6s,	estimator xgboost's best error=9.7092,	best estimator xgboost's best error=9.7092
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.6s,	estimator xgboost's best error=9.7092,	best estimator xgboost's best error=9.7092
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.6s,	estimator xgboost's best error=8.6131,	best estimator xgboost's best error=8.6131
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.7s,	estimator xgboost's best error=8.6131,	best estimator xgboost's best error=8.6131
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.7s,	estimator xgboost's best error=8.6131,	best estimator xgboost's best error=8.6131
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 0.8s,	estimator xgboost's best error=6.3508,	best estimator xgboost's best error=6.3508
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 1.0s,	estimator xgboost's best error=5.7424,	best estimator xgboost's best error=5.7424
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 09:01:51] {3072} INFO -  at 1.1s,	estimator xgboost's best error=5.7424,	best estimator xgboost's best error=5.7424
[flaml.automl: 09-23 09:01:51] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 09:01:52] {3072} INFO -  at 1.4s,	estimator xgboost's best error=5.5838,	best estimator xgboost's best error=5.5838
[flaml.automl: 09-23 09:01:52] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 09:01:52] {3072} INFO -  at 1.5s,	estimator xgboost's best error=5.5838,	best estimator xgboost's best error=5.5838
[flaml.automl: 09-23 09:01:52] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 09:01:52] {3072} INFO -  at 1.6s,	estimator xgboost's best error=5.5838,	best estimator xgboost's best error=5.5838
[flaml.automl: 09-23 09:01:52] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 09:01:52] {3072} INFO -  at 2.0s,	estimator xgboost's best error=5.5838,	best estimator xgboost's best error=5.5838
[flaml.automl: 09-23 09:01:52] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 09:01:52] {3072} INFO -  at 2.1s,	estimator xgboost's best error=5.5838,	best estimator xgboost's best error=5.5838
[flaml.automl: 09-23 09:01:52] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 09:01:53] {3072} INFO -  at 2.6s,	estimator xgboost's best error=5.5838,	best estimator xgboost's best error=5.5838
[flaml.automl: 09-23 09:01:53] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 09:02:50] {3072} INFO -  at 59.9s,	estimator xgboost's best error=5.4509,	best estimator xgboost's best error=5.4509
[flaml.automl: 09-23 09:03:50] {3335} INFO - retrain xgboost for 59.4s
[flaml.automl: 09-23 09:03:50] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.8672927626293638, colsample_bynode=1,
             colsample_bytree=0.8088389016065578, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.2620338774525896,
             max_delta_step=0, max_depth=0, max_leaves=38,
             min_child_weight=0.08001440001341949, missing=nan,
             monotone_constraints='()', n_estimators=30, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.005014045258863178, scale_pos_weight=1,
             subsample=0.8837922001935126, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 09:03:50] {2636} INFO - fit succeeded
[flaml.automl: 09-23 09:03:50] {2637} INFO - Time taken to find the best model: 59.87694215774536
[flaml.automl: 09-23 09:03:50] {2648} WARNING - Time taken to find the best model is 100% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
O3(0)最佳参数：{'n_estimators': 79, 'max_leaves': 38, 'min_child_weight': 0.08001440001341949, 'learning_rate': 0.2620338774525896, 'subsample': 0.8837922001935126, 'colsample_bylevel': 0.8672927626293638, 'colsample_bytree': 0.8088389016065578, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.005014045258863178}
O3(0)最佳损失：-4.450938625012381
O3(0)最好结果：{'pred_time': 1.40644697653197e-05, 'wall_clock_time': 59.87694215774536, 'metric_for_logging': {'pred_time': 1.40644697653197e-05}, 'val_loss': 5.450938625012381, 'training_iteration': 1, 'config': {'n_estimators': 79, 'max_leaves': 38, 'min_child_weight': 0.08001440001341949, 'learning_rate': 0.2620338774525896, 'subsample': 0.8837922001935126, 'colsample_bylevel': 0.8672927626293638, 'colsample_bytree': 0.8088389016065578, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.005014045258863178}, 'config/n_estimators': 79, 'config/max_leaves': 38, 'config/min_child_weight': 0.08001440001341949, 'config/learning_rate': 0.2620338774525896, 'config/subsample': 0.8837922001935126, 'config/colsample_bylevel': 0.8672927626293638, 'config/colsample_bytree': 0.8088389016065578, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.005014045258863178, 'experiment_tag': 'exp', 'time_total_s': 57.27293086051941}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.8672927626293638, colsample_bynode=1,
             colsample_bytree=0.8088389016065578, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.2620338774525896,
             max_delta_step=0, max_depth=0, max_leaves=38,
             min_child_weight=0.08001440001341949, missing=nan,
             monotone_constraints='()', n_estimators=30, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.005014045258863178, scale_pos_weight=1,
             subsample=0.8837922001935126, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
O3(0)的R2=0.9706008449506724
O3(0)的mse=61.743920185798515
O3(0)的mae=5.534692643858405
O3(0)的mar=0.21660731132786748
总共花费的时间为：119.61
沧州市
1071A
1073A
3324A
[flaml.automl: 09-23 09:11:08] {2390} INFO - task = regression
[flaml.automl: 09-23 09:11:08] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 09:11:08] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 09:11:08] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 09:11:08] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 09:11:08] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 09:11:10] {3025} INFO - Estimated sufficient time budget=11239s. Estimated necessary time budget=11s.
[flaml.automl: 09-23 09:11:10] {3072} INFO -  at 1.2s,	estimator xgboost's best error=45.8217,	best estimator xgboost's best error=45.8217
[flaml.automl: 09-23 09:11:10] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 09:11:11] {3072} INFO -  at 2.3s,	estimator xgboost's best error=22.1678,	best estimator xgboost's best error=22.1678
[flaml.automl: 09-23 09:11:11] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 09:11:12] {3072} INFO -  at 3.5s,	estimator xgboost's best error=22.1678,	best estimator xgboost's best error=22.1678
[flaml.automl: 09-23 09:11:12] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 09:11:21] {3072} INFO -  at 12.8s,	estimator xgboost's best error=22.1678,	best estimator xgboost's best error=22.1678
[flaml.automl: 09-23 09:11:21] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 09:11:22] {3072} INFO -  at 13.9s,	estimator xgboost's best error=12.2628,	best estimator xgboost's best error=12.2628
[flaml.automl: 09-23 09:11:22] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 09:11:24] {3072} INFO -  at 15.4s,	estimator xgboost's best error=10.3272,	best estimator xgboost's best error=10.3272
[flaml.automl: 09-23 09:11:24] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 09:11:25] {3072} INFO -  at 17.0s,	estimator xgboost's best error=9.6576,	best estimator xgboost's best error=9.6576
[flaml.automl: 09-23 09:11:25] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 09:11:28] {3072} INFO -  at 19.5s,	estimator xgboost's best error=9.6576,	best estimator xgboost's best error=9.6576
[flaml.automl: 09-23 09:11:28] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 09:11:29] {3072} INFO -  at 21.0s,	estimator xgboost's best error=9.6576,	best estimator xgboost's best error=9.6576
[flaml.automl: 09-23 09:11:29] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 09:11:32] {3072} INFO -  at 23.9s,	estimator xgboost's best error=8.8591,	best estimator xgboost's best error=8.8591
[flaml.automl: 09-23 09:11:32] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 09:11:34] {3072} INFO -  at 25.4s,	estimator xgboost's best error=8.8591,	best estimator xgboost's best error=8.8591
[flaml.automl: 09-23 09:11:34] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 09:11:35] {3072} INFO -  at 26.5s,	estimator xgboost's best error=8.8591,	best estimator xgboost's best error=8.8591
[flaml.automl: 09-23 09:11:35] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 09:11:43] {3072} INFO -  at 34.9s,	estimator xgboost's best error=6.7284,	best estimator xgboost's best error=6.7284
[flaml.automl: 09-23 09:11:43] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 09:11:43] {3072} INFO -  at 35.0s,	estimator xgboost's best error=5.9912,	best estimator xgboost's best error=5.9912
[flaml.automl: 09-23 09:11:43] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 09:11:43] {3072} INFO -  at 35.1s,	estimator xgboost's best error=5.9912,	best estimator xgboost's best error=5.9912
[flaml.automl: 09-23 09:11:43] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 09:11:44] {3072} INFO -  at 35.4s,	estimator xgboost's best error=5.9371,	best estimator xgboost's best error=5.9371
[flaml.automl: 09-23 09:11:44] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 09:11:44] {3072} INFO -  at 35.5s,	estimator xgboost's best error=5.9371,	best estimator xgboost's best error=5.9371
[flaml.automl: 09-23 09:11:44] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 09:11:44] {3072} INFO -  at 35.6s,	estimator xgboost's best error=5.9371,	best estimator xgboost's best error=5.9371
[flaml.automl: 09-23 09:11:44] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 09:11:44] {3072} INFO -  at 36.0s,	estimator xgboost's best error=5.9371,	best estimator xgboost's best error=5.9371
[flaml.automl: 09-23 09:11:44] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 09:11:44] {3072} INFO -  at 36.1s,	estimator xgboost's best error=5.9371,	best estimator xgboost's best error=5.9371
[flaml.automl: 09-23 09:11:44] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 09:11:45] {3072} INFO -  at 36.5s,	estimator xgboost's best error=5.9130,	best estimator xgboost's best error=5.9130
[flaml.automl: 09-23 09:11:45] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 09:11:48] {3072} INFO -  at 40.2s,	estimator xgboost's best error=4.6014,	best estimator xgboost's best error=4.6014
[flaml.automl: 09-23 09:11:48] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 09:11:49] {3072} INFO -  at 40.5s,	estimator xgboost's best error=4.6014,	best estimator xgboost's best error=4.6014
[flaml.automl: 09-23 09:11:49] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 09:11:58] {3072} INFO -  at 50.0s,	estimator xgboost's best error=4.6014,	best estimator xgboost's best error=4.6014
[flaml.automl: 09-23 09:11:58] {2897} INFO - iteration 24, current learner xgboost
[flaml.automl: 09-23 09:12:07] {3072} INFO -  at 58.4s,	estimator xgboost's best error=4.6014,	best estimator xgboost's best error=4.6014
[flaml.automl: 09-23 09:13:06] {3335} INFO - retrain xgboost for 59.0s
[flaml.automl: 09-23 09:13:06] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.947904794098435, colsample_bynode=1,
             colsample_bytree=0.8129857635943755, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.6023269513573992,
             max_delta_step=0, max_depth=0, max_leaves=76,
             min_child_weight=0.016356499255813995, missing=nan,
             monotone_constraints='()', n_estimators=15, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.0009765625, scale_pos_weight=1,
             subsample=0.9754506843790957, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 09:13:06] {2636} INFO - fit succeeded
[flaml.automl: 09-23 09:13:06] {2637} INFO - Time taken to find the best model: 40.16219997406006
O3(0)最佳参数：{'n_estimators': 143, 'max_leaves': 76, 'min_child_weight': 0.016356499255813995, 'learning_rate': 0.6023269513573992, 'subsample': 0.9754506843790957, 'colsample_bylevel': 0.947904794098435, 'colsample_bytree': 0.8129857635943755, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0009765625}
O3(0)最佳损失：-3.601439710129821
O3(0)最好结果：{'pred_time': 1.3839643015603555e-06, 'wall_clock_time': 40.16219997406006, 'metric_for_logging': {'pred_time': 1.3839643015603555e-06}, 'val_loss': 4.601439710129821, 'training_iteration': 1, 'config': {'n_estimators': 143, 'max_leaves': 76, 'min_child_weight': 0.016356499255813995, 'learning_rate': 0.6023269513573992, 'subsample': 0.9754506843790957, 'colsample_bylevel': 0.947904794098435, 'colsample_bytree': 0.8129857635943755, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0009765625}, 'config/n_estimators': 143, 'config/max_leaves': 76, 'config/min_child_weight': 0.016356499255813995, 'config/learning_rate': 0.6023269513573992, 'config/subsample': 0.9754506843790957, 'config/colsample_bylevel': 0.947904794098435, 'config/colsample_bytree': 0.8129857635943755, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.0009765625, 'experiment_tag': 'exp', 'time_total_s': 3.7062718868255615}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.947904794098435, colsample_bynode=1,
             colsample_bytree=0.8129857635943755, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.6023269513573992,
             max_delta_step=0, max_depth=0, max_leaves=76,
             min_child_weight=0.016356499255813995, missing=nan,
             monotone_constraints='()', n_estimators=15, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.0009765625, scale_pos_weight=1,
             subsample=0.9754506843790957, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
O3(0)的R2=0.9714068975683847
O3(0)的mse=57.4372928268936
O3(0)的mae=5.192173619080981
O3(0)的mar=0.1431591962640777
总共花费的时间为：117.97
衡水市
1074A
1075A
3188A
3459A
[flaml.automl: 09-23 09:22:59] {2390} INFO - task = regression
[flaml.automl: 09-23 09:22:59] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 09:22:59] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 09:22:59] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 09:22:59] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 09:22:59] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 09:23:01] {3025} INFO - Estimated sufficient time budget=49559s. Estimated necessary time budget=50s.
[flaml.automl: 09-23 09:23:01] {3072} INFO -  at 1.3s,	estimator xgboost's best error=46.8266,	best estimator xgboost's best error=46.8266
[flaml.automl: 09-23 09:23:01] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 09:23:03] {3072} INFO -  at 3.2s,	estimator xgboost's best error=22.7311,	best estimator xgboost's best error=22.7311
[flaml.automl: 09-23 09:23:03] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 09:23:04] {3072} INFO -  at 4.3s,	estimator xgboost's best error=22.7311,	best estimator xgboost's best error=22.7311
[flaml.automl: 09-23 09:23:04] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 09:23:10] {3072} INFO -  at 10.2s,	estimator xgboost's best error=22.7311,	best estimator xgboost's best error=22.7311
[flaml.automl: 09-23 09:23:10] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 09:23:11] {3072} INFO -  at 11.3s,	estimator xgboost's best error=12.2879,	best estimator xgboost's best error=12.2879
[flaml.automl: 09-23 09:23:11] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 09:23:12] {3072} INFO -  at 12.7s,	estimator xgboost's best error=10.7952,	best estimator xgboost's best error=10.7952
[flaml.automl: 09-23 09:23:12] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 09:23:14] {3072} INFO -  at 14.3s,	estimator xgboost's best error=9.6783,	best estimator xgboost's best error=9.6783
[flaml.automl: 09-23 09:23:14] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 09:23:16] {3072} INFO -  at 16.8s,	estimator xgboost's best error=9.6783,	best estimator xgboost's best error=9.6783
[flaml.automl: 09-23 09:23:16] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 09:23:18] {3072} INFO -  at 18.3s,	estimator xgboost's best error=9.6783,	best estimator xgboost's best error=9.6783
[flaml.automl: 09-23 09:23:18] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 09:23:20] {3072} INFO -  at 21.1s,	estimator xgboost's best error=8.8144,	best estimator xgboost's best error=8.8144
[flaml.automl: 09-23 09:23:20] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 09:23:22] {3072} INFO -  at 22.5s,	estimator xgboost's best error=8.8144,	best estimator xgboost's best error=8.8144
[flaml.automl: 09-23 09:23:22] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 09:23:23] {3072} INFO -  at 23.6s,	estimator xgboost's best error=8.8144,	best estimator xgboost's best error=8.8144
[flaml.automl: 09-23 09:23:23] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 09:23:27] {3072} INFO -  at 27.2s,	estimator xgboost's best error=7.6599,	best estimator xgboost's best error=7.6599
[flaml.automl: 09-23 09:23:27] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 09:23:30] {3072} INFO -  at 30.5s,	estimator xgboost's best error=7.6599,	best estimator xgboost's best error=7.6599
[flaml.automl: 09-23 09:23:30] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 09:23:32] {3072} INFO -  at 33.0s,	estimator xgboost's best error=7.6599,	best estimator xgboost's best error=7.6599
[flaml.automl: 09-23 09:23:32] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 09:23:34] {3072} INFO -  at 34.6s,	estimator xgboost's best error=7.6599,	best estimator xgboost's best error=7.6599
[flaml.automl: 09-23 09:23:34] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 09:23:37] {3072} INFO -  at 37.2s,	estimator xgboost's best error=7.5115,	best estimator xgboost's best error=7.5115
[flaml.automl: 09-23 09:23:37] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 09:23:39] {3072} INFO -  at 39.6s,	estimator xgboost's best error=7.5115,	best estimator xgboost's best error=7.5115
[flaml.automl: 09-23 09:23:39] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 09:23:40] {3072} INFO -  at 40.8s,	estimator xgboost's best error=7.5115,	best estimator xgboost's best error=7.5115
[flaml.automl: 09-23 09:23:40] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 09:23:42] {3072} INFO -  at 42.6s,	estimator xgboost's best error=7.5115,	best estimator xgboost's best error=7.5115
[flaml.automl: 09-23 09:23:42] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 09:23:43] {3072} INFO -  at 43.7s,	estimator xgboost's best error=7.5115,	best estimator xgboost's best error=7.5115
[flaml.automl: 09-23 09:23:43] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 09:23:51] {3072} INFO -  at 51.2s,	estimator xgboost's best error=6.3644,	best estimator xgboost's best error=6.3644
[flaml.automl: 09-23 09:23:51] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 09:23:59] {3072} INFO -  at 59.3s,	estimator xgboost's best error=6.2238,	best estimator xgboost's best error=6.2238
[flaml.automl: 09-23 09:24:33] {3335} INFO - retrain xgboost for 34.1s
[flaml.automl: 09-23 09:24:33] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.8870008876841574, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5025866867945519,
             max_delta_step=0, max_depth=0, max_leaves=17,
             min_child_weight=0.008718108515031738, missing=nan,
             monotone_constraints='()', n_estimators=38, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.00672395905185771, scale_pos_weight=1,
             subsample=0.8853384301102215, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 09:24:33] {2636} INFO - fit succeeded
[flaml.automl: 09-23 09:24:33] {2637} INFO - Time taken to find the best model: 59.34704089164734
[flaml.automl: 09-23 09:24:33] {2648} WARNING - Time taken to find the best model is 99% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.
O3(0)最佳参数：{'n_estimators': 38, 'max_leaves': 17, 'min_child_weight': 0.008718108515031738, 'learning_rate': 0.5025866867945519, 'subsample': 0.8853384301102215, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8870008876841574, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.00672395905185771, 'FLAML_sample_size': 44131}
O3(0)最佳损失：-5.223814668045736
O3(0)最好结果：{'pred_time': 6.875245061628581e-06, 'wall_clock_time': 59.34704089164734, 'metric_for_logging': {'pred_time': 6.875245061628581e-06}, 'val_loss': 6.223814668045736, 'training_iteration': 1, 'config': {'n_estimators': 38, 'max_leaves': 17, 'min_child_weight': 0.008718108515031738, 'learning_rate': 0.5025866867945519, 'subsample': 0.8853384301102215, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8870008876841574, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.00672395905185771, 'FLAML_sample_size': 44131}, 'config/n_estimators': 38, 'config/max_leaves': 17, 'config/min_child_weight': 0.008718108515031738, 'config/learning_rate': 0.5025866867945519, 'config/subsample': 0.8853384301102215, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.8870008876841574, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.00672395905185771, 'config/FLAML_sample_size': 44131, 'experiment_tag': 'exp', 'time_total_s': 8.13901424407959}
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,
             colsample_bynode=1, colsample_bytree=0.8870008876841574, gamma=0,
             gpu_id=-1, grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.5025866867945519,
             max_delta_step=0, max_depth=0, max_leaves=17,
             min_child_weight=0.008718108515031738, missing=nan,
             monotone_constraints='()', n_estimators=38, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.00672395905185771, scale_pos_weight=1,
             subsample=0.8853384301102215, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
O3(0)的R2=0.9679993477735096
O3(0)的mse=66.58358663711596
O3(0)的mae=5.463545821913395
O3(0)的mar=0.17442939413852163
总共花费的时间为：94.12
邢台市
1078A
1079A
1080A
[flaml.automl: 09-23 09:32:12] {2390} INFO - task = regression
[flaml.automl: 09-23 09:32:12] {2392} INFO - Data split method: uniform
[flaml.automl: 09-23 09:32:12] {2396} INFO - Evaluation method: holdout
[flaml.automl: 09-23 09:32:12] {2465} INFO - Minimizing error metric: mae
[flaml.automl: 09-23 09:32:12] {2605} INFO - List of ML learners in AutoML Run: ['xgboost']
[flaml.automl: 09-23 09:32:12] {2897} INFO - iteration 0, current learner xgboost
[flaml.automl: 09-23 09:32:14] {3025} INFO - Estimated sufficient time budget=11381s. Estimated necessary time budget=11s.
[flaml.automl: 09-23 09:32:14] {3072} INFO -  at 1.2s,	estimator xgboost's best error=43.5260,	best estimator xgboost's best error=43.5260
[flaml.automl: 09-23 09:32:14] {2897} INFO - iteration 1, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.3s,	estimator xgboost's best error=21.2844,	best estimator xgboost's best error=21.2844
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 2, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.3s,	estimator xgboost's best error=21.2844,	best estimator xgboost's best error=21.2844
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 3, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.4s,	estimator xgboost's best error=21.2844,	best estimator xgboost's best error=21.2844
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 4, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.5s,	estimator xgboost's best error=12.6090,	best estimator xgboost's best error=12.6090
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 5, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.5s,	estimator xgboost's best error=11.4710,	best estimator xgboost's best error=11.4710
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 6, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.6s,	estimator xgboost's best error=10.0167,	best estimator xgboost's best error=10.0167
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 7, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.6s,	estimator xgboost's best error=10.0167,	best estimator xgboost's best error=10.0167
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 8, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.7s,	estimator xgboost's best error=10.0167,	best estimator xgboost's best error=10.0167
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 9, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.7s,	estimator xgboost's best error=8.8154,	best estimator xgboost's best error=8.8154
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 10, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.8s,	estimator xgboost's best error=8.8154,	best estimator xgboost's best error=8.8154
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 11, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.8s,	estimator xgboost's best error=8.8154,	best estimator xgboost's best error=8.8154
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 12, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 2.9s,	estimator xgboost's best error=6.7721,	best estimator xgboost's best error=6.7721
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 13, current learner xgboost
[flaml.automl: 09-23 09:32:15] {3072} INFO -  at 3.1s,	estimator xgboost's best error=6.0815,	best estimator xgboost's best error=6.0815
[flaml.automl: 09-23 09:32:15] {2897} INFO - iteration 14, current learner xgboost
[flaml.automl: 09-23 09:32:16] {3072} INFO -  at 3.2s,	estimator xgboost's best error=6.0815,	best estimator xgboost's best error=6.0815
[flaml.automl: 09-23 09:32:16] {2897} INFO - iteration 15, current learner xgboost
[flaml.automl: 09-23 09:32:16] {3072} INFO -  at 3.3s,	estimator xgboost's best error=5.9632,	best estimator xgboost's best error=5.9632
[flaml.automl: 09-23 09:32:16] {2897} INFO - iteration 16, current learner xgboost
[flaml.automl: 09-23 09:32:16] {3072} INFO -  at 3.5s,	estimator xgboost's best error=5.9632,	best estimator xgboost's best error=5.9632
[flaml.automl: 09-23 09:32:16] {2897} INFO - iteration 17, current learner xgboost
[flaml.automl: 09-23 09:32:16] {3072} INFO -  at 3.6s,	estimator xgboost's best error=5.9632,	best estimator xgboost's best error=5.9632
[flaml.automl: 09-23 09:32:16] {2897} INFO - iteration 18, current learner xgboost
[flaml.automl: 09-23 09:32:16] {3072} INFO -  at 4.0s,	estimator xgboost's best error=5.9632,	best estimator xgboost's best error=5.9632
[flaml.automl: 09-23 09:32:16] {2897} INFO - iteration 19, current learner xgboost
[flaml.automl: 09-23 09:32:16] {3072} INFO -  at 4.1s,	estimator xgboost's best error=5.9632,	best estimator xgboost's best error=5.9632
[flaml.automl: 09-23 09:32:16] {2897} INFO - iteration 20, current learner xgboost
[flaml.automl: 09-23 09:32:18] {3072} INFO -  at 5.6s,	estimator xgboost's best error=5.8902,	best estimator xgboost's best error=5.8902
[flaml.automl: 09-23 09:32:18] {2897} INFO - iteration 21, current learner xgboost
[flaml.automl: 09-23 09:32:21] {3072} INFO -  at 8.3s,	estimator xgboost's best error=4.8091,	best estimator xgboost's best error=4.8091
[flaml.automl: 09-23 09:32:21] {2897} INFO - iteration 22, current learner xgboost
[flaml.automl: 09-23 09:32:21] {3072} INFO -  at 8.8s,	estimator xgboost's best error=4.8091,	best estimator xgboost's best error=4.8091
[flaml.automl: 09-23 09:32:21] {2897} INFO - iteration 23, current learner xgboost
[flaml.automl: 09-23 09:33:19] {3072} INFO -  at 66.6s,	estimator xgboost's best error=4.8091,	best estimator xgboost's best error=4.8091
[flaml.automl: 09-23 09:34:11] {3335} INFO - retrain xgboost for 52.2s
[flaml.automl: 09-23 09:34:11] {3342} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.947904794098435, colsample_bynode=1,
             colsample_bytree=0.8129857635943755, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.6023269513573992,
             max_delta_step=0, max_depth=0, max_leaves=76,
             min_child_weight=0.016356499255813995, missing=nan,
             monotone_constraints='()', n_estimators=14, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.0009765625, scale_pos_weight=1,
             subsample=0.9754506843790957, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
[flaml.automl: 09-23 09:34:11] {2636} INFO - fit succeeded
[flaml.automl: 09-23 09:34:11] {2637} INFO - Time taken to find the best model: 8.308178663253784
O3(0)最佳参数：{'n_estimators': 143, 'max_leaves': 76, 'min_child_weight': 0.016356499255813995, 'learning_rate': 0.6023269513573992, 'subsample': 0.9754506843790957, 'colsample_bylevel': 0.947904794098435, 'colsample_bytree': 0.8129857635943755, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0009765625}
O3(0)最佳损失：-3.809115013217225
O3(0)最好结果：{'pred_time': 4.474865904760576e-06, 'wall_clock_time': 8.308178663253784, 'metric_for_logging': {'pred_time': 4.474865904760576e-06}, 'val_loss': 4.809115013217225, 'training_iteration': 1, 'config': {'n_estimators': 143, 'max_leaves': 76, 'min_child_weight': 0.016356499255813995, 'learning_rate': 0.6023269513573992, 'subsample': 0.9754506843790957, 'colsample_bylevel': 0.947904794098435, 'colsample_bytree': 0.8129857635943755, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0009765625}, 'config/n_estimators': 143, 'config/max_leaves': 76, 'config/min_child_weight': 0.016356499255813995, 'config/learning_rate': 0.6023269513573992, 'config/subsample': 0.9754506843790957, 'config/colsample_bylevel': 0.947904794098435, 'config/colsample_bytree': 0.8129857635943755, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.0009765625, 'experiment_tag': 'exp', 'time_total_s': 2.6817922592163086}
XGBRegressor(base_score=0.5, booster='gbtree',
             colsample_bylevel=0.947904794098435, colsample_bynode=1,
             colsample_bytree=0.8129857635943755, gamma=0, gpu_id=-1,
             grow_policy='lossguide', importance_type='gain',
             interaction_constraints='', learning_rate=0.6023269513573992,
             max_delta_step=0, max_depth=0, max_leaves=76,
             min_child_weight=0.016356499255813995, missing=nan,
             monotone_constraints='()', n_estimators=14, n_jobs=-1,
             num_parallel_tree=1, random_state=0, reg_alpha=0.0009765625,
             reg_lambda=0.0009765625, scale_pos_weight=1,
             subsample=0.9754506843790957, tree_method='hist',
             use_label_encoder=False, validate_parameters=1, verbosity=0)
O3(0)的R2=0.9694426430361648
O3(0)的mse=67.01859593779369
O3(0)的mae=5.495975707529397
O3(0)的mar=0.16582815515851315
总共花费的时间为：119.34
太原市
1081A
